---
created: 2025-09-29 10:27:37
last_modified: 2025-09-29 11:34:54
---
## #141
한 회사는 사용자에게 글로벌 긴급 뉴스, 지역 알림 및 날씨 업데이트를 제공하는 웹 기반 포털을 운영합니다. 포털은 정적 및 동적 콘텐츠를 혼합하여 사용자가 개인화된 뷰를 받을 수 있도록 제공합니다. 콘텐츠는 애플리케이션 로드 밸런서(ALB) 뒤에서 실행되는 Amazon EC2 인스턴스에서 실행되는 API 서버를 통해 HTTPS로 제공됩니다. 회사는 전 세계 사용자에게 가능한 한 빠르게 포털 콘텐츠를 제공하고자 합니다.  
솔루션 설계자는 모든 사용자에게 최소 지연 시간을 보장하기 위해 애플리케이션을 어떻게 설계해야 합니까?

A. 애플리케이션 스택을 단일 AWS 리전에 배포합니다. ALB를 오리진으로 지정하여 모든 정적 및 동적 콘텐츠를 제공하기 위해 Amazon CloudFront를 사용합니다.  

B. 애플리케이션 스택을 두 개의 AWS 리전에 배포합니다. Amazon Route 53 지연 시간(latency) 라우팅 정책을 사용하여 가장 가까운 리전의 ALB에서 모든 콘텐츠를 제공합니다.  

C. 애플리케이션 스택을 단일 AWS 리전에 배포합니다. Amazon CloudFront를 사용하여 정적 콘텐츠를 제공하고 동적 콘텐츠는 ALB에서 직접 제공합니다.  

D. 애플리케이션 스택을 두 개의 AWS 리전에 배포합니다. Amazon Route 53 지리 위치(geolocation) 라우팅 정책을 사용하여 가장 가까운 리전의 ALB에서 모든 콘텐츠를 제공합니다.

```
A company runs a web-based portal that provides users with global breaking news, local alerts, and weather updates. The portal delivers each user a personalized view by using mixture of static and dynamic content. Content is served over HTTPS through an API server running on an Amazon EC2 instance behind an Application Load Balancer (ALB). The company wants the portal to provide this content to its users across the world as quickly as possible.  
How should a solutions architect design the application to ensure the LEAST amount of latency for all users?

- A. Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve all static and dynamic content by specifying the ALB as an origin.
- B. Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.
- C. Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve the static content. Serve the dynamic content directly from the ALB.
- D. Deploy the application stack in two AWS Regions. Use an Amazon Route 53 geolocation routing policy to serve all content from the ALB in the closest Region.
```

정답 : `A`

- CloudFront는 글로벌 엣지 로케이션을 활용하여 전 세계 사용자에게 정적 및 동적 콘텐츠를 빠르게 제공
- ALB를 오리진으로 지정하면 정적 콘텐츠와 동적 API 응답 모두 CloudFront를 통해 캐싱되고 전달되므로 지연 시간이 최소화
- 단일 리전에서 CloudFront를 활용하면, 전 세계 사용자에게 최소한의 추가 운영 부담으로 빠른 콘텐츠 전달 가능
- 다중 리전 배포(B와 D)는 인프라 복잡성을 증가시키고, 라우팅 정책과 데이터 동기화 문제를 발생시켜 운영 부담을 늘림
- C는 동적 콘텐츠를 ALB에서 직접 제공하므로 전 세계 사용자에게는 지연이 발생

오답 이유

- **B. 두 개 리전 + Route 53 지연 시간 라우팅**
    - 동적/정적 콘텐츠를 각 리전에 배포해야 하며, 데이터 동기화, 세션 관리, 운영 복잡성이 증가합니다.
    - CloudFront를 사용하면 지연 시간 문제를 더 적은 운영 부담으로 해결할 수 있음.
    
- **C. 단일 리전 + CloudFront 정적, ALB 동적**
    - 정적 콘텐츠는 CloudFront에서 빠르게 전달되지만, 동적 콘텐츠는 ALB에서 직접 제공되므로 전 세계 사용자에게는 지연 발생 가능.
    
- **D. 두 개 리전 + Route 53 지리 위치 라우팅**
    - B와 유사하게 인프라 복잡성 증가, 데이터 동기화 및 운영 부담 발생.


## #142
한 게임 회사가 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 실행되며 UDP 기반 트래픽만 지원합니다. 회사는 프런트엔드 계층이 가능한 최고의 사용자 경험을 제공해야 합니다. 해당 계층은 **낮은 지연 시간**, **가장 가까운 엣지 위치로 트래픽 라우팅**, **애플리케이션 엔드포인트에 대한 정적 IP 주소 제공**을 만족해야 합니다.  
솔루션 설계자는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

A. Amazon Route 53을 구성하여 요청을 Application Load Balancer로 전달합니다. AWS Lambda를 AWS Application Auto Scaling에서 애플리케이션에 사용합니다.  

B. Amazon CloudFront를 구성하여 요청을 Network Load Balancer로 전달합니다. AWS Lambda를 AWS Application Auto Scaling 그룹에서 애플리케이션에 사용합니다.  

C. AWS Global Accelerator를 구성하여 요청을 Network Load Balancer로 전달합니다. EC2 인스턴스를 EC2 Auto Scaling 그룹에서 애플리케이션에 사용합니다.  

D. Amazon API Gateway를 구성하여 요청을 Application Load Balancer로 전달합니다. EC2 인스턴스를 EC2 Auto Scaling 그룹에서 애플리케이션에 사용합니다.

```
A gaming company is designing a highly available architecture. The application runs on a modified Linux kernel and supports only UDP-based traffic. The company needs the front-end tier to provide the best possible user experience. That tier must have low latency, route traffic to the nearest edge location, and provide static IP addresses for entry into the application endpoints.  
What should a solutions architect do to meet these requirements?

- A. Configure Amazon Route 53 to forward requests to an Application Load Balancer. Use AWS Lambda for the application in AWS Application Auto Scaling.
- B. Configure Amazon CloudFront to forward requests to a Network Load Balancer. Use AWS Lambda for the application in an AWS Application Auto Scaling group.
- C. Configure AWS Global Accelerator to forward requests to a Network Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.
- D. Configure Amazon API Gateway to forward requests to an Application Load Balancer. Use Amazon EC2 instances for the application in an EC2 Auto Scaling group.
```

정답 : `C

- 요구사항
	- UDP 트래픽
	- 낮은 지연시간
	- 엣지 로케이션 기반 라우팅
	- 정적 IP 제공
- AWS Global Accelerator는 글로벌 네트워크 백본을 통해 사용자의 요청을 가장 가까운 AWS 엣지 로케이션으로 전달하며 정적 Anycast IP 주소를 제공
- NLB(Network Load Balancer)는 UDP 트래픽을 지원하며, EC2 오토스케일링 그룹과 함께 사용하면 확장성과 고가용성을 제공

오답 이유

- **A. Route 53 + ALB + Lambda**
    - ALB는 **UDP 트래픽을 지원하지 않음**.
    - Lambda는 UDP 서버 역할을 직접 수행할 수 없으며, Application Auto Scaling과는 맞지 않음.
    
- **B. CloudFront + NLB + Lambda**
    - CloudFront는 **HTTP/HTTPS 트래픽**만 지원. UDP 트래픽 라우팅 불가.
    - Lambda는 UDP 서버를 호스팅할 수 없음.
    
- **D. API Gateway + ALB + EC2**
    - API Gateway는 **HTTP/HTTPS 트래픽만 지원**, UDP 트래픽 불가.
    - ALB 역시 UDP를 지원하지 않음.


## #143
한 회사가 기존의 온프레미스 모놀리식 애플리케이션을 AWS로 마이그레이션하려고 합니다. 회사는 가능한 한 프런트엔드 코드와 백엔드 코드를 최대한 유지하려고 합니다. 그러나 회사는 애플리케이션을 더 작은 애플리케이션으로 분리하고자 합니다. 각 애플리케이션은 다른 팀이 관리할 예정입니다. 회사는 **높은 확장성**과 **운영 부담 최소화**가 가능한 솔루션이 필요합니다.  
어떤 솔루션이 이러한 요구사항을 충족합니까?

A. 애플리케이션을 AWS Lambda에 호스팅합니다. 애플리케이션을 Amazon API Gateway와 통합합니다.  

B. 애플리케이션을 AWS Amplify에 호스팅합니다. 애플리케이션을 Amazon API Gateway API에 연결하고, 해당 API를 AWS Lambda와 통합합니다.  

C. 애플리케이션을 Amazon EC2 인스턴스에 호스팅합니다. EC2 인스턴스를 대상으로 하는 Auto Scaling 그룹과 함께 Application Load Balancer를 설정합니다.  

D. 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)에 호스팅합니다. Amazon ECS를 대상으로 하는 Application Load Balancer를 설정합니다.

```
A company wants to migrate its existing on-premises monolithic application to AWS. The company wants to keep as much of the front-end code and the backend code as possible. However, the company wants to break the application into smaller applications. A different team will manage each application. The company needs a highly scalable solution that minimizes operational overhead.  
Which solution will meet these requirements?

- A. Host the application on AWS Lambda. Integrate the application with Amazon API Gateway.
- B. Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda.
- C. Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets.
- D. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target.
```

정답 : `D`

- 요구사항
	- 기존 코드 최대한 활용
	- 모놀리식 -> 마이크로서비스
	- 팀별 관리
	- 높은 확장성 및 운영 부담 최소화
- Amazon ECS는 컨테이너 기반 애플리케이션을 호스팅, 기존 애플리케이션을 컨테이너화하여 분리된 서비스로 실행 가능
- ALB를 ECS와 연결하면 각 서비스별로 트래픽 분리 가능, 오토스케일링 정책을 적용해 자동 확장 가능
- 운영 부담이 EC2 기반 호스팅보다 낮으며, 람다보다 기존 코드를 많이 재사용 가능


## #144
한 회사가 최근에 글로벌 전자상거래 애플리케이션의 데이터 저장소로 Amazon Aurora를 사용하기 시작했습니다.  
대용량 보고서를 실행할 때 개발자들은 전자상거래 애플리케이션 성능이 저하된다고 보고합니다.  
Amazon CloudWatch에서 메트릭을 검토한 결과, 솔루션스 아키텍트는 월간 보고서를 실행할 때 **ReadIOPS**와 **CPUUtilization** 메트릭이 급증하는 것을 확인했습니다.  
가장 비용 효율적인 솔루션은 무엇입니까?

A. 월간 보고서를 Amazon Redshift로 마이그레이션합니다.  
B. 월간 보고서를 Aurora Replica로 마이그레이션합니다.  
C. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다.  
D. Aurora 인스턴스에서 Provisioned IOPS를 증가시킵니다.

```
A company recently started using Amazon Aurora as the data store for its global ecommerce application. When large reports are run, developers report that the ecommerce application is performing poorly. After reviewing metrics in Amazon CloudWatch, a solutions architect finds that the ReadIOPS and CPUUtilizalion metrics are spiking when monthly reports run.  
What is the MOST cost-effective solution?

- A. Migrate the monthly reporting to Amazon Redshift.
- B. Migrate the monthly reporting to an Aurora Replica.
- C. Migrate the Aurora database to a larger instance class.
- D. Increase the Provisioned IOPS on the Aurora instance.
```

정답 : `B`

- 문제 상황 : 월간 보고서 실행 시 오로라 인스턴스의 ReadIOPS와 CPU 사용률이 급증 -> 주 데이터베이스 성능 저하 발생
- 가장 비용 효율적인 방법은 읽기 전용 복제본을 사용해 보고서 쿼리를 오프로드하는 것
- 오로라 레플리카를 사용하면 기존 마스터 인스턴스의 부하를 줄이고, 별도의 읽기 트래픽을 처리할 수 있음

오답 이유

- **A. Amazon Redshift로 마이그레이션**
    - Redshift는 데이터 웨어하우스용으로 적합하며, ETL과 분석에 최적화됨.
    - 월간 보고서용만 옮기면 데이터 동기화 및 운영 오버헤드가 커지므로 비용과 운영 부담이 증가.
    
- **C. 더 큰 인스턴스로 마이그레이션**
    - 단순 인스턴스 업그레이드는 마스터 인스턴스 성능을 높이지만, 지속적인 비용 증가.
    - 비용 효율적이지 않음.
    
- **D. Provisioned IOPS 증가**
    - IOPS 증가만으로 CPU 문제 해결 불가.
    - 읽기 트래픽이 많다면 CPU와 I/O 모두 영향을 받으므로 근본 해결책이 아님.


## #145
한 회사가 웹사이트 분석 애플리케이션을 단일 Amazon EC2 온디맨드 인스턴스에서 호스팅하고 있습니다.  
분석 소프트웨어는 PHP로 작성되었고 MySQL 데이터베이스를 사용합니다.  
분석 소프트웨어, PHP를 제공하는 웹 서버, 데이터베이스 서버는 모두 동일한 EC2 인스턴스에서 호스팅되고 있습니다.  
애플리케이션은 바쁜 시간대에 성능 저하를 보이고 있으며 5xx 오류를 발생시키고 있습니다.  
회사는 애플리케이션이 원활하게 확장되도록 해야 합니다.  
가장 비용 효율적으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. 이 AMI를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Application Load Balancer를 사용하여 각 EC2 인스턴스로 부하를 분산합니다.  

B. 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. 이 AMI를 사용하여 두 번째 EC2 온디맨드 인스턴스를 시작합니다. Amazon Route 53 가중 라우팅을 사용하여 두 EC2 인스턴스에 부하를 분산합니다.  

C. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. AWS Lambda 함수를 생성하여 EC2 인스턴스를 중지하고 인스턴스 유형을 변경합니다. CPU 사용률이 75%를 초과하면 Lambda 함수를 호출하도록 Amazon CloudWatch 경보를 생성합니다.  

D. 데이터베이스를 Amazon Aurora MySQL DB 인스턴스로 마이그레이션합니다. 웹 애플리케이션의 AMI를 생성합니다. AMI를 런치 템플릿에 적용합니다. 런치 템플릿을 사용하여 Auto Scaling 그룹을 생성합니다. 런치 템플릿이 Spot Fleet을 사용하도록 구성합니다. Auto Scaling 그룹에 Application Load Balancer를 연결합니다.

```
A company hosts a website analytics application on a single Amazon EC2 On-Demand Instance. The analytics software is written in PHP and uses a MySQL database. The analytics software, the web server that provides PHP, and the database server are all hosted on the EC2 instance. The application is showing signs of performance degradation during busy times and is presenting 5xx errors. The company needs to make the application scale seamlessly.  
Which solution will meet these requirements MOST cost-effectively?

- A. Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load to each EC2 instance.
- B. Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use Amazon Route 53 weighted routing to distribute the load across the two EC2 instances.
- C. Migrate the database to an Amazon Aurora MySQL DB instance. Create an AWS Lambda function to stop the EC2 instance and change the instance type. Create an Amazon CloudWatch alarm to invoke the Lambda function when CPU utilization surpasses 75%.
- D. Migrate the database to an Amazon Aurora MySQL DB instance. Create an AMI of the web application. Apply the AMI to a launch template. Create an Auto Scaling group with the launch template Configure the launch template to use a Spot Fleet. Attach an Application Load Balancer to the Auto Scaling group.
```

정답 : `D`

- 오로라 데이터베이스로 분리해 MySQL 부하를 완화
- 웹 서버를 AMI + 런치 템플릿 + 오토스케일링 그룹으로 배포 -> 트래픽 증가 시 자동으로 EC2 인스턴스 확장
- ALB로 트래픽 분산 및 헬스 체크 -> 고가용성 확보
- Spot Fleet 사용 -> 비용 효율성 극대화

오답 이유

- **A**: ALB를 사용하지만 EC2 인스턴스 수를 수동으로 관리 → 자동 확장 불가, 트래픽 증가 시 성능 저하 가능
    
- **B**: Route 53 가중 라우팅은 실시간 트래픽 분산에 적합하지 않음 → “원활하게 확장” 요구사항 미충족
    
- **C**: EC2 중지 후 인스턴스 유형 변경 방식 → 확장 시 다운타임 발생, 실시간 대응 불가


## #146
한 회사가 프로덕션 환경에서 Application Load Balancer 뒤의 Amazon EC2 On-Demand 인스턴스 그룹에서 상태 비저장(stateless) 웹 애플리케이션을 실행하고 있습니다. 애플리케이션은 매 영업일 8시간 동안 많은 사용량을 경험합니다. 야간에는 애플리케이션 사용량이 보통 수준으로 안정적이며, 주말에는 사용량이 낮습니다.
회사는 애플리케이션의 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하고자 합니다.
어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 전체 워크로드에 대해 Spot 인스턴스를 사용합니다.  

B. 기본 사용량에 대해 Reserved 인스턴스를 사용합니다. 애플리케이션이 필요로 하는 추가 용량에는 Spot 인스턴스를 사용합니다.  

C. 기본 사용량에 대해 On-Demand 인스턴스를 사용합니다. 애플리케이션이 필요로 하는 추가 용량에는 Spot 인스턴스를 사용합니다.  

D. 기본 사용량에 대해 Dedicated 인스턴스를 사용합니다. 애플리케이션이 필요로 하는 추가 용량에는 On-Demand 인스턴스를 사용합니다.

```
A company runs a stateless web application in production on a group of Amazon EC2 On-Demand Instances behind an Application Load Balancer. The application experiences heavy usage during an 8-hour period each business day. Application usage is moderate and steady overnight. Application usage is low during weekends.  
The company wants to minimize its EC2 costs without affecting the availability of the application.  
Which solution will meet these requirements?

- A. Use Spot Instances for the entire workload.
- B. Use Reserved Instances for the baseline level of usage. Use Spot instances for any additional capacity that the application needs.
- C. Use On-Demand Instances for the baseline level of usage. Use Spot Instances for any additional capacity that the application needs.
- D. Use Dedicated Instances for the baseline level of usage. Use On-Demand Instances for any additional capacity that the application needs.
```

정답 : `B`

- 애플리케이션에는 기본 사용량(baseline usage)이 있으며, 이는 매일 일정 시간 동안 반복되는 예측 가능한 사용량
- 예측ㄱ 가능한 기본 사용량에는 Reserved Instances를 사용하면 비용을 상당히 절감 가능
- 추가 사용량은 변동적이므로 Spot Instances를 활용하면 가용성을 유지하면서 비용을 최소화

오답 이유

- **A**: Spot 인스턴스는 저렴하지만, 중단 가능성이 있어 **가용성을 요구하는 전체 워크로드**에 사용하면 안정성을 보장할 수 없습니다.
    
- **C**: On-Demand 인스턴스는 비용이 높아, 반복적이고 예측 가능한 기본 사용량에 사용하면 비용 효율성이 떨어집니다.
    
- **D**: Dedicated 인스턴스는 하드웨어 전용 배정을 의미하며, 비용이 매우 높습니다. 변동 용량을 On-Demand로 처리해도 전체 비용이 비효율적입니다.


## #147
한 회사는 중요 애플리케이션의 애플리케이션 로그 파일을 10년 동안 보관해야 합니다. 애플리케이션 팀은 문제 해결을 위해 지난 한 달(마지막 1개월) 로그를 정기적으로 접근하지만, 1개월보다 오래된 로그는 거의 접근하지 않습니다. 애플리케이션은 월 10TB 이상의 로그를 생성합니다.  
이 요구사항을 가장 비용 효율적으로 만족하는 스토리지 옵션은 무엇입니까?

A. 로그를 Amazon S3에 저장합니다. AWS Backup을 사용하여 1개월보다 오래된 로그를 S3 Glacier Deep Archive로 이동합니다.  
B. 로그를 Amazon S3에 저장합니다. S3 수명 주기(S3 Lifecycle) 정책을 사용하여 1개월보다 오래된 로그를 S3 Glacier Deep Archive로 이동합니다.  
C. 로그를 Amazon CloudWatch Logs에 저장합니다. AWS Backup을 사용하여 1개월보다 오래된 로그를 S3 Glacier Deep Archive로 이동합니다.  
D. 로그를 Amazon CloudWatch Logs에 저장합니다. Amazon S3 수명 주기(S3 Lifecycle) 정책을 사용하여 1개월보다 오래된 로그를 S3 Glacier Deep Archive로 이동합니다.

```
A company needs to retain application log files for a critical application for 10 years. The application team regularly accesses logs from the past month for troubleshooting, but logs older than 1 month are rarely accessed. The application generates more than 10 TB of logs per month.  
Which storage option meets these requirements MOST cost-effectively?

- A. Store the logs in Amazon S3. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.
- B. Store the logs in Amazon S3. Use S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.
- C. Store the logs in Amazon CloudWatch Logs. Use AWS Backup to move logs more than 1 month old to S3 Glacier Deep Archive.
- D. Store the logs in Amazon CloudWatch Logs. Use Amazon S3 Lifecycle policies to move logs more than 1 month old to S3 Glacier Deep Archive.
```

정답 : `B`

- 요구사항
	- 월 10TB 이상의 대규모 로그 장기(10년) 보관
	- 최근 1개월치에만 즉시 접근, 그 이후는 거의 접근 X -> 비용 최적화 측면에서 S3 Standard(또는 필요시 S3 Intelligent-Tiering 단기간)
	- S3 수명 주기 규칙은 S3 자체 기능으로 자동,저비용,정책 기반 전환을 제공 -> 운영 오버헤드가 거의 없음
	- S3 -> Glacier Deep Archive 전환은 비용 면에서 가장 유리



## #148
한 회사는 다음과 같은 구성 요소를 포함하는 데이터 수집 워크플로를 가지고 있습니다:
- 새 데이터 전달에 대한 알림을 수신하는 Amazon Simple Notification Service (Amazon SNS) 주제
- 데이터를 처리하고 저장하는 AWS Lambda 함수

수집 워크플로는 네트워크 연결 문제로 인해 때때로 실패합니다. 실패가 발생하면 해당 데이터는 수동으로 작업을 다시 실행하지 않는 한 수집되지 않습니다.  
모든 알림이 결국 처리되도록 하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Lambda 함수를 여러 가용 영역에 배포하도록 구성한다.  
B. Lambda 함수의 구성을 수정하여 함수의 CPU 및 메모리 할당을 늘린다.  
C. SNS 주제의 재시도 전략을 구성하여 재시도 횟수와 재시도 간 대기 시간을 모두 늘린다.  
D. Amazon Simple Queue Service (Amazon SQS) 큐를 실패 시 대상으로 구성한다. Lambda 함수가 큐의 메시지를 처리하도록 수정한다.

```
A company has a data ingestion workflow that includes the following components:  
An Amazon Simple Notification Service (Amazon SNS) topic that receives notifications about new data deliveries  
An AWS Lambda function that processes and stores the data  
The ingestion workflow occasionally fails because of network connectivity issues. When failure occurs, the corresponding data is not ingested unless the company manually reruns the job.  
What should a solutions architect do to ensure that all notifications are eventually processed?

- A. Configure the Lambda function for deployment across multiple Availability Zones.
- B. Modify the Lambda function's configuration to increase the CPU and memory allocations for the function.
- C. Configure the SNS topic’s retry strategy to increase both the number of retries and the wait time between retries.
- D. Configure an Amazon Simple Queue Service (Amazon SQS) queue as the on-failure destination. Modify the Lambda function to process messages in the queue.
```


정답 : `D`

- SNS -> Lambda 직접 연동 시 일시적인 네트워크/처리 오류가 발생하면 알림 메시지 유실
- SQS를 SNS와 람다 사이에 추가하면 메시지가 내구성 있게 저장
- 람다에서 장애가 발생하더라도 메시지를 재처리 가능
- SQS는 at-least-once delivery 보장 -> 모든 알림이 결국 처리되도록 보장

오답 이유

- **A. Lambda 함수를 여러 가용 영역에 배포하도록 구성한다.**
    → Lambda는 본래 고가용성과 다중 AZ 지원을 제공하므로, 문제의 근본 원인(메시지 유실) 해결책이 아님.
    
- **B. Lambda 함수의 CPU 및 메모리 할당을 늘린다.**
    → 성능 최적화에는 도움이 될 수 있으나, 네트워크 오류로 인한 실패/메시지 유실 문제를 해결하지 못함.
    
- **C. SNS 주제의 재시도 전략을 구성한다.**    
    → SNS는 일정 횟수까지만 재시도를 수행하며, 그 후에는 메시지를 유실할 수 있음. 메시지를 보존하는 내구성 있는 큐가 필요함.


## #149
한 회사는 이벤트 데이터를 생성하는 서비스를 가지고 있습니다. 회사는 이벤트 데이터가 수신되는 즉시 AWS를 사용하여 처리하고자 합니다. 데이터는 특정 순서로 기록되며, 이 순서는 처리 과정 전체에서 유지되어야 합니다. 회사는 운영 오버헤드를 최소화하는 솔루션을 구현하고자 합니다.  
솔루션 아키텍트는 이를 어떻게 구현해야 합니까?

A. Amazon Simple Queue Service (Amazon SQS) FIFO 큐를 생성하여 메시지를 보관한다. AWS Lambda 함수를 설정하여 큐에서 메시지를 처리한다.  
B. Amazon Simple Notification Service (Amazon SNS) 주제를 생성하여 페이로드가 포함된 알림을 전달한다. AWS Lambda 함수를 구독자로 구성한다.  
C. Amazon Simple Queue Service (Amazon SQS) 표준 큐를 생성하여 메시지를 보관한다. AWS Lambda 함수를 설정하여 큐에서 메시지를 독립적으로 처리한다.  
D. Amazon Simple Notification Service (Amazon SNS) 주제를 생성하여 페이로드가 포함된 알림을 전달한다. Amazon Simple Queue Service (Amazon SQS) 큐를 구독자로 구성한다.

```
A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing. The company wants to implement a solution that minimizes operational overhead.  
How should a solutions architect accomplish this?

- A. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue.
- B. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber.
- C. Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently.
- D. Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber.
```


정답 : `A`

- 요구사항 : 데이터의 순서를 반드시 유지해야 함
- SQS Standard 큐는 높은 처리량을 지원하지만 순서를 보장하지 않음
- SQS FIFO 큐는 메시지 순서 보장과 정확히 한 번 처리를 제공
- 람다와 통합 시 자동으로 메시지를 순차적으로 처리할 수 있어 운영 오버헤드 최소화

오답 이유

- **B. SNS + Lambda**
    → SNS는 순서를 보장하지 않으며, 다중 구독자 환경에서 메시지가 비순차적으로 처리될 수 있음.
    
- **C. SQS Standard Queue + Lambda**
    → Standard Queue는 메시지 순서를 보장하지 않음. 따라서 “특정 순서 유지” 요구사항을 만족하지 못함.
    
- **D. SNS + SQS**
    → SNS 자체는 순서 보장이 없고, SQS Standard Queue로 연결 시에도 순서 보장이 불가능. FIFO 보장이 필요하므로 적합하지 않음.


## #150
한 회사는 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션하고 있습니다. 마이그레이션 설계 요구사항의 일환으로 솔루션스 아키텍트는 인프라 메트릭 알람을 구현해야 합니다. 회사는 CPU 사용률이 짧게 급등해서 50%를 넘는 경우에는 조치를 취할 필요가 없습니다. 그러나 CPU 사용률이 50%를 초과하고 동시에 디스크의 읽기 IOPS가 높은 경우에는 가능한 한 빨리 조치해야 합니다. 솔루션스 아키텍트는 또한 거짓 알람(false alarm)을 줄여야 합니다.  
이 요구사항을 충족하려면 무엇을 해야 합니까?

A. 가능한 경우 Amazon CloudWatch 복합(Composite) 알람을 생성합니다.  
B. Amazon CloudWatch 대시보드를 생성하여 메트릭을 시각화하고 문제에 빠르게 대응합니다.  
C. 애플리케이션을 모니터링하고 알람을 발생시키기 위해 Amazon CloudWatch Synthetics 캐너리를 생성합니다.  
D. 가능한 경우 여러 메트릭 임계값을 가진 단일 Amazon CloudWatch 단일 메트릭 알람을 생성합니다.

```
A company is migrating an application from on-premises servers to Amazon EC2 instances. As part of the migration design requirements, a solutions architect must implement infrastructure metric alarms. The company does not need to take action if CPU utilization increases to more than 50% for a short burst of time. However, if the CPU utilization increases to more than 50% and read IOPS on the disk are high at the same time, the company needs to act as soon as possible. The solutions architect also must reduce false alarms.  
What should the solutions architect do to meet these requirements?

- A. Create Amazon CloudWatch composite alarms where possible.
- B. Create Amazon CloudWatch dashboards to visualize the metrics and react to issues quickly.
- C. Create Amazon CloudWatch Synthetics canaries to monitor the application and raise an alarm.
- D. Create single Amazon CloudWatch metric alarms with multiple metric thresholds where possible.
```

정답 : `A`

- 요구사항
	- 두 조건이 동시에(AND) 만족될 때만 알람
	- 짧은 순간의 CPU 버스트에는 알람을 발생시키지 않음
- CloudWatch 복합 알람(Composite Alarm)은 여러 개의 하위 알람(child alarms)을 논리식(AND, OR, NOT)으로 결합할 수 있으므로 CPU > 50% AND ReadIOPS가 높음 과 같은 다중 조건 논리를 바로 표현 가능
- 권장 구현 방법
	1. 하위 알람 1 - CPU 알람: CPU 사용률 임계값을 50%로 설정하되, 짧은 버스트를 무시하도록 Period와 EvaluationPeriods 또는 datapoints to alarm을 적절히 설정(예: 1분(period) 데이터 3개 중 2개 초과 등)하여 순간적인 스파이크를 필터링
	2. 하위 알람 2 - ReadIOPS 알람 : Read IOPS 임계값과 유효 기간을 설정
	3. 복합 알람 : 하위 알람 1 && 하위 알람 2 로 구성.


오답 이유

- **B. CloudWatch 대시보드 생성**
    - 대시보드는 모니터링/시각화에는 유용하지만 **알람 트리거를 자동화하는 기능이 아님**. 요구사항은 자동 알람/조치가 필요하므로 대시보드만으로는 불충분합니다.
    
- **C. CloudWatch Synthetics 캐너리**
    - Synthetics는 엔드투엔드(웹 페이지, API) 가용성·응답성 테스트에 적합한 서비스로, OS 수준의 CPU/IO 메트릭 결합 조건을 모니터링하는 데 적절하지 않습니다.
    
- **D. 단일 CloudWatch 단일 메트릭 알람 (여러 임계값)**
    - 단일 메트릭 알람은 **하나의 메트릭** 또는 메트릭 수식(metric math)에 기반할 수는 있지만, 서로 다른 메트릭 간의 논리적 AND(동시에 두 알람 상태를 요구)를 표현하고 거짓 알람을 줄이는 데는 **복합 알람보다 덜 직관적이고 유연**합니다. 또한 짧은 버스트을 무시하려면 개별 메트릭 알람의 평가기간/데이터포인트를 조정하는데, 이렇게 만든 하위 알람들을 복합 알람으로 조합하는 것이 권장되는 패턴입니다.


## #151
한 회사는 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 회사의 규정 준수 요건에 따르면 회사는 ap-northeast-3 리전만 사용할 수 있습니다. 회사 관리자는 VPC를 인터넷에 연결할 수 없습니다.
어떤 솔루션이 이러한 요구사항을 충족합니까? (두 가지를 선택하세요.)

A. AWS Control Tower를 사용하여 데이터 레지던시 가드레일을 구현하여 인터넷 액세스를 거부하고 ap-northeast-3을 제외한 모든 AWS 리전으로의 액세스를 거부합니다.  

B. AWS WAF의 규칙을 사용하여 인터넷 액세스를 차단합니다. 계정 설정에서 ap-northeast-3을 제외한 모든 AWS 리전으로의 액세스를 거부합니다.  

C. AWS Organizations를 사용하여 VPC가 인터넷에 연결되는 것을 방지하는 서비스 제어 정책(SCP)을 구성합니다. ap-northeast-3을 제외한 모든 AWS 리전으로의 액세스를 거부합니다.  

D. 각 VPC에 대해 네트워크 ACL의 아웃바운드 규칙을 생성하여 0.0.0.0/0으로부터의 모든 트래픽을 거부합니다. 각 사용자에 대해 IAM 정책을 생성하여 ap-northeast-3 이외의 AWS 리전을 사용하지 못하게 합니다.  

E. AWS Config를 사용하여 인터넷 게이트웨이를 탐지하는 관리형 규칙을 활성화하고 ap-northeast-3 외부에 배포된 새로운 리소스를 탐지하고 경고하도록 활성화합니다.

```
A company wants to migrate its on-premises data center to AWS. According to the company's compliance requirements, the company can use only the ap-northeast-3 Region. Company administrators are not permitted to connect VPCs to the internet.  
Which solutions will meet these requirements? (Choose two.)

- A. Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap-northeast-3.
- B. Use rules in AWS WAF to prevent internet access. Deny access to all AWS Regions except ap-northeast-3 in the AWS account settings.
- C. Use AWS Organizations to configure service control policies (SCPS) that prevent VPCs from gaining internet access. Deny access to all AWS Regions except ap-northeast-3.
- D. Create an outbound rule for the network ACL in each VPC to deny all traffic from 0.0.0.0/0. Create an IAM policy for each user to prevent the use of any AWS Region other than ap-northeast-3.
- E. Use AWS Config to activate managed rules to detect and alert for internet gateways and to detect and alert for new resources deployed outside of ap-northeast-3.
```


정답 : `C, E`

- C. AWS Organizations + Service Control Policies(SCPs)
	- 리전 제한(리전 허용/거부) 및 리소스 생성 제한(예: 인터넷 연결 관리 API 차단)을 계정 전체에 강제 적용하려면 Organizations의 SCP가 적합
	- SCP를 사용하면 특정 계정·조직 단위(OU)에 대해 aws:RequestedRegion 같은 조건을 이용해 ap-northeast-3 이외의 리전에서의 API 호출을 거부할 수 있고, ec2:CreateInternetGateway, ec2:AttachInternetGateway, ec2:CreateNatGateway 등 인터넷 연결을 만들거나 구성하는 API 호출을 차단하는 정책을 적용 가능
	- SCP는 관리자가 의도적으로 권한을 부여하더라도(계정 수준의 IAM 권한보다 상위에서) 정책을 강제하므로 **“관리자는 VPC를 인터넷에 연결할 수 없음”** 요구사항을 기술적으로 강제
- E. AWS Config의 관리형 규칙(탐지 및 경보)
	- 예방(차단) 정책과 결합하여 탐지/감사 체계를 갖추는 것은 규정 준수에서 중요
	- AWS Config는 리소스가 생성되면 규칙과 비교하여 비준수(Noncomplicant) 를 보고하고 알림(SNS 등)을 트리거할 수 있음
		- 인터넷 게이트웨이(IGW)가 생성되거나 서브넷에 퍼블릭 라우트가 추가되는지 감지하는 규칙, 리소스가 ap-northeast-3 이외의 리전에 생성되었는지 감지하는 규칙을 활성화하여 **빠른 감사·교정**
	- 탐지 규칙은 운영팀에게 알림을 주고 자동으로 remediation(예: 람다를 통한 삭제/태깅 등)을 트리거할 수 있어 거버넌스 자동화에 도움


오답 이유

**A. AWS Control Tower로만 처리**
- Control Tower는 조직 초기 설정과 표준 계정 구조(OU)·가드레일 적용을 쉽게 해주며, 일부 가드레일은 SCP/Config 등에 의해 구현됩니다. 그러나 Control Tower는 이미 계정이 Control Tower 관리 하에 있어야 하고 환경 구축이 추가적이며, 질문의 핵심(정책 강제 + 규정 준수 모니터링)을 바로 해결하려면 **직접 Organizations의 SCP와 Config 규칙을 구현**하는 것이 명확하고 경량입니다. Control Tower는 유용하지만 필수 요소는 아니고, 단독 선택지가 가장 간단한 해법이라고 보기 어렵습니다(또한 Control Tower는 모든 경우에 원하는 동일한 예방 정책을 자동으로 제공하지 않을 수 있음).

**B. AWS WAF + 계정 설정에서 리전 거부**
- AWS WAF는 웹 애플리케이션 계층(HTTP/HTTPS)에 대한 필터링 도구로, VPC 수준의 인터넷 연결(IGW, NAT 등)을 차단할 수 없음. 따라서 VPC가 인터넷에 연결되는 것을 차단하려는 목적에 적합하지 않습니다. 계정 설정에서 리전 거부도 표준 기능으로 제공되지 않으며, 리전 차단은 Organizations의 SCP로 구현해야 합니다.

**D. 네트워크 ACL 아웃바운드 차단 + IAM 정책으로 리전 제한(각 사용자)**
- 네트워크 ACL(네트워크 ACL)은 VPC 수준에서 트래픽을 제어할 수 있지만 **수작업으로 모든 VPC 및 서브넷에 적용**해야 하고, 관리자가 변경 가능하므로 정책 강제성(유효한 규정 준수 강제력)이 약합니다.
    
- IAM 정책으로 리전 사용을 제한하는 것은 가능할 수 있으나(조건 키 사용) **SC P가 아닌 개별 사용자/역할 수준에서 관리**하면 누락이나 운영 복잡성이 커집니다. 또한 NACL 차단은 관리자가 변경하면 우회 가능하므로 규정 준수 강제 수단으로는 취약합니다.


## #152
한 회사는 신입 사원 교육을 위해 3계층 웹 애플리케이션을 사용합니다. 이 애플리케이션은 하루에 단지 12시간만 액세스됩니다. 회사는 정보를 저장하기 위해 Amazon RDS for MySQL DB 인스턴스를 사용하고 있으며 비용을 최소화하려고 합니다.  
이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. AWS Systems Manager Session Manager용 IAM 정책을 구성합니다. 해당 정책에 대한 IAM 역할을 생성합니다. 역할의 신뢰 관계(trust relationship)를 업데이트합니다. DB 인스턴스에 대해 자동 시작/중지를 설정합니다.  

B. 사용자가 DB 인스턴스가 중지된 동안 캐시에서 데이터를 액세스할 수 있도록 Amazon ElastiCache for Redis 캐시 클러스터를 생성합니다. DB 인스턴스가 시작된 후 캐시를 무효화합니다.  

C. Amazon EC2 인스턴스를 시작합니다. Amazon RDS에 액세스 권한을 부여하는 IAM 역할을 생성합니다. 역할을 EC2 인스턴스에 연결합니다. 원하는 일정에 EC2 인스턴스를 시작 및 중지하도록 cron 작업을 구성합니다.  

D. DB 인스턴스를 시작 및 중지하는 AWS Lambda 함수를 생성합니다. Lambda 함수를 호출하도록 Amazon EventBridge(CloudWatch Events)의 예약 규칙을 생성합니다. 규칙의 대상으로 Lambda 함수를 구성합니다.

```
A company uses a three-tier web application to provide training to new employees. The application is accessed for only 12 hours every day. The company is using an Amazon RDS for MySQL DB instance to store information and wants to minimize costs.  
What should a solutions architect do to meet these requirements?

- A. Configure an IAM policy for AWS Systems Manager Session Manager. Create an IAM role for the policy. Update the trust relationship of the role. Set up automatic start and stop for the DB instance.
- B. Create an Amazon ElastiCache for Redis cache cluster that gives users the ability to access the data from the cache when the DB instance is stopped. Invalidate the cache after the DB instance is started.
- C. Launch an Amazon EC2 instance. Create an IAM role that grants access to Amazon RDS. Attach the role to the EC2 instance. Configure a cron job to start and stop the EC2 instance on the desired schedule.
- D. Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules.
```


정답 : `D`

- 애플리케이션은 하루 12시간만 사용되므로 비용을 절감하려면 사용하지 않는 시간에 RDS 인스턴스 중지해 인스턴스 운영 요금을 줄이는 것이 효과적
- 람다 + EventBridge(예약) 조합은 운영 오버헤드가 매우 낮고 완전 관리형
	- 람다 함수(예: boto3의 start_db_instance/stop_db_instance 호출)는 간단하고 관리가 쉬우며, 실행 환경을 운영할 필요가 없음
	- EventBridge 예약 규칙(크론 또는 rate 표현식)으로 자동적이고 정확하게 시작/중지 스케줄을 트리거할 수 있음

오답 이유

- **A. Systems Manager Session Manager용 IAM 정책 + 자동 시작/중지**
    - Session Manager(원격 쉘/세션 접속)는 RDS 인스턴스의 스케줄 제어와 직접 관련이 없습니다. 자동 시작/중지는 별도의 실행 메커니즘(예: Lambda+EventBridge)을 필요로 하며, 단순히 Session Manager 권한을 추가하는 것으로는 스케줄링이 되지 않습니다.
    
- **B. ElastiCache로 캐시 제공 후 DB 중지**
    - 캐시는 일시적 복제본이며 **정확한 영구 저장소를 대체할 수 없음**(데이터 일관성, 초기 로드 문제, 캐시 미스 처리 등). 또한 로그인이력/트랜잭션이 필요한 교육 애플리케이션에는 캐시만으로는 적절치 않습니다. DB를 중지한 상태에서 캐시로만 운영하려면 복잡한 동기화·무결성 구현이 필요하여 오히려 운영 부담과 위험이 커집니다.
    
- **C. EC2 인스턴스와 cron으로 EC2 시작/중지 제어**
    - EC2를 별도로 띄워 cron으로 RDS 시작/중지를 제어하면 **추가 인프라(EC2 비용, 관리, 보안 패치 등)** 가 발생하고 내결함성이 떨어집니다. Lambda+EventBridge는 관리형으로 훨씬 단순하고 비용·운영 부담이 적습니다.


## #153
한 회사는 인기곡의 클립으로 만든 벨소리를 판매합니다. 벨소리 파일은 Amazon S3 Standard에 저장되며 파일 크기는 최소 128KB입니다. 회사에는 수백만 개의 파일이 있지만, 90일이 지난 벨소리는 다운로드가 거의 발생하지 않습니다. 회사는 가장 자주 액세스되는 파일은 사용자가 바로 이용할 수 있게 유지하면서 저장 비용을 절감해야 합니다.  
이 요구사항을 가장 비용 효율적으로 충족하려면 어떤 조치를 취해야 합니까?

A. 객체의 초기 저장 계층으로 S3 Standard-Infrequent Access (S3 Standard-IA) 스토리지를 구성합니다.  
B. 파일을 S3 Intelligent-Tiering으로 이동하고 90일 후에 객체를 저비용 스토리지 계층으로 이동하도록 구성합니다.  
C. S3 인벤토리를 구성하여 객체를 관리하고 90일 후에 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동합니다.  
D. S3 수명 주기 정책을 구현하여 객체를 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 90일 후에 이동시킵니다.

```
A company sells ringtones created from clips of popular songs. The files containing the ringtones are stored in Amazon S3 Standard and are at least 128 KB in size. The company has millions of files, but downloads are infrequent for ringtones older than 90 days. The company needs to save money on storage while keeping the most accessed files readily available for its users.  
Which action should the company take to meet these requirements MOST cost-effectively?

- A. Configure S3 Standard-Infrequent Access (S3 Standard-IA) storage for the initial storage tier of the objects.
- B. Move the files to S3 Intelligent-Tiering and configure it to move objects to a less expensive storage tier after 90 days.
- C. Configure S3 inventory to manage objects and move them to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days.
- D. Implement an S3 Lifecycle policy that moves the objects from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-1A) after 90 days.
```

정답 : `B`

- 요구사항
	- 저장 비용 절감
	- 가장 자주 액세스되는 파일은 즉시 사용 가능
- S3 Intelligent-Tiering은 객체 접근 패턴을 자동으로 모니터링하여 자주 접근되는 객체는 Frequent tier에 유지하고 접근이 드문 객체는 Infrequent/Archive 계층으로 자동 이동 -> 운영자가 일일이 규칙을 관리하지 않아도 되며, "가장 많이 액세스되는 파일은 바로 사용가능" 요구 만족
- 수백만 개 객체처럼 규모가 큰 경우, Intelligent-Tiering은 수동 규칙 관리/분류 부담과 실수 가능성을 줄여주고 장기적으로 비용 절감 효과

오답 이유

- **A. 초기 저장을 S3 Standard-IA로 구성**
    - Standard-IA는 접근 빈도가 낮은 객체에 대해 비용이 유리하지만, 초기 저장 계층으로 모든 객체를 Standard-IA로 두면 **새로 업로드되는(최근) 인기 파일들이 즉시 접근되어야 할 때** 불필요한 조회 요금과 지연(최소 저장 기간 등)이 발생할 수 있습니다. 문제는 “가장 자주 액세스되는 파일은 바로 사용 가능”이어야 하므로 모든 파일을 처음부터 IA로 저장하는 것은 부적절합니다.
    
- **C. S3 인벤토리로 관리 후 90일 뒤에 Standard-IA 이동**
    - S3 Inventory는 객체 목록/메타데이터 보고에 유용하지만, 비용 절감 목적의 자동 계층화는 **Lifecycle 규칙 또는 Intelligent-Tiering**이 더 적합합니다. Inventory는 운영·분석용이며 매일/주기적 처리·추가 로직 필요로 하여 운영 오버헤드를 증가시킬 수 있습니다.
    
- **D. S3 Lifecycle 규칙으로 90일 후 Standard-IA로 이동**
    - Lifecycle 정책은 예측 가능한 액세스 패턴(모든 객체 90일 이후 드물게 접근됨)에 잘 맞는 저비용 옵션입니다. 그러나 문제에서 요구한 “가장 자주 액세스되는 파일은 즉시 사용 가능”을 **동적으로** 보장하려면, 일부 오래된 파일이 가끔 액세스될 경우 수동으로 예외를 관리해야 하거나 조회 시 비용/지연이 발생할 수 있습니다. 반면 Intelligent-Tiering은 빈번히 접근되는 오래된 객체를 자동으로 Frequent tier에 유지하므로 운영 부담 없이 사용자 경험을 보장합니다.


## #154
한 회사는 의료 실험 결과를 Amazon S3 저장소에 저장해야 합니다. 저장소는 몇 명의 과학자가 새 파일을 추가할 수 있도록 허용해야 하며, 다른 모든 사용자는 읽기 전용 액세스로 제한해야 합니다. 어떤 사용자도 저장소의 파일을 수정하거나 삭제할 수 있는 권한을 가져서는 안 됩니다. 회사는 모든 파일을 생성일로부터 최소 1년 동안 보관해야 합니다.  
이 요구사항을 충족할 수 있는 솔루션은 무엇입니까?

A. S3 Object Lock를 거버넌스 모드로 사용하고 법적 보유(Legal Hold)를 1년 동안 적용합니다.  
B. S3 Object Lock를 준수 모드(Compliance mode)로 사용하고 보존 기간을 365일로 설정합니다.  
C. IAM 역할을 사용하여 모든 사용자가 S3 버킷의 객체를 삭제하거나 변경하지 못하도록 제한합니다. S3 버킷 정책을 사용하여 해당 IAM 역할만 허용합니다.  
D. S3 버킷에서 객체가 추가될 때마다 AWS Lambda 함수를 호출하도록 구성합니다. 함수는 저장된 객체의 해시를 추적하여 수정된 객체를 표시하도록 구성합니다.

```
A company needs to save the results from a medical trial to an Amazon S3 repository. The repository must allow a few scientists to add new files and must restrict all other users to read-only access. No users can have the ability to modify or delete any files in the repository. The company must keep every file in the repository for a minimum of 1 year after its creation date.  
Which solution will meet these requirements?

- A. Use S3 Object Lock in governance mode with a legal hold of 1 year.
- B. Use S3 Object Lock in compliance mode with a retention period of 365 days.
- C. Use an IAM role to restrict all users from deleting or changing objects in the S3 bucket. Use an S3 bucket policy to only allow the IAM role.
- D. Configure the S3 bucket to invoke an AWS Lambda function every time an object is added. Configure the function to track the hash of the saved object so that modified objects can be marked accordingly.
```

정답 : `B`

- S3 Object Lock Compliance Mode는 모든 사용자(심지어 루트 사용자 포함)도 보존 기간 동안 객체를 수정/삭제할 수 없도록 강제
- 365일 동안 Retention Period를 설정하면, 설정된 기간 동안 객체가 자동으로 보호
- 일부 과학자만 새 파일을 추가하도록 권한을 부여하는 것은 IAM 정책과 버킷 정책으로 제어 가능

오답 이유

- **A. Governance mode + Legal Hold 1년**
    - Governance 모드는 객체 삭제/수정을 제한할 수 있지만, **특정 권한을 가진 사용자(예: 루트 또는 s3:BypassGovernanceRetention 권한 보유자)**는 이를 우회할 수 있습니다.
    - 요구사항에서는 어떤 사용자도 1년 동안 삭제/수정을 못하도록 해야 하므로 Compliance Mode가 적합합니다.
    
- **C. IAM 역할과 버킷 정책만 사용**
    - IAM 정책과 버킷 정책은 권한 기반으로 제어할 수 있지만, **S3 Object Lock와 달리 우회 가능한 루트 사용자 또는 버킷 소유자에 의해 삭제 가능**하며, 객체 생성 후 최소 보관 기간을 보장하지 않습니다.
    
- **D. Lambda 함수로 해시 추적**
    - Lambda로 객체 변경을 감지하고 표시할 수는 있지만, **삭제/수정 자체를 방지할 수 없으며**, 1년 보존 기간을 강제할 수 없습니다. 운영 복잡성도 크게 증가합니다.


## #155
대형 미디어 회사가 AWS에서 웹 애플리케이션을 호스팅합니다. 회사는 사용자가 전 세계 어디에서든 파일에 안정적으로 액세스할 수 있도록 기밀 미디어 파일을 캐싱하려고 합니다. 콘텐츠는 Amazon S3 버킷에 저장되어 있습니다. 회사는 요청이 지리적으로 어디에서 발생하든 콘텐츠를 빠르게 제공해야 합니다.  
이 요구사항을 충족할 수 있는 솔루션은 무엇입니까?

A. AWS DataSync를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다.  
B. AWS Global Accelerator를 배포하여 S3 버킷을 웹 애플리케이션에 연결합니다.  
C. Amazon CloudFront를 배포하여 S3 버킷을 CloudFront 엣지 서버에 연결합니다.  
D. Amazon Simple Queue Service(Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션에 연결합니다.

```
A large media company hosts a web application on AWS. The company wants to start caching confidential media files so that users around the world will have reliable access to the files. The content is stored in Amazon S3 buckets. The company must deliver the content quickly, regardless of where the requests originate geographically.  
Which solution will meet these requirements?

- A. Use AWS DataSync to connect the S3 buckets to the web application.
- B. Deploy AWS Global Accelerator to connect the S3 buckets to the web application.
- C. Deploy Amazon CloudFront to connect the S3 buckets to CloudFront edge servers.
- D. Use Amazon Simple Queue Service (Amazon SQS) to connect the S3 buckets to the web application.
```

정답 : `C`

- Amazon CloudFront는 글로벌 엣지 네트워크를 사용해 S3 버킷의 콘텐츠를 캐싱하고, 사용자 요청에 가장 가까운 엣지 위치에서 콘텐츠를 제공하여 지연 시간을 최소화
- S3와 CloudFront를 연동하면 기밀 콘텐츠도 Signed URLs 또는 Signed Cookies를 통해 안전하게 배포 가능

오답 이유

- **A. AWS DataSync**
    - DataSync는 대량 데이터를 온프레미스와 AWS 또는 AWS 간에 **동기화/마이그레이션**하는 서비스입니다.
    - 실시간 캐싱이나 글로벌 사용자에게 콘텐츠를 빠르게 제공하는 기능은 제공하지 않습니다.
    
- **B. AWS Global Accelerator**
    - Global Accelerator는 정적 IP를 통해 애플리케이션 트래픽을 **가장 가까운 AWS 리전으로 라우팅**합니다.
    - S3 버킷과 직접 연결해 캐싱을 제공하지 않으며, CDN 기능이 없기 때문에 글로벌 콘텐츠 배포에는 부적합합니다.
    
- **D. Amazon SQS**
    - SQS는 메시지 큐 서비스로 **비동기 메시징**을 제공하며, 콘텐츠 캐싱이나 지연 시간 최적화 기능과 관련이 없습니다.

## #156
한 회사는 서로 다른 데이터베이스에서 배치 데이터를 생성합니다. 회사는 또한 네트워크 센서와 애플리케이션 API에서 실시간 스트림 데이터를 생성합니다. 회사는 모든 데이터를 비즈니스 분석을 위해 한 곳에 통합해야 합니다. 회사는 들어오는 데이터를 처리한 후, 데이터를 서로 다른 Amazon S3 버킷에 스테이징해야 합니다. 팀은 이후 일회성 쿼리를 실행하고, 데이터를 비즈니스 인텔리전스 도구로 가져와 핵심 성과 지표(KPI)를 표시합니다.  
이 요구사항을 **가장 적은 운영 오버헤드**로 충족할 수 있는 단계의 조합은 무엇입니까? (2개 선택)

A. 일회성 쿼리에는 Amazon Athena를 사용합니다. KPI 대시보드를 생성하기 위해 Amazon QuickSight를 사용합니다.  

B. 일회성 쿼리에는 Amazon Kinesis Data Analytics를 사용합니다. KPI 대시보드를 생성하기 위해 Amazon QuickSight를 사용합니다.  

C. 사용자 지정 AWS Lambda 함수를 생성하여 데이터베이스의 개별 레코드를 Amazon Redshift 클러스터로 이동합니다.  

D. AWS Glue ETL 작업을 사용하여 데이터를 JSON 형식으로 변환합니다. 데이터를 여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 로드합니다.  

E. AWS Lake Formation의 블루프린트를 사용하여 데이터 레이크에 수집할 수 있는 데이터를 식별합니다. AWS Glue를 사용하여 소스를 크롤링하고 데이터를 추출한 다음, Amazon S3에 Apache Parquet 형식으로 로드합니다.

```
A company produces batch data that comes from different databases. The company also produces live stream data from network sensors and application APIs. The company needs to consolidate all the data into one place for business analytics. The company needs to process the incoming data and then stage the data in different Amazon S3 buckets. Teams will later run one-time queries and import the data into a business intelligence tool to show key performance indicators (KPIs).  
Which combination of steps will meet these requirements with the LEAST operational overhead? (Choose two.)

- A. Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.
- B. Use Amazon Kinesis Data Analytics for one-time queries. Use Amazon QuickSight to create dashboards for KPIs.
- C. Create custom AWS Lambda functions to move the individual records from the databases to an Amazon Redshift cluster.
- D. Use an AWS Glue extract, transform, and load (ETL) job to convert the data into JSON format. Load the data into multiple Amazon OpenSearch Service (Amazon Elasticsearch Service) clusters.
- E. Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format.
```

정답 : `A, E`

- A: S3에 스테이징 된 데이터를 Athena로 서버리스 SQL 쿼리 실행 가능하며, QuickSight와 연동해 대시보드 생성이 가능. 서버나 클러스터 관리가 필요 없음
- E: AWS Lake Formation + Glue를 사용하면 데이터 레이크로 쉽게 데이터 수집, 변환(ETL), Apache Parquet 같은 효율적인 컬럼 기반 포맷으로 S3에 저장할 수 있어 운영 오버헤드 최소화

오답 이유

- **B. Kinesis Data Analytics**
    - Kinesis Data Analytics는 **실시간 스트리밍 분석**에 적합하지만, 일회성 쿼리나 BI 대시보드 생성 용도로는 과도하고 운영 부담이 있음.
    
- **C. 사용자 지정 Lambda + Redshift**
    - 레코드 단위 이동은 **운영 오버헤드가 크고, 배치/실시간 데이터 처리 시 확장성이 낮음**.
    
- **D. Glue ETL + OpenSearch**
    - OpenSearch는 검색 최적화용이며, **BI 분석/일회성 쿼리에는 적합하지 않음**.


## #157
1. 문제 전체 한글 번역:

한 회사는 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장합니다. 회사는 모든 데이터를 5년 동안 보관해야 하며, 5년 후에는 모든 데이터를 삭제해야 합니다. 또한, 데이터베이스 내에서 수행된 모든 작업의 감사 로그(audit logs)는 무기한 보관해야 합니다. 현재 회사는 Aurora에 대해 자동 백업이 구성되어 있습니다.

이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 하는 단계의 조합은 무엇입니까? (2개 선택)

A. DB 클러스터의 수동 스냅샷을 생성합니다.  
B. 자동 백업에 대한 수명 주기(lifecycle) 정책을 생성합니다.  
C. 자동 백업 보존 기간을 5년으로 구성합니다.  
D. DB 클러스터에 대한 Amazon CloudWatch Logs 내보내기를 구성합니다.  
E. AWS Backup을 사용하여 백업을 수행하고 백업을 5년 동안 보관합니다.

```
A company stores data in an Amazon Aurora PostgreSQL DB cluster. The company must store all the data for 5 years and must delete all the data after 5 years. The company also must indefinitely keep audit logs of actions that are performed within the database. Currently, the company has automated backups configured for Aurora.  
  
Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)

- A. Take a manual snapshot of the DB cluster.
- B. Create a lifecycle policy for the automated backups.
- C. Configure automated backup retention for 5 years.
- D. Configure an Amazon CloudWatch Logs export for the DB cluster.
- E. Use AWS Backup to take the backups and to keep the backups for 5 years.
```


정답 : `D, E`

- 요구사항
	- 데이터는 5년 보관 후 삭제 -> 장기 보관과 삭제 정책 필요
	- 감사 로그는 무기한 보관 -> 로그 수집 및 장기 보관 필요
- E: AWS Backup을 사용하면 Aurora 클러스터의 백업을 관리하고, 5년 보관 후 삭제하도록 정책 설정 가능 -> 데이터 보존/삭제 요구사항을 충족
- D: Aurora PostgreSQL의 감사 로그를 CloudWatch Logs로 내보내기 설정하면, 로그를 무기한 저장 가능

오답 이유

- **A. 수동 스냅샷**
    - 수동 스냅샷은 **무기한 보관**되며 자동 삭제되지 않음. 따라서 5년 후 데이터를 삭제해야 하는 요구사항에 부적합.
    
- **B. 자동 백업 수명 주기(lifecycle) 정책 생성**
    - Aurora는 **자동 백업 수명 주기를 직접 설정할 수 없음**, 최대 보존 기간은 35일. 따라서 5년 보관 요구사항 충족 불가.
    
- **C. 자동 백업 보존 기간 5년**
    - Aurora 자동 백업의 최대 보존 기간은 35일로 제한되어 5년 요구사항 충족 불가.


## #158
솔루션스 아키텍트가 다가오는 음악 이벤트를 위해 웹사이트 성능을 최적화하려고 합니다. 공연 비디오는 실시간 스트리밍으로 제공된 후 주문형(on-demand)으로도 제공됩니다. 이벤트는 전 세계 온라인 관객을 유치할 것으로 예상됩니다.

실시간 스트리밍과 주문형 스트리밍 모두의 성능을 향상시키는 서비스는 무엇입니까?

A. Amazon CloudFront  
B. AWS Global Accelerator  
C. Amazon Route 53  
D. Amazon S3 Transfer Acceleration

```
A solutions architect is optimizing a website for an upcoming musical event. Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience.  
  
Which service will improve the performance of both the real-time and on-demand streaming?

- A. Amazon CloudFront
- B. AWS Global Accelerator
- C. Amazon Route 53
- D. Amazon S3 Transfer Acceleration
```

정답 : `A`

- Amazon CloudFront는 전 세계 엣지 로케이션을 통해 콘텐츠를 캐싱하고 제공하므로 실시간 및 주문형 비디오 모두 성능 개선 가능
- CloudFront는 HTTP(S) 기반 스트리밍과 MediaStore, S3 등의 오리진과 연동되어 대규모 글로벌 트래픽 처리에 적합

오답 이유

- **B. AWS Global Accelerator**
    - 전 세계 사용자에게 고정 IP와 최적 경로 제공, **TCP/UDP 트래픽 지연 최소화**에 효과적.
    - 하지만 **HTTP 기반 스트리밍 콘텐츠 캐싱과 성능 최적화 기능은 제공하지 않음**, 실시간/온디맨드 비디오 성능 향상에는 제한적.
    
- **C. Amazon Route 53**
    - 도메인 이름 해석(DNS) 서비스.
    - 지연 기반 라우팅(latency-based routing) 제공 가능하지만, **스트리밍 콘텐츠 전송 최적화 기능은 없음**.
    
- **D. Amazon S3 Transfer Acceleration**
    - S3 업로드 속도 향상을 위해 전용 CloudFront 엣지 로케이션 사용.
    - **실시간 스트리밍 성능 개선 불가**, 주로 S3 업로드 최적화용.


## #159
한 회사가 Amazon API Gateway와 AWS Lambda를 사용하는 공개 서버리스 애플리케이션을 운영하고 있습니다. 최근 애플리케이션 트래픽이 봇넷에서 발생한 사기성 요청으로 급증했습니다.

승인되지 않은 사용자의 요청을 차단하기 위해 솔루션스 아키텍트가 수행해야 할 단계는 무엇입니까? (두 가지 선택)

A. 정품 사용자에게만 공유되는 API 키를 사용하여 사용량 계획(Usage Plan)을 생성합니다.  
B. Lambda 함수 내에 논리를 통합하여 사기성 IP 주소의 요청을 무시합니다.  
C. AWS WAF 규칙을 구현하여 악성 요청을 타겟팅하고 필터링 조치를 트리거합니다.  
D. 기존 공개 API를 프라이빗 API로 변환합니다. DNS 레코드를 업데이트하여 사용자를 새 API 엔드포인트로 리디렉션합니다.  
E. API에 액세스하려는 각 사용자에 대해 IAM 역할을 생성합니다. 사용자가 API 호출 시 역할을 맡습니다.

```
A company is running a publicly accessible serverless application that uses Amazon API Gateway and AWS Lambda. The application’s traffic recently spiked due to fraudulent requests from botnets.  
  
Which steps should a solutions architect take to block requests from unauthorized users? (Choose two.)

- A. Create a usage plan with an API key that is shared with genuine users only.
- B. Integrate logic within the Lambda function to ignore the requests from fraudulent IP addresses.
- C. Implement an AWS WAF rule to target malicious requests and trigger actions to filter them out.
- D. Convert the existing public API to a private API. Update the DNS records to redirect users to the new API endpoint.
- E. Create an IAM role for each user attempting to access the API. A user will assume the role when making the API call.
```

정답 : `A, C`

- A. Usage Plan + Key
	- API Gateway의 사용량 계획과 API 키를 사용하면 인증된 사용자에게만 API 사용 권한을 부여할 수 있음
	- 봇이나 비인가 사용자의 접근을 제한하여 트래픽 급증을 방지
- C. AWS WAF 규칙
	- IP 주소, 요청 패턴, 헤더 등을 기반으로 악성 트래픽을 필터링
	- 봇넷이나 사기성 요청을 실시간으로 차단 가능

오답 이유

- **B. Lambda 함수 내 필터링**
    - 가능은 하지만, 모든 요청이 Lambda까지 도달해야 하므로 이미 **트래픽 비용 발생** 및 Lambda 실행 시간 소모.
    - 사전 필터링(WAF)보다 비효율적임.        
    
- **D. 프라이빗 API 변환**
    - 외부 사용자 접근을 원천 차단하지만, 일반 사용자가 접근할 수 없게 됨.
    - 공개 API 사용 요구와 상충.
    
- **E. IAM 역할 부여**
    - 모든 사용자별 IAM 역할 관리는 **운영 오버헤드가 매우 큼**.
    - 공개 서버리스 API에 적용하기 어렵고 실무적으로 비효율적임.


## #160
한 전자상거래 회사가 AWS 클라우드에서 분석 애플리케이션을 호스팅하고 있습니다. 애플리케이션은 매월 약 300MB의 데이터를 생성합니다. 데이터는 JSON 형식으로 저장됩니다. 회사는 데이터를 백업하기 위한 재해 복구 솔루션을 평가하고 있습니다. 데이터는 필요할 경우 **밀리초 단위로 접근 가능해야 하며**, 데이터는 **30일 동안 보관**되어야 합니다.

이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. Amazon OpenSearch Service (Amazon Elasticsearch Service)  
B. Amazon S3 Glacier  
C. Amazon S3 Standard  
D. Amazon RDS for PostgreSQL

```
An ecommerce company hosts its analytics application in the AWS Cloud. The application generates about 300 MB of data each month. The data is stored in JSON format. The company is evaluating a disaster recovery solution to back up the data. The data must be accessible in milliseconds if it is needed, and the data must be kept for 30 days.  
  
Which solution meets these requirements MOST cost-effectively?

- A. Amazon OpenSearch Service (Amazon Elasticsearch Service)
- B. Amazon S3 Glacier
- C. Amazon S3 Standard
- D. Amazon RDS for PostgreSQL
```

정답 : `C`

- Amazon S3 Standard는 밀리초 단위로 접근 가능
- JSON 데이터와 같은 작용 용량(월 300MB)에 대해 매우 비용 효율적인 스토리지 솔루션
- S3 Glacier나 Deep Archive는 액세스 시 몇 분~시간 정도의 지연이 있어, 즉시 접근 요구에 충족하지 못함
- Amazon RDS는 관리 오버헤드가 있고, 데이터 용량이 작아 비용 효율적이지 않음
- OpenSearch는 검색 및 분석 목적이 아니라 단순 백업용에는 과도한 비용이 발생

오답 이유

- **A. Amazon OpenSearch Service**
    - 검색 및 분석 목적의 서비스. 백업용으로는 불필요하게 비용이 높음.
    
- **B. Amazon S3 Glacier**
    - 매우 저렴하지만, 데이터 접근 시 수 분~수 시간 지연 발생. 즉시 접근 요구사항 불충족.
    
- **D. Amazon RDS for PostgreSQL**
    - 관리 오버헤드가 크고, 300MB 데이터에는 과도한 비용.