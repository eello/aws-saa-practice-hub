---
created: 2025-10-17 13:52:36
last_modified: 2025-10-17 14:58:55
---
## #561
한 회사의 웹사이트는 매일 수백만 건의 요청을 처리하며, 요청 수는 계속 증가하고 있습니다. 솔루션스 아키텍트는 웹 애플리케이션의 응답 시간을 개선해야 합니다. 솔루션스 아키텍트는 애플리케이션이 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색할 때 지연 시간을 줄여야 한다고 판단했습니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. DynamoDB Accelerator(DAX) 클러스터를 설정합니다. 모든 읽기 요청을 DAX를 통해 라우팅합니다.
B. Amazon ElastiCache for Redis를 DynamoDB 테이블과 웹 애플리케이션 사이에 설정합니다. 모든 읽기 요청을 Redis를 통해 라우팅합니다.
C. Amazon ElastiCache for Memcached를 DynamoDB 테이블과 웹 애플리케이션 사이에 설정합니다. 모든 읽기 요청을 Memcached를 통해 라우팅합니다.
D. 테이블에서 Amazon DynamoDB Streams를 설정하고, AWS Lambda가 테이블에서 읽어 Amazon ElastiCache를 채우도록 합니다. 모든 읽기 요청을 ElastiCache를 통해 라우팅합니다.

```
A company's website handles millions of requests each day, and the number of requests continues to increase. A solutions architect needs to improve the response time of the web application. The solutions architect determines that the application needs to decrease latency when retrieving product details from the Amazon DynamoDB table.  
  
Which solution will meet these requirements with the LEAST amount of operational overhead?

- A. Set up a DynamoDB Accelerator (DAX) cluster. Route all read requests through DAX.
- B. Set up Amazon ElastiCache for Redis between the DynamoDB table and the web application. Route all read requests through Redis.
- C. Set up Amazon ElastiCache for Memcached between the DynamoDB table and the web application. Route all read requests through Memcached.
- D. Set up Amazon DynamoDB Streams on the table, and have AWS Lambda read from the table and populate Amazon ElastiCache. Route all read requests through ElastiCache.
```

정답 : `A`

- DAX는 DynamoDB 전용 완전관리형 인모메리 캐시로, SDK 수준에서의 드롭인 전환만으로 마이크로초 단위의 읽기 지연을 제공
- 일관성/무효화 처리를 서비스가 관리해 별도의 캐시 동기화 로직이나 파이프라인을 운영할 필요가 없어 운영 오버헤드 최소화

오답 이유

- B. Redis는 범용 캐시로 유연하지만 DynamoDB 전용이 아니며, 키 전략/TTL/무효화 로직 등을 애플리케이션이 직접 관리해야 하므로 운영 오버헤드가 증가합니다.

- C. Memcached 역시 애플리케이션이 캐시 채움/무효화를 직접 관리해야 하고, 확장/일관성 보장이 제한적이라 DAX 대비 운영 부담이 큽니다.

- D. Streams+Lambda로 캐시를 채우는 아키텍처는 이벤트 파이프라인/재처리/동기화 실패 처리 등 복잡성이 커져 운영 오버헤드가 가장 높습니다.


## #562
솔루션스 아키텍트는 VPC의 Amazon EC2 인스턴스에서 Amazon DynamoDB로의 API 호출이 인터넷을 통해 전송되지 않도록 해야 합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 단계의 조합은 무엇입니까? (2개를 선택하십시오.)

A. 엔드포인트에 대한 라우팅 테이블 항목을 생성합니다.  
B. DynamoDB에 대한 게이트웨이 엔드포인트를 생성합니다.  
C. Amazon EC2에 대한 인터페이스 엔드포인트를 생성합니다.  
D. VPC의 각 서브넷에 엔드포인트용 탄력적 네트워크 인터페이스(ENI)를 생성합니다.  
E. 액세스를 제공하기 위해 엔드포인트의 보안 그룹에 항목을 생성합니다.

```
A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not travel across the internet.  
  
Which combination of steps should the solutions architect take to meet this requirement? (Choose two.)

- A. Create a route table entry for the endpoint.
- B. Create a gateway endpoint for DynamoDB.
- C. Create an interface endpoint for Amazon EC2.
- D. Create an elastic network interface for the endpoint in each of the subnets of the VPC.
- E. Create a security group entry in the endpoint's security group to provide access.
```

정답 : `A, B`

- DynamoDB는 게이트웨이 VPC 엔드포인트를 사용하는 AWS 서비스 중 하나로, 이를 생성하면 VPC 내부에서 사설 경로를 통해 DynamoDB API 호출이 인터넷을 거치지 않고 처리
- 게이트웨이 엔드포인트는 VPC 라우팅 테이블에 전용 경로 항목을 자동 또는 수동으로 추가해야 동작
	- 인터페이스 엔드포인트나 보안 그룹 설정은 DynamoDB의 게이트웨이에는 필요하지 않음

오답 이유

- C. 인터페이스 엔드포인트(PrivateLink)는 S3, DynamoDB와 같은 게이트웨이 엔드포인트 지원 서비스에는 사용되지 않습니다. EC2용 엔드포인트도 존재하지 않습니다.

- D. 게이트웨이 엔드포인트는 ENI를 생성하지 않습니다(ENI는 인터페이스 엔드포인트 전용 구조). 따라서 잘못된 선택입니다.

- E. 게이트웨이 엔드포인트에는 보안 그룹이 적용되지 않습니다. 보안 그룹 설정은 인터페이스 엔드포인트에만 해당됩니다.


## #563
한 회사는 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터와 온프레미스 Kubernetes 클러스터 모두에서 애플리케이션을 운영합니다. 이 회사는 모든 클러스터와 워크로드를 중앙 위치에서 보고자 합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon CloudWatch Container Insights를 사용하여 클러스터 정보를 수집하고 그룹화합니다.
B. Amazon EKS Connector를 사용하여 모든 Kubernetes 클러스터를 등록하고 연결합니다.
C. AWS Systems Manager를 사용하여 클러스터 정보를 수집하고 조회합니다.
D. Amazon EKS Anywhere를 기본 클러스터로 사용하여 네이티브 Kubernetes 명령으로 다른 클러스터를 조회합니다.

```
A company runs its applications on both Amazon Elastic Kubernetes Service (Amazon EKS) clusters and on-premises Kubernetes clusters. The company wants to view all clusters and workloads from a central location.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use Amazon CloudWatch Container Insights to collect and group the cluster information.
- B. Use Amazon EKS Connector to register and connect all Kubernetes clusters.
- C. Use AWS Systems Manager to collect and view the cluster information.
- D. Use Amazon EKS Anywhere as the primary cluster to view the other clusters with native Kubernetes commands.
```

정답 : `B`

- EKS Connector는 온프레미스 또는 타 클라우드의 순정 Kubernetes 클러스터를 EKS 콘솔에 등록해 단일 화면에서 클러스터와 네임스페이스/워크로드를 가시화
- 운영형 에이전트를 설치해 연결만 하면 되며, 워크로드 조회 중심(가시성) 기능이므로 설정/유지 오버헤드가 가장 낮음

오답 이유

- A. Container Insights는 메트릭/로그 수집·대시보드 목적이며, 온프레미스 포함 모든 클러스터와 워크로드를 EKS 콘솔처럼 중앙에서 ‘목록화/탐색’하는 기능이 아닙니다. 수집 파이프라인 구축 오버헤드도 증가합니다.

- C. Systems Manager는 인스턴스/OS 수준 관리에 적합하며, Kubernetes 클러스터/워크로드 단위의 중앙 가시화를 기본 제공하지 않습니다.

- D. EKS Anywhere는 온프레미스에서 EKS 규격 클러스터를 **구축/운영**하기 위한 배포 옵션입니다. 기존의 EKS가 아닌 임의 클러스터를 중앙에서 ‘보기’ 위한 솔루션이 아니며, EKS 콘솔 통합 가시성을 바로 제공하지 않습니다.


## #564
한 회사가 전자상거래 애플리케이션을 구축하고 있으며, 민감한 고객 정보를 저장해야 합니다. 회사는 고객이 웹사이트에서 구매 거래를 완료할 수 있도록 해야 합니다. 또한 데이터베이스 관리자(DBA)로부터도 민감한 고객 데이터가 보호되도록 해야 합니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 민감한 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. EBS 암호화를 사용하여 데이터를 암호화합니다. IAM 인스턴스 역할을 사용하여 액세스를 제한합니다.  
B. 민감한 데이터를 Amazon RDS for MySQL에 저장합니다. AWS Key Management Service(AWS KMS) 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다.  
C. 민감한 데이터를 Amazon S3에 저장합니다. AWS Key Management Service(AWS KMS) 서버 측 암호화를 사용하여 데이터를 암호화합니다. S3 버킷 정책을 사용하여 액세스를 제한합니다.  
D. 민감한 데이터를 Amazon FSx for Windows Server에 저장합니다. 파일 공유를 애플리케이션 서버에 마운트합니다. Windows 파일 권한을 사용하여 액세스를 제한합니다.

```
A company is building an ecommerce application and needs to store sensitive customer information. The company needs to give customers the ability to complete purchase transactions on the website. The company also needs to ensure that sensitive customer data is protected, even from database administrators.  
  
Which solution meets these requirements?

- A. Store sensitive data in an Amazon Elastic Block Store (Amazon EBS) volume. Use EBS encryption to encrypt the data. Use an IAM instance role to restrict access.
- B. Store sensitive data in Amazon RDS for MySQL. Use AWS Key Management Service (AWS KMS) client-side encryption to encrypt the data.
- C. Store sensitive data in Amazon S3. Use AWS Key Management Service (AWS KMS) server-side encryption to encrypt the data. Use S3 bucket policies to restrict access.
- D. Store sensitive data in Amazon FSx for Windows Server. Mount the file share on application servers. Use Windows file permissions to restrict access.
```

정답 : `B`

- Amazon RDS for MySQL에 민감을 데이터를 저장하고 AWS KMS 클라이언트 측 암호화를 사용하는 것은 데이터베이스 관리자가 암호화되지 않은 데이터를 볼 수 없도록 하는 유일한 방법
- 클라이언트 측 암호화는 애플리케이션이 데이터를 데이터베이스로 전송하기 전에 암호화하기 때문에, RDS나 DBA는 암호화디지 않은 원본 데이터를 볼 수 없음

오답 이유

- A. EBS 암호화는 디스크 수준(서버 측) 암호화로, EC2 인스턴스와 OS 레벨에서는 평문 데이터에 접근할 수 있습니다. 즉, DBA나 루트 사용자가 데이터에 접근 가능하므로 요구사항을 충족하지 못합니다.

- C. S3 서버 측 암호화(SSE-KMS)는 S3 저장 시 암호화를 제공하지만, AWS KMS 키를 사용할 수 있는 IAM 사용자(또는 관리자)는 복호화가 가능하기 때문에 "DBA로부터의 보호" 요구사항을 완벽히 충족하지 않습니다. 또한 이 시나리오는 웹 거래 처리용 데이터베이스에 적합하지 않습니다.

- D. FSx for Windows Server는 파일 스토리지 서비스로, 데이터베이스 트랜잭션 처리를 지원하지 않습니다. 또한 Windows 파일 권한으로는 관리자 접근을 완전히 차단할 수 없습니다.


## #565
한 회사는 트랜잭션 데이터를 처리하는 온프레미스 MySQL 데이터베이스를 보유하고 있습니다. 이 회사는 데이터베이스를 AWS 클라우드로 마이그레이션하고자 합니다. 마이그레이션된 데이터베이스는 데이터베이스를 사용하는 회사의 애플리케이션과의 호환성을 유지해야 합니다. 또한 마이그레이션된 데이터베이스는 수요가 증가하는 기간 동안 자동으로 확장되어야 합니다.

다음 중 어떤 마이그레이션 솔루션이 이러한 요구 사항을 충족합니까?

A. 기본 MySQL 도구를 사용하여 데이터베이스를 Amazon RDS for MySQL로 마이그레이션합니다. 탄력적 스토리지 확장을 구성합니다.  
B. mysqldump 유틸리티를 사용하여 데이터베이스를 Amazon Redshift로 마이그레이션합니다. Amazon Redshift 클러스터에 Auto Scaling을 활성화합니다.  
C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다. Aurora Auto Scaling을 활성화합니다.  
D. AWS Database Migration Service(AWS DMS)를 사용하여 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. Auto Scaling 정책을 구성합니다.

```
A company has an on-premises MySQL database that handles transactional data. The company is migrating the database to the AWS Cloud. The migrated database must maintain compatibility with the company's applications that use the database. The migrated database also must scale automatically during periods of increased demand.  
  
Which migration solution will meet these requirements?

- A. Use native MySQL tools to migrate the database to Amazon RDS for MySQL. Configure elastic storage scaling.
- B. Migrate the database to Amazon Redshift by using the mysqldump utility. Turn on Auto Scaling for the Amazon Redshift cluster.
- C. Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon Aurora. Turn on Aurora Auto Scaling.
- D. Use AWS Database Migration Service (AWS DMS) to migrate the database to Amazon DynamoDB. Configure an Auto Scaling policy.
```

정답 : `C`

- Amazon Aurora는 MySQL과 호환되는 완전관리형 관계형 데이터베이스 서비스로, 기존 애플리케이션의 MySQL 드라이버 및 쿼리와 호환
- Aurora Auto Scaling을 사용하면 읽기 전용 리플리카를 자동으로 추가하거나 제거하여 수요 증가에 따라 자동 확장
- AWS Database Migration Service(AWS DMS)를 통해 다운타임을 최소화하면서 실시간 복제를 수행할 수 있어 마이그레이션 시 최적의 선택

오답 이유

- A. RDS for MySQL은 MySQL과 호환되지만, 자동 확장은 스토리지에 한정됩니다(Elastic Storage Scaling). 데이터베이스 인스턴스의 CPU나 연결 수는 자동 확장되지 않으므로 요구사항의 "자동 확장"을 완전히 충족하지 못합니다.

- B. Amazon Redshift는 분석(OLAP) 워크로드용 데이터 웨어하우스이며, 트랜잭션(OLTP) 데이터베이스와 호환되지 않습니다. 또한 MySQL 애플리케이션과 직접적인 쿼리 호환성이 없습니다.

- D. DynamoDB는 NoSQL 키-값 데이터베이스로, MySQL과 전혀 호환되지 않습니다. 관계형 스키마나 SQL 쿼리를 사용하는 기존 애플리케이션과 호환되지 않습니다.


## #566
한 회사는 두 개의 가용 영역(AZ)에 걸쳐 VPC 내에서 여러 Amazon EC2 Linux 인스턴스를 실행하고 있습니다. 인스턴스들은 계층적 디렉터리 구조를 사용하는 애플리케이션을 호스팅합니다. 애플리케이션은 공유 스토리지에 대해 빠르고 동시적인 읽기 및 쓰기가 필요합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Amazon S3 버킷을 생성합니다. VPC의 모든 EC2 인스턴스에서 액세스를 허용합니다.
B. Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2 인스턴스에서 EFS 파일 시스템을 마운트합니다.
C. 프로비저닝된 IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 시스템을 생성합니다. EBS 볼륨을 모든 EC2 인스턴스에 연결합니다.
D. 각 EC2 인스턴스에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 파일 시스템을 생성합니다. 서로 다른 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다.

```
A company runs multiple Amazon EC2 Linux instances in a VPC across two Availability Zones. The instances host applications that use a hierarchical directory structure. The applications need to read and write rapidly and concurrently to shared storage.  
  
What should a solutions architect do to meet these requirements?

- A. Create an Amazon S3 bucket. Allow access from all the EC2 instances in the VPC.
- B. Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system from each EC2 instance.
- C. Create a file system on a Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volume. Attach the EBS volume to all the EC2 instances.
- D. Create file systems on Amazon Elastic Block Store (Amazon EBS) volumes that are attached to each EC2 instance. Synchronize the EBS volumes across the different EC2 instances.
```

정답 : `B`

- Amazon EFS는 리눅스용 완전관리형, 다중 AZ, 다중 인스턴스 동시 마운트가 가능한 POSIX 호환 네트워크 파일 시스템
- 계층적 디렉터리, 파일 잠금, 동시 읽기/쓰기를 필요로 하는 애플리케이션의 공유 스토리지 요구를 가장 간단히 충족
- 탄력적 확장으로 처리량과 IOPS를 자동 조정

오답 이유

- A. S3는 객체 스토리지로 POSIX 파일 시스템이 아니며, 파일 잠금/디렉터리/저지연 동시 쓰기 같은 요구를 충족하지 못합니다. 애플리케이션의 계층적 디렉터리 및 공유 파일 시스템 시맨틱에 부적합합니다.

- C. EBS 볼륨은 단일 인스턴스에 연결하는 것이 기본이며, io1/io2 멀티어태치가 있어도 동일 AZ 내 제한·클러스터 파일 시스템 필요 등 제약이 큽니다. 다중 AZ 동시 공유 파일 시스템 요구에 맞지 않습니다.

- D. 각 인스턴스별 EBS에 쓰고 동기화하는 방식은 운영 복잡도와 지연/충돌 위험이 큽니다. 실시간 동시 읽기/쓰기와 파일 잠금을 보장하지 않으며, 다중 AZ 일관 공유 스토리지 요구에 부합하지 않습니다.


## #567
한 솔루션스 아키텍트가 건물 내 비즈니스 임차인의 시간당 에너지 소비량을 저장하는 워크로드를 설계하고 있습니다. 센서들은 각 임차인의 사용량을 합산하는 HTTP 요청을 통해 데이터베이스에 데이터를 전달할 것입니다. 솔루션스 아키텍트는 가능한 경우 관리형 서비스를 사용해야 합니다. 솔루션스 아키텍트가 독립적인 구성 요소를 추가함에 따라 향후 워크로드는 더 많은 기능을 받게 될 것입니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon API Gateway와 AWS Lambda 함수를 사용하여 센서로부터 데이터를 수신하고, 데이터를 처리한 다음, Amazon DynamoDB 테이블에 데이터를 저장합니다.
B. Auto Scaling 그룹의 Amazon EC2 인스턴스가 지원하는 Elastic Load Balancer를 사용하여 센서로부터 데이터를 수신하고 처리합니다. 처리된 데이터를 저장하기 위해 Amazon S3 버킷을 사용합니다.
C. Amazon API Gateway와 AWS Lambda 함수를 사용하여 센서로부터 데이터를 수신하고, 데이터를 처리한 다음, Amazon EC2 인스턴스의 Microsoft SQL Server Express 데이터베이스에 데이터를 저장합니다.
D. Auto Scaling 그룹의 Amazon EC2 인스턴스가 지원하는 Elastic Load Balancer를 사용하여 센서로부터 데이터를 수신하고 처리합니다. 처리된 데이터를 저장하기 위해 Amazon Elastic File System(Amazon EFS) 공유 파일 시스템을 사용합니다.

```
A solutions architect is designing a workload that will store hourly energy consumption by business tenants in a building. The sensors will feed a database through HTTP requests that will add up usage for each tenant. The solutions architect must use managed services when possible. The workload will receive more features in the future as the solutions architect adds independent components.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in an Amazon DynamoDB table.
- B. Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon S3 bucket to store the processed data.
- C. Use Amazon API Gateway with AWS Lambda functions to receive the data from the sensors, process the data, and store the data in a Microsoft SQL Server Express database on an Amazon EC2 instance.
- D. Use an Elastic Load Balancer that is supported by an Auto Scaling group of Amazon EC2 instances to receive and process the data from the sensors. Use an Amazon Elastic File System (Amazon EFS) shared file system to store the processed data.
```

정답 : `A`

- API Gateway + Lambda는 완전관리형 서버리스로 인프라 관리가 거의 없고 HTTP 기반 수집･처리 파이프라인을 손쉽게 확장 가능
- DynamoDB는 무제한에 가까운 확장성과 초저지연을 제공하며 시계열/테넌트별 합산 패턴에 적합
- 이후 독립 컴포넌트(추가 Lambda, EventBridge, 스트림 처리 등)와 느슨하게 결합된 아키텍처를 구성하기에 유리

오답 이유

- B. ELB + EC2 + S3는 수집/처리를 위한 서버 관리, OS 패치, Auto Scaling 정책 조정 등 운영 오버헤드가 큽니다. S3는 객체 스토리지로서 시계열 누적 갱신(행 단위 업데이트)에 비효율적입니다.

- C. SQL Server Express를 EC2에서 운영하면 DB 패치/백업/가용성/스케일링을 직접 관리해야 하므로 운영 오버헤드가 큽니다. Express 에디션은 규모와 기능 제약도 있어 자동 확장에 불리합니다.

- D. ELB + EC2 + EFS는 여전히 인스턴스/파일시스템 성능·용량·스루풋 튜닝과 패치 관리가 필요합니다. 다중 동시 갱신 및 시계열 집계에는 키-값/문서형 DB(DynamoDB)보다 설계 복잡도가 높고 운영 비용이 큽니다.


## #568
한 솔루션스 아키텍트가 엔지니어링 도면을 저장하고 조회하는 데 사용되는 새로운 웹 애플리케이션을 위한 스토리지 아키텍처를 설계하고 있습니다. 모든 애플리케이션 구성 요소는 AWS 인프라에 배포될 것입니다.

애플리케이션 설계는 사용자가 엔지니어링 도면이 로드될 때 기다리는 시간을 최소화하기 위해 캐싱을 지원해야 합니다. 애플리케이션은 페타바이트 단위의 데이터를 저장할 수 있어야 합니다.

솔루션스 아키텍트는 어떤 스토리지와 캐싱의 조합을 사용해야 합니까?

A. Amazon S3와 Amazon CloudFront
B. Amazon S3 Glacier와 Amazon ElastiCache
C. Amazon Elastic Block Store(Amazon EBS) 볼륨과 Amazon CloudFront
D. AWS Storage Gateway와 Amazon ElastiCache

```
A solutions architect is designing the storage architecture for a new web application used for storing and viewing engineering drawings. All application components will be deployed on the AWS infrastructure.  
  
The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data.  
  
Which combination of storage and caching should the solutions architect use?

- A. Amazon S3 with Amazon CloudFront
- B. Amazon S3 Glacier with Amazon ElastiCache
- C. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront
- D. AWS Storage Gateway with Amazon ElastiCache
```

정답 : `A`

- Amazon S3는 사실상 무제한에 가까운 확장성으로 페타바이급 객체 저장을 지원
- Amazon CloudFront는 전 세계 엣지에서 객체를 캐싱하여 이미지/도면과 같은 정적 콘텐츠의 로드 지연을 크게 줄임

오답 이유

- B. S3 Glacier는 아카이브/장기 보관용 스토리지로 검색 지연이 크며, 실시간 뷰잉/빠른 로딩 캐시 시나리오에 부적합합니다. ElastiCache는 앱 내부 데이터 캐시로서 글로벌 엣지 캐시가 아니며 대용량 객체 전송 최적화 목적과 다릅니다.

- C. EBS는 단일 인스턴스(또는 제한적 멀티어태치) 블록 스토리지로 페타바이트급 수평 확장 객체 저장에 부적합하고, CloudFront는 원본으로 EBS를 직접 사용할 수 없습니다(일반적으로 S3/ALB/맞춤 원본이 필요).

- D. Storage Gateway는 온프레미스–AWS 하이브리드 접속을 위한 서비스로, 전 구성 요소가 AWS에 있는 본 시나리오에 불필요합니다. 또한 ElastiCache는 글로벌 콘텐츠 캐시가 아니라 애플리케이션 메모리 캐시입니다.


## #569
Amazon EventBridge 규칙이 서드파티(제3자) API를 대상으로 하고 있습니다. 그러나 해당 서드파티 API는 어떠한 인바운드 트래픽도 수신하지 않았습니다. 솔루션스 아키텍트는 규칙 조건이 충족되고 있는지, 그리고 규칙의 대상(Target)이 실제로 호출되고 있는지를 확인해야 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS/Events 네임스페이스에서 Amazon CloudWatch의 지표를 확인합니다.  
B. Amazon Simple Queue Service(Amazon SQS) 데드레터 큐(DLQ)의 이벤트를 검토합니다.  
C. Amazon CloudWatch Logs에서 이벤트를 확인합니다.  
D. AWS CloudTrail에서 EventBridge 이벤트에 대한 추적(트레일)을 확인합니다.

```
An Amazon EventBridge rule targets a third-party API. The third-party API has not received any incoming traffic. A solutions architect needs to determine whether the rule conditions are being met and if the rule's target is being invoked.  
  
Which solution will meet these requirements?

- A. Check for metrics in Amazon CloudWatch in the namespace for AWS/Events.
- B. Review events in the Amazon Simple Queue Service (Amazon SQS) dead-letter queue.
- C. Check for the events in Amazon CloudWatch Logs.
- D. Check the trails in AWS CloudTrail for the EventBridge events.
```

정답 : `A`

- Amazon EventBridge는 기본적으로 CloudWatch Metircs(AWS/Events 네임스페이스)에 규칙 실행 및 대상 호출에 대한 지표를 자동 갱신
	- Invocations, FailedInvocations, TriggeredRules 등의 지표를 통해 규칙 조건이 트리거되었는지와 대상이 실제로 호출되었는지 모니터링 가능
- 별도의 로깅이나 코드 수정 없이 운영 오버헤드 없이 상태를 확인할 수 있는 가장 직접적인 방법

오답 이유

- B. SQS 데드레터 큐(DLQ)는 EventBridge 대상이 SQS이고, 실패한 이벤트를 DLQ로 설정한 경우에만 관련이 있습니다. 문제에서는 타깃이 “서드파티 API”이므로 DLQ는 구성되지 않았을 가능성이 높습니다.

- C. CloudWatch Logs는 EventBridge 규칙 자체의 로그를 저장하지 않습니다. 로그는 EventBridge 대상이 Lambda 또는 ECS 등 로그를 남기는 서비스일 때만 기록됩니다. EventBridge 자체 트리거 여부를 판단하기에는 부적합합니다.

- D. CloudTrail은 관리 이벤트(API 호출 추적)를 기록하지만, **EventBridge 이벤트 전달(트리거 동작)** 은 데이터 이벤트로 간주되어 CloudTrail에 기록되지 않습니다. 따라서 규칙 실행/대상 호출 여부를 직접 확인할 수 없습니다.


## #570
한 회사는 매주 금요일 저녁에 실행되는 대규모 워크로드를 보유하고 있습니다.  
이 워크로드는 us-east-1 리전의 두 개의 가용 영역(AZ)에 있는 Amazon EC2 인스턴스에서 실행됩니다.  
일반적으로 회사는 항상 최대 두 개의 인스턴스만 실행해야 합니다.  
그러나 회사는 매주 금요일마다 반복적으로 발생하는 높은 워크로드를 처리하기 위해 인스턴스를 6개까지 확장하고자 합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon EventBridge에서 인스턴스를 확장하도록 리마인더를 생성합니다.  
B. 예약된 작업(Scheduled Action)이 있는 Auto Scaling 그룹을 생성합니다.  
C. 수동 확장을 사용하는 Auto Scaling 그룹을 생성합니다.  
D. 자동 확장을 사용하는 Auto Scaling 그룹을 생성합니다.

```
A company has a large workload that runs every Friday evening. The workload runs on Amazon EC2 instances that are in two Availability Zones in the us-east-1 Region. Normally, the company must run no more than two instances at all times. However, the company wants to scale up to six instances each Friday to handle a regularly repeating increased workload.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Create a reminder in Amazon EventBridge to scale the instances.
- B. Create an Auto Scaling group that has a scheduled action.
- C. Create an Auto Scaling group that uses manual scaling.
- D. Create an Auto Scaling group that uses automatic scaling.
```

정답 : `B`

- 예약된 확장은 예측 가능한 시간 기반 워크로드 증가에 최적화된 오토 스케일링 기능
- 매주 금요일 저녁과 같은 반복적 시간 패턴에 따라 인스턴스를 자동으로 확장(2 → 6)하고, 이후 워크로드가 끝나면 자동 축소(6 → 2)하도록 설정 가능

오답 이유

- A. EventBridge는 스케줄 기반 트리거를 만들 수 있지만, 인스턴스 확장을 직접 제어하지 않습니다. 추가적인 Lambda 함수나 API 호출 로직을 구성해야 하므로 오버헤드가 증가합니다.

- C. 수동 확장은 사용자가 직접 인스턴스 수를 변경해야 하므로 자동화되지 않습니다. 매주 금요일마다 사람의 개입이 필요하여 운영 효율성이 떨어집니다.

- D. 자동 확장은 트래픽 변화나 지표(CPU, 네트워크 등)에 기반한 확장 방식으로, 시간 기반 확장에는 불필요하게 복잡합니다. “예측 가능한 패턴”에는 예약 기반 확장이 더 단순하고 효율적입니다.


## #571
한 회사가 REST API를 생성하고 있습니다. 회사에는 TLS 사용에 대한 엄격한 요구 사항이 있습니다. 회사는 API 엔드포인트에서 TLSv1.3을 요구합니다. 회사는 또한 특정 공개 서드파티 인증 기관(CA)이 TLS 인증서를 서명하도록 요구합니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 로컬 머신을 사용하여 서드파티 CA가 서명한 인증서를 생성합니다. 인증서를 AWS Certificate Manager(ACM)에 가져옵니다(Import). Amazon API Gateway에서 HTTP API를 생성하고 커스텀 도메인을 구성합니다. 커스텀 도메인이 해당 인증서를 사용하도록 설정합니다.
B. AWS Certificate Manager(ACM)에서 서드파티 CA가 서명한 인증서를 생성합니다. Amazon API Gateway에서 HTTP API를 생성하고 커스텀 도메인을 구성합니다. 커스텀 도메인이 해당 인증서를 사용하도록 설정합니다.
C. AWS Certificate Manager(ACM)를 사용하여 서드파티 CA가 서명한 인증서를 생성합니다. 인증서를 AWS Certificate Manager(ACM)에 가져옵니다(Import). AWS Lambda 함수를 생성하고 Lambda 함수 URL을 구성합니다. Lambda 함수 URL이 해당 인증서를 사용하도록 설정합니다.
D. AWS Certificate Manager(ACM)에서 서드파티 CA가 서명한 인증서를 생성합니다. AWS Lambda 함수를 생성하고 Lambda 함수 URL을 구성합니다. Lambda 함수 URL이 해당 인증서를 사용하도록 설정합니다.

```
A company is creating a REST API. The company has strict requirements for the use of TLS. The company requires TLSv1.3 on the API endpoints. The company also requires a specific public third-party certificate authority (CA) to sign the TLS certificate.  
  
Which solution will meet these requirements?

- A. Use a local machine to create a certificate that is signed by the third-party CImport the certificate into AWS Certificate Manager (ACM). Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.
- B. Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.
- C. Use AWS Certificate Manager (ACM) to create a certificate that is signed by the third-party CA. Import the certificate into AWS Certificate Manager (ACM). Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate.
- D. Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate.
```

정답 : `A`

- 특정 서드파티 공인 CA가 서명한 인증서를 ACM에 가져오기해서 사용해야 함
- API Gateway의 커스텀 도메인은 ACM 인증서를 사용할 수 있으며, 최신 보안 정책으로 TLSv1.3을 적용해 엔드포인트 구성 가능
- ACM은 임의의 외부 CA로 "발급 요청"을 대행해 주지 않으므로, 외부 CA 발급 인증서의 사용은 가져오기 방식이 유일

오답 이유

- B. ACM에서 서드파티 CA가 서명한 공개 인증서를 “발급”받을 수 없습니다. ACM이 발급하는 공개 인증서는 Amazon Trust Services 체인으로만 가능합니다. 서드파티 CA 요구사항을 만족하지 못합니다.

- C. Lambda 함수 URL은 사용자 지정 도메인/사용자 지정 인증서를 직접 연결할 수 없습니다. 또한 “ACM에서 서드파티 CA로 발급”도 불가능하므로 전제부터 성립하지 않습니다.

- D. Lambda 함수 URL에 ACM 인증서를 연결할 수 없습니다. 게다가 ACM이 서드파티 CA로부터 직접 발급받아 주지도 않습니다.


## #572
한 회사가 AWS에서 애플리케이션을 운영하고 있습니다. 애플리케이션은 일정하지 않은 사용량을 받습니다. 애플리케이션은 온프레미스 MySQL 호환 데이터베이스에 연결하기 위해 AWS Direct Connect를 사용합니다. 온프레미스 데이터베이스는 일관되게 최소 2 GiB의 메모리를 사용합니다.

회사는 온프레미스 데이터베이스를 관리형 AWS 서비스로 마이그레이션하려고 합니다. 회사는 예기치 않은 워크로드 증가를 관리하기 위해 오토 스케일링 기능을 사용하고자 합니다.

다음 중 최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 기본 읽기 및 쓰기 용량 설정으로 Amazon DynamoDB 데이터베이스를 프로비저닝합니다.
B. 최소 용량 1 Aurora capacity unit(ACU)으로 Amazon Aurora 데이터베이스를 프로비저닝합니다.
C. 최소 용량 1 Aurora capacity unit(ACU)으로 Amazon Aurora Serverless v2 데이터베이스를 프로비저닝합니다.
D. 2 GiB 메모리로 Amazon RDS for MySQL 데이터베이스를 프로비저닝합니다.

```
A company runs an application on AWS. The application receives inconsistent amounts of usage. The application uses AWS Direct Connect to connect to an on-premises MySQL-compatible database. The on-premises database consistently uses a minimum of 2 GiB of memory.  
  
The company wants to migrate the on-premises database to a managed AWS service. The company wants to use auto scaling capabilities to manage unexpected workload increases.  
  
Which solution will meet these requirements with the LEAST administrative overhead?

- A. Provision an Amazon DynamoDB database with default read and write capacity settings.
- B. Provision an Amazon Aurora database with a minimum capacity of 1 Aurora capacity unit (ACU).
- C. Provision an Amazon Aurora Serverless v2 database with a minimum capacity of 1 Aurora capacity unit (ACU).
- D. Provision an Amazon RDS for MySQL database with 2 GiB of memory.
```

정답 : `C`

- Aurora Serverless v2 (MySQL 호환)는 수요에 따라 세밀한 단위로 자동으로 확장/축소되는 완전관리형 데이터베이스
- 1 ACU ≈ 2GiB 메모리로 최소 필요 메모리를 충족하면서, 트래픽 급증 시 자동으로 확장되어 운영 개입이 거의 없음

오답 이유

- A. DynamoDB는 NoSQL 키-값/문서형 DB로 MySQL 호환성이 없어 스키마/쿼리 레이어 재설계가 필요합니다. 요구사항(“MySQL 호환”)을 만족하지 않습니다.

- B. 일반(provisioned) Aurora는 인스턴스 기반으로 운영되며 ACU 설정 대상이 아닙니다. 컴퓨팅은 자동 확장이 아니어서 트래픽 급증에 대한 자동 대응이 제한적입니다.

- D. RDS for MySQL은 정해진 인스턴스 크기로 운영되며, 컴퓨팅 자동 확장이 지원되지 않습니다(수동 스케일 업/다운 필요). 예기치 않은 워크로드 증가에 대한 자동 대응 요건을 충족하지 못합니다.


## #573
한 회사가 AWS Lambda로 이벤트 기반 프로그래밍 모델을 사용하려고 합니다. 회사는 Java 11로 실행되는 Lambda 함수의 시작 지연 시간을 줄이려고 합니다. 회사는 애플리케이션에 대해 엄격한 지연 시간 요구 사항은 없습니다. 회사는 함수가 확장될 때 콜드 스타트와 이상치(Outlier) 지연 시간을 줄이고자 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?

A. Lambda 프로비저닝된 동시성을 구성합니다.
B. Lambda 함수의 타임아웃을 늘립니다.
C. Lambda 함수의 메모리를 늘립니다.
D. Lambda SnapStart를 구성합니다.

```
A company wants to use an event-driven programming model with AWS Lambda. The company wants to reduce startup latency for Lambda functions that run on Java 11. The company does not have strict latency requirements for the applications. The company wants to reduce cold starts and outlier latencies when a function scales up.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Configure Lambda provisioned concurrency.
- B. Increase the timeout of the Lambda functions.
- C. Increase the memory of the Lambda functions.
- D. Configure Lambda SnapStart.
```

정답 : `D`

- SnapStart는 자바 11 이상의 런타임에서 함수 초기화 후 실행 환경을 스냅샷에 저장해 두었다가, 확장 시 사전 초기화된 스냅샷을 복원하여 콜드 스타트와 스케일 아웃 시의 이상치 지연을 크게 줄임
- 지속적으로 인스턴스를 예열해 두는 비용이 드는 프로비저닝된 동시성과 달리, SnapStart는 일반적으로 더 비용 효율적

오답 이유

- A. 프로비저닝된 동시성은 콜드 스타트를 줄이지만, 미리 인스턴스를 예열해 유지하므로 상시 비용이 발생합니다. 본 요구사항의 "가장 비용 효율적" 조건에 덜 적합합니다.

- B. 타임아웃을 늘리는 것은 실행 가능 시간을 늘릴 뿐, 초기화 지연(콜드 스타트) 자체를 줄이지 못합니다.

- C. 메모리를 늘리면 할당 CPU가 증가해 초기화가 빨라질 수 있으나, 콜드 스타트 자체를 구조적으로 제거하지 못하고 비용이 증가합니다. 비용 대비 효과가 SnapStart보다 낮습니다.


## #574
한 금융 서비스 회사가 Amazon RDS for MySQL 데이터베이스를 사용하는 새로운 애플리케이션을 출시했습니다. 회사는 이 애플리케이션을 사용하여 주식 시장 동향을 추적합니다. 회사는 매주 말에 단 2시간 동안만 애플리케이션을 운영할 필요가 있습니다. 회사는 데이터베이스 실행 비용을 최적화해야 합니다.

다음 중 어떤 솔루션이 가장 비용 효율적으로 이러한 요구 사항을 충족합니까?

A. 기존 RDS for MySQL 데이터베이스를 Aurora Serverless v2 MySQL 데이터베이스 클러스터로 마이그레이션합니다.
B. 기존 RDS for MySQL 데이터베이스를 Aurora MySQL 데이터베이스 클러스터로 마이그레이션합니다.
C. 기존 RDS for MySQL 데이터베이스를 MySQL이 실행되는 Amazon EC2 인스턴스로 마이그레이션합니다. EC2 인스턴스에 인스턴스 예약을 구매합니다.
D. 기존 RDS for MySQL 데이터베이스를 MySQL 컨테이너 이미지를 사용하여 태스크를 실행하는 Amazon Elastic Container Service(Amazon ECS) 클러스터로 마이그레이션합니다.

```
A financial services company launched a new application that uses an Amazon RDS for MySQL database. The company uses the application to track stock market trends. The company needs to operate the application for only 2 hours at the end of each week. The company needs to optimize the cost of running the database.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Migrate the existing RDS for MySQL database to an Aurora Serverless v2 MySQL database cluster.
- B. Migrate the existing RDS for MySQL database to an Aurora MySQL database cluster.
- C. Migrate the existing RDS for MySQL database to an Amazon EC2 instance that runs MySQL. Purchase an instance reservation for the EC2 instance.
- D. Migrate the existing RDS for MySQL database to an Amazon Elastic Container Service (Amazon ECS) cluster that uses MySQL container images to run tasks.
```

정답 : `A`

- Aurora Serverless v2는 수요에 따라 ACU 단위로 자동 확장/축소되며, 사용량 기반 과금으로 짧은 시간대 운용에 유리
- MySQL 호환성을 유지하면서 예기치 않은 부하에도 자동으로 대응하므로, 비용 최적화와 유연한 스케일링을 동시에 만족

오답 이유

- B. 프로비저닝된(고정 인스턴스) Aurora MySQL은 24/7로 인스턴스를 유지하므로, 주 2시간만 사용하는 워크로드에 비해 불필요한 고정 비용이 큽니다. 자동 컴퓨팅 축소가 제한적입니다.

- C. EC2에 직접 MySQL을 운영하면 패치/백업/가용성/확장 관리 등 운영 오버헤드가 커지고, RI는 장시간 지속 사용에 최적화된 요금 모델이라 주 2시간 사용 시 비용 효율이 떨어집니다.

- D. ECS에서 MySQL 컨테이너를 돌리면 스토리지 영속성(EFS 등), 백업, 장애조치, 모니터링을 직접 설계·운영해야 합니다. 관리형 DB 대비 운영 복잡도와 리스크가 커서 비용/운영 효율 모두 불리합니다.


## #575
한 회사가 AWS 리전에서 Application Load Balancer 뒤에 Amazon Elastic Kubernetes Service(Amazon EKS)에 애플리케이션을 배포하고 있습니다. 애플리케이션은 PostgreSQL 데이터베이스 엔진에 데이터를 저장해야 합니다. 회사는 데이터베이스의 데이터가 고가용성을 갖기를 원합니다. 또한 읽기 워크로드 용량 증가도 필요합니다.

다음 중 가장 높은 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 글로벌 테이블로 구성된 Amazon DynamoDB 데이터베이스 테이블을 생성합니다.
B. Multi-AZ 배포를 사용하는 Amazon RDS 데이터베이스를 생성합니다.
C. Multi-AZ DB 클러스터 배포를 사용하는 Amazon RDS 데이터베이스를 생성합니다.
D. 교차 리전 읽기 전용 복제본으로 구성된 Amazon RDS 데이터베이스를 생성합니다.

```
A company deploys its applications on Amazon Elastic Kubernetes Service (Amazon EKS) behind an Application Load Balancer in an AWS Region. The application needs to store data in a PostgreSQL database engine. The company wants the data in the database to be highly available. The company also needs increased capacity for read workloads.  
  
Which solution will meet these requirements with the MOST operational efficiency?

- A. Create an Amazon DynamoDB database table configured with global tables.
- B. Create an Amazon RDS database with Multi-AZ deployments.
- C. Create an Amazon RDS database with Multi-AZ DB cluster deployment.
- D. Create an Amazon RDS database configured with cross-Region read replicas.
```

정답 : `C`

- RDS Multi-AZ DB 클러스터는 하나의 라이터와 여러 리더(여러 AZ에 분산된 읽기 가능한 스탠바이)를 제공하여 고가용성과 읽기 확장을 동시에 충족
- 관리형 장애 조치･패치･백업을 제공하므로 운영 오버헤드가 가장 낮음

오답 이유

- A. DynamoDB는 NoSQL 키-값/문서형 DB로 PostgreSQL과 호환되지 않습니다. 관계형 스키마/SQL을 요구하는 워크로드 요건을 충족하지 않습니다.

- B. RDS Multi-AZ(인스턴스) 배포는 스탠바이가 읽기 불가(대기 전용)인 구조여서 고가용성은 제공하나 읽기 용량 증대 요구를 충족하지 못합니다.

- D. 교차 리전 읽기 복제본은 재해 복구와 원거리 읽기 분산에 유용하지만, 동일 리전 내 고가용성/읽기 확장 요구에 비해 불필요하게 복잡하고 비용이 큽니다. 또한 기본 장애 조치 대상은 아닌 경우가 많습니다.


## #576
한 회사가 Amazon API Gateway와 AWS Lambda를 사용하여 AWS에서 RESTful 서버리스 웹 애플리케이션을 구축하고 있습니다.  
이 웹 애플리케이션의 사용자는 지리적으로 분산되어 있으며, 회사는 이러한 사용자들의 API 요청 지연(latency)을 줄이고자 합니다.

이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 유형의 엔드포인트를 사용해야 합니까?

A. 프라이빗 엔드포인트 (Private endpoint)  
B. 리전 엔드포인트 (Regional endpoint)  
C. 인터페이스 VPC 엔드포인트 (Interface VPC endpoint)  
D. 엣지 최적화 엔드포인트 (Edge-optimized endpoint)

```
A company is building a RESTful serverless web application on AWS by using Amazon API Gateway and AWS Lambda. The users of this web application will be geographically distributed, and the company wants to reduce the latency of API requests to these users.  
  
Which type of endpoint should a solutions architect use to meet these requirements?

- A. Private endpoint
- B. Regional endpoint
- C. Interface VPC endpoint
- D. Edge-optimized endpoint
```

정답 : `D`

- Edge-optimized 엔드포인트는 Amazon CloudFront 네트워크(글로벌 엣지 로케이션)을 활용하여 전 세계 분산된 사용자의 API 요청을 가장 가까운 엣지 로케이션으로 라우팅
- 이를 통해 지리적으로 떨어진 사용자에게도 낮은 지연 시간을 제공하며, 전 세계 사용자 기반을 가진 API 서비스에 적합

오답 이유

- A. Private endpoint는 VPC 내부에서만 API Gateway를 액세스할 때 사용하는 옵션으로, 퍼블릭 인터넷 사용자에게는 접근할 수 없습니다. 글로벌 사용자 접근 요구사항을 충족하지 않습니다.

- B. Regional endpoint는 특정 리전 내 사용자에게 낮은 지연 시간을 제공하지만, 글로벌 사용자에게는 엣지 캐싱이 없어 지연이 커질 수 있습니다.

- C. Interface VPC endpoint는 API Gateway를 VPC 내부의 프라이빗 네트워크를 통해 호출할 때 사용하는 옵션으로, 외부 퍼블릭 사용자에게는 적용되지 않습니다.


## #577
한 회사가 웹사이트의 콘텐츠 페이지를 제공하기 위해 Amazon CloudFront 배포를 사용하고 있습니다.  
회사는 클라이언트가 회사의 웹사이트에 액세스할 때 TLS 인증서를 사용하도록 보장해야 합니다.  
또한 TLS 인증서의 생성과 갱신을 자동화하고자 합니다.

다음 중 가장 높은 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudFront 보안 정책을 사용하여 인증서를 생성합니다.  
B. CloudFront 원본 액세스 제어(OAC)를 사용하여 인증서를 생성합니다.  
C. AWS Certificate Manager(ACM)을 사용하여 인증서를 생성합니다. 도메인에 대해 DNS 검증(DNS validation)을 사용합니다.  
D. AWS Certificate Manager(ACM)을 사용하여 인증서를 생성합니다. 도메인에 대해 이메일 검증(email validation)을 사용합니다.

```
A company uses an Amazon CloudFront distribution to serve content pages for its website. The company needs to ensure that clients use a TLS certificate when accessing the company's website. The company wants to automate the creation and renewal of the TLS certificates.  
  
Which solution will meet these requirements with the MOST operational efficiency?

- A. Use a CloudFront security policy to create a certificate.
- B. Use a CloudFront origin access control (OAC) to create a certificate.
- C. Use AWS Certificate Manager (ACM) to create a certificate. Use DNS validation for the domain.
- D. Use AWS Certificate Manager (ACM) to create a certificate. Use email validation for the domain.
```

정답 : `C`

- AWS Certificate Manager(ACM)은 CloudFront에서 사용할 수 있는 TLS 인증서를 자동으로 생성 및 갱신할 수 있는 관리형 서비스
- DNS 검증은 한 번 설정하면 인증서 만료 시 자동으로 재검증 및 자동 갱신이 이루어지므로, 이메일 검증보다 훨씬 운영 오버헤드가 낮고 완전 자동화 가능
- CloudFront 배포는 ACM에서 생성된 인증서를 연결해 HTTPS(SSL/TLS) 통신을 강제할 수 있음

오답 이유

- A. CloudFront 보안 정책(Security Policy)은 지원되는 TLS 버전과 암호화 스위트 설정을 제어하지만, 인증서를 “생성”하지 않습니다. TLS 인증서 자동화 요구사항을 충족하지 않습니다.

- B. CloudFront 원본 액세스 제어(OAC)는 S3 버킷 원본 접근 보안을 위한 기능으로, TLS 인증서 생성과 무관합니다.

- D. ACM의 이메일 검증은 인증서 발급 시마다 이메일 확인 절차가 필요합니다. 재갱신 시 수동 개입이 필요하므로 자동화와 운영 효율 측면에서 DNS 검증보다 비효율적입니다.

## #578
한 회사가 데이터베이스 계층으로 Amazon DynamoDB를 사용하는 서버리스 애플리케이션을 배포했습니다. 애플리케이션의 사용자가 크게 증가했습니다. 회사는 데이터베이스 응답 시간을 밀리초에서 마이크로초 단위로 개선하고, 데이터베이스에 대한 요청을 캐시하고자 합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. DynamoDB Accelerator(DAX)를 사용합니다.
B. 데이터베이스를 Amazon Redshift로 마이그레이션합니다.
C. 데이터베이스를 Amazon RDS로 마이그레이션합니다.
D. Amazon ElastiCache for Redis를 사용합니다.

```
A company deployed a serverless application that uses Amazon DynamoDB as a database layer. The application has experienced a large increase in users. The company wants to improve database response time from milliseconds to microseconds and to cache requests to the database.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use DynamoDB Accelerator (DAX).
- B. Migrate the database to Amazon Redshift.
- C. Migrate the database to Amazon RDS.
- D. Use Amazon ElastiCache for Redis.
```

정답 : `A`

- DAX는 DynamoDB 전용, 완전관리형 인메모리 캐시로 마이크로초 단위의 읽기 지연을 제공하며 read-through/write-through 캐싱을 지원
- SDK 수준의 설정 변경만으로 통합 가능하므로 운영 오버헤드가 가장 낮고, 서버리스 + DynamoDB 아키텍처에 자연스럽게 맞음

오답 이유

- B. Redshift는 컬럼형 데이터 웨어하우스로 분석(OLAP) 워크로드에 최적화되어 있으며, 트랜잭션/초저지연 키-값 접근과 목적이 다릅니다. 캐시 요구도 충족하지 못합니다.

- C. RDS로 마이그레이션해도 캐시 기능이 내장되지 않으며, 인스턴스/백업/패치 관리 등 운영 오버헤드가 증가합니다. 마이크로초 지연 달성에도 부적합합니다.

- D. ElastiCache for Redis는 일반 캐시로 사용할 수 있으나 DynamoDB 인지(Cache invalidation, 일관성, API 호환)가 없어 애플리케이션 변경과 운영 복잡도가 큽니다. DAX보다 통합/운영 효율이 떨어집니다.


## #579
한 회사가 Amazon RDS for PostgreSQL을 사용하는 애플리케이션을 운영하고 있습니다.  
이 애플리케이션은 평일 근무 시간 동안에만 트래픽을 받습니다.  
회사는 이러한 사용 패턴에 따라 비용을 최적화하고 운영 오버헤드를 줄이기를 원합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Instance Scheduler를 사용하여 시작 및 중지 일정을 구성합니다.  
B. 자동 백업을 끕니다. 데이터베이스의 주간 수동 스냅샷을 생성합니다.  
C. 최소 CPU 사용률을 기준으로 데이터베이스를 시작 및 중지하는 사용자 정의 AWS Lambda 함수를 생성합니다.  
D. All Upfront 예약형 DB 인스턴스를 구매합니다.

```
A company runs an application that uses Amazon RDS for PostgreSQL. The application receives traffic only on weekdays during business hours. The company wants to optimize costs and reduce operational overhead based on this usage.  
  
Which solution will meet these requirements?

- A. Use the Instance Scheduler on AWS to configure start and stop schedules.
- B. Turn off automatic backups. Create weekly manual snapshots of the database.
- C. Create a custom AWS Lambda function to start and stop the database based on minimum CPU utilization.
- D. Purchase All Upfront reserved DB instances.
```

정답 : `A`

- Instance Scheduler on AWS는 RDS 인스턴스(및 EC2 포함)에 대해 자동 시작/중지 스케줄을 설정할 수 있는 솔루션
- 트래픽이 없는 주말 및 근무 외 시간대에는 인스턴스를 자동으로 중지하고, 평일 근무 시간에만 실행되도록 하여 비용 절감과 운영 자동화를 동시에 달성

오답 이유

- B. 백업 설정을 끄면 비용 절감 효과는 미미하며, 장애 복구(RTO/RPO)가 악화됩니다. 사용 시간대 기반의 자동화 절감 효과와 무관합니다.

- C. CPU 사용률 기반의 Lambda 제어는 비표준적이며, RDS API 호출/모니터링 로직을 직접 구현해야 합니다. 관리 복잡도와 운영 오버헤드가 증가합니다.

- D. 예약형 인스턴스(RI)는 1년 또는 3년 단위의 상시 실행 워크로드에 적합하며, 평일 근무시간 전용 사용에는 비효율적입니다. 오히려 비용 낭비로 이어질 수 있습니다.


## #580
한 회사는 온프레미스에서 지연 시간에 민감한 애플리케이션을 로컬로 연결된 스토리지로 실행하고 있습니다. 회사는 리프트 앤 시프트(lift and shift) 방식으로 애플리케이션을 AWS 클라우드로 이전하고 있습니다. 회사는 애플리케이션 아키텍처를 변경하고 싶지 않습니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

A. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. 애플리케이션을 실행하기 위해 Amazon FSx for Lustre 파일 시스템을 사용합니다.
B. 애플리케이션을 Amazon EC2 인스턴스에서 호스팅합니다. 애플리케이션을 실행하기 위해 Amazon Elastic Block Store(Amazon EBS) GP2 볼륨을 사용합니다.
C. Amazon EC2 인스턴스로 Auto Scaling 그룹을 구성합니다. 애플리케이션을 실행하기 위해 Amazon FSx for OpenZFS 파일 시스템을 사용합니다.
D. 애플리케이션을 Amazon EC2 인스턴스에서 호스팅합니다. 애플리케이션을 실행하기 위해 Amazon Elastic Block Store(Amazon EBS) GP3 볼륨을 사용합니다.

```
A company uses locally attached storage to run a latency-sensitive application on premises. The company is using a lift and shift method to move the application to the AWS Cloud. The company does not want to change the application architecture.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for Lustre file system to run the application.
- B. Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP2 volume to run the application.
- C. Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for OpenZFS file system to run the application.
- D. Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP3 volume to run the application.
```

정답 : `D`

- 지연 시간에 민감한 워크로드를 아키텍처 변경 없이 리프트 앤 시프트하려면 EC2에 로컬 염결 블록 스토리지를 붙이는 것이 가장 단순하고 지연이 낮음
- gp3는 gp2 대비 GB당 비용이 더 저렴하고, 용량과 무관하게 IOPS/처리량을 독립적으로 프로비저닝할 수 있어 성능/비용 최적화가 쉬움

오답 이유

- A. FSx for Lustre는 HPC/대규모 병렬 처리 및 S3 데이터 세트에 최적화된 네트워크 파일 시스템으로, 로컬 블록 스토리지 대비 네트워크 홉으로 인한 지연이 증가하고 비용도 더 큽니다. 단순 리프트 앤 시프트에 과도합니다.

- B. gp2는 성능이 볼륨 크기에 종속되고, gp3보다 GB당 비용이 높습니다. 동작은 가능하지만 "가장 비용 효율적" 기준에서 gp3보다 열립니다.

- C. FSx for OpenZFS는 스냅샷/복제 등 파일 시스템 기능이 풍부하지만 네트워크 파일 시스템이므로 지연 측면에서 로컬 블록 스토리지보다 불리하고 비용도 더 큽니다. 요구사항에 비해 과도한 솔루션입니다.