---
created: 2025-10-16 09:24:46
last_modified: 2025-10-16 11:29:52
---
## #501
회사는 고객 결제 데이터를 Amazon S3에 있는 회사의 데이터 레이크로 수집하려고 합니다. 회사는 평균적으로 매분 결제 데이터를 수신합니다. 회사는 결제 데이터를 실시간으로 분석하고자 합니다. 그런 다음 회사를 데이터 레이크로 데이터를 수집하려고 합니다.

이 요구 사항을 가장 운영 효율적으로 충족하는 솔루션은 무엇입니까?

A. Amazon Kinesis Data Streams를 사용하여 데이터를 수집한다. AWS Lambda를 사용하여 데이터를 실시간으로 분석한다.
B. AWS Glue를 사용하여 데이터를 수집한다. Amazon Kinesis Data Analytics를 사용하여 데이터를 실시간으로 분석한다.
C. Amazon Kinesis Data Firehose를 사용하여 데이터를 수집한다. Amazon Kinesis Data Analytics를 사용하여 데이터를 실시간으로 분석한다.
D. Amazon API Gateway를 사용하여 데이터를 수집한다. AWS Lambda를 사용하여 데이터를 실시간으로 분석한다.

```
A company wants to ingest customer payment data into the company's data lake in Amazon S3. The company receives payment data every minute on average. The company wants to analyze the payment data in real time. Then the company wants to ingest the data into the data lake.  
  
Which solution will meet these requirements with the MOST operational efficiency?

- A. Use Amazon Kinesis Data Streams to ingest data. Use AWS Lambda to analyze the data in real time.
- B. Use AWS Glue to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time.
- C. Use Amazon Kinesis Data Firehose to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time.
- D. Use Amazon API Gateway to ingest data. Use AWS Lambda to analyze the data in real time.
```

정답 : `C`

- Kinesis Data Firehose는 완전관리형으로 S3로의 자동 배치 및 재시도/버퍼링/압축/암호화를 제공하여 데이터 레이크 적재를 가장 쉽게 처리
- Kinesis Data Analytics는 스트림을 실시간으로 분석/집계하고, 결과를 Firehose나 S3 등으로 보낼 수 있어 실시간 분석 → 데이터 레이크 적재 흐름을 운영 최소화로 구현
- 매분 단위의 연속 유입은 배치보다 스트리밍 파이프라인이 적합하며, 운영 오버헤드가 가장 낮은 조합은 Firehose + KDA

오답 이유

- **A. Kinesis Data Streams + Lambda 실시간 분석**
    - 가능은 하지만 **샤드 수 관리/스케일링/컨슈머 코드 운영** 등 운영 부담이 큽니다.
    - S3 적재를 위해 별도 Firehose 연동 또는 S3 쓰기 코드를 직접 관리해야 함(운영 효율 ↓).
    
- **B. AWS Glue + Kinesis Data Analytics**
    - **Glue는 주로 ETL/배치/스키마 메타데이터(Glue Data Catalog)** 중심으로, **실시간 수집 엔드포인트**로 적합하지 않습니다.
    - 스트리밍 Glue 작업도 있으나 본 시나리오에서 **수집 계층으로 Glue를 전면 채택**하는 것은 일반적/최소운영 해법이 아님.
    
- **D. API Gateway + Lambda**
    - API 기반 동기 호출은 **스트리밍 대량 수집**에 비해 비용/확장성/스루풋 측면에서 비효율적입니다.
    - 이벤트 스트림 처리/버퍼링/재시도/배치 전달 등 **스트리밍 필수 기능이 부족**합니다.


## #502
한 회사가 Amazon EC2에서 콘텐츠 관리 시스템(CMS)을 사용하는 웹사이트를 운영하고 있습니다. CMS는 단일 EC2 인스턴스에서 실행되며 데이터 계층으로 Amazon Aurora MySQL Multi-AZ DB 인스턴스를 사용합니다. 웹사이트 이미지는 EC2 인스턴스 내부에 마운트된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장되어 있습니다.

웹사이트의 성능과 탄력성을 향상시키기 위해 솔루션스 아키텍트가 취해야 할 작업의 조합은 무엇입니까? (두 개 선택)

A. 모든 EC2 인스턴스에 마운트된 Amazon S3 버킷으로 웹사이트 이미지를 이동한다.
B. 기본 EC2 인스턴스에서 NFS 공유를 사용하여 웹사이트 이미지를 공유한다. 이 공유를 다른 EC2 인스턴스에 마운트한다.
C. 모든 EC2 인스턴스에 마운트된 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 웹사이트 이미지를 이동한다.
D. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성한다. 이 AMI를 사용하여 Auto Scaling 그룹의 일부로 애플리케이션 로드 밸런서 뒤에 새로운 인스턴스를 프로비저닝한다. Auto Scaling 그룹이 최소 두 개의 인스턴스를 유지하도록 구성한다. 웹사이트를 위해 AWS Global Accelerator에서 가속기를 구성한다.
E. 기존 EC2 인스턴스에서 Amazon 머신 이미지(AMI)를 생성한다. 이 AMI를 사용하여 Auto Scaling 그룹의 일부로 애플리케이션 로드 밸런서 뒤에 새로운 인스턴스를 프로비저닝한다. Auto Scaling 그룹이 최소 두 개의 인스턴스를 유지하도록 구성한다. 웹사이트를 위해 Amazon CloudFront 배포를 구성한다.

```
A company runs a website that uses a content management system (CMS) on Amazon EC2. The CMS runs on a single EC2 instance and uses an Amazon Aurora MySQL Multi-AZ DB instance for the data tier. Website images are stored on an Amazon Elastic Block Store (Amazon EBS) volume that is mounted inside the EC2 instance.  
  
Which combination of actions should a solutions architect take to improve the performance and resilience of the website? (Choose two.)

- A. Move the website images into an Amazon S3 bucket that is mounted on every EC2 instance
- B. Share the website images by using an NFS share from the primary EC2 instance. Mount this share on the other EC2 instances.
- C. Move the website images onto an Amazon Elastic File System (Amazon EFS) file system that is mounted on every EC2 instance.
- D. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an accelerator in AWS Global Accelerator for the website
- E. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an Amazon CloudFront distribution for the website.
```

정답 : `C, E`

- C: 단일 EBS에 이미지를 저장하면 인스턴스 로컬 종속성과 단일 장애 지점(SPOF)이 된다.
	- Amazon EFS는 다중 AZ에 걸친 완전관리형 NFS로, 여러 EC2가 동시에 마운드 가능하고 탄력적으로 확장
- E: ALB + Auto Scaling(최소 2대)로 웹 계층의 고가용성/자동 복구 확보
	- CloudFront는 정적 콘텐츠 캐싱으로 전 세계 엣지에서 응답, 지연 감소 및 오리진 부하 감소 → 성능과 복원력 동시 향상

오답 이유

**A. S3를 마운트하여 사용**
- S3는 **객체 스토리지**이며 네이티브 POSIX 파일시스템이 아님. s3fs 같은 FUSE는 운영·성능·일관성 이슈가 있어 **웹 앱의 공유 파일 저장소 대체로 권장되지 않음**. EFS가 정답.

**B. 기본 EC2에서 NFS 공유**
- 기본 인스턴스가 **단일 장애 지점**이 되어 가용성과 확장성 저하. 또한 운영 관리 부담(패치, 스토리지 증설, 성능 튜닝) 증가. **EFS의 다중 AZ 관리형 NFS**가 더 적합.

**D. ALB+ASG+Global Accelerator*
- GA는 **비캐시 동적 트래픽의 글로벌 가속**에 유효하지만, 이 시나리오의 핵심 병목인 **정적 이미지 오프로드/캐싱**을 해결하지 못함(캐시 X). CloudFront가 **성능·비용·부하 감소** 측면에서 더 적합.


## #503
한 회사가 인프라 모니터링 서비스를 운영하고 있습니다.  
회사는 고객의 AWS 계정 내 데이터를 모니터링할 수 있는 새로운 기능을 개발 중입니다.  
이 새로운 기능은 고객 계정의 AWS API를 호출하여 Amazon EC2 인스턴스를 조회(describe)하고,  
Amazon CloudWatch 메트릭을 읽을(read) 것입니다.

회사가 고객 계정에 접근하기 위해 가장 보안적인 방법은 무엇입니까?

A. 고객이 자신의 계정에 EC2 및 CloudWatch 읽기 전용 권한을 가진 IAM 역할을 생성하고, 회사 계정을 신뢰(trust)하도록 트러스트 정책을 구성하도록 한다.  
B. 읽기 전용 EC2 및 CloudWatch 권한을 가진 역할에 대해 임시 AWS 자격 증명을 제공하는 토큰 발급기(token vending machine)를 구현하는 서버리스 API를 생성한다.  
C. 고객이 자신의 계정에 EC2 및 CloudWatch 읽기 전용 권한을 가진 IAM 사용자를 생성하도록 하고, 해당 사용자의 액세스 키와 비밀 키를 암호화하여 비밀 관리 시스템에 저장한다.  
D. 고객이 자신의 계정에 Amazon Cognito 사용자를 생성하여 EC2 및 CloudWatch 읽기 전용 권한을 가진 IAM 역할을 사용하도록 하고, Amazon Cognito 사용자 이름과 비밀번호를 암호화하여 비밀 관리 시스템에 저장한다.

```
A company runs an infrastructure monitoring service. The company is building a new feature that will enable the service to monitor data in customer AWS accounts. The new feature will call AWS APIs in customer accounts to describe Amazon EC2 instances and read Amazon CloudWatch metrics.  
  
What should the company do to obtain access to customer accounts in the MOST secure way?

- A. Ensure that the customers create an IAM role in their account with read-only EC2 and CloudWatch permissions and a trust policy to the company’s account.
- B. Create a serverless API that implements a token vending machine to provide temporary AWS credentials for a role with read-only EC2 and CloudWatch permissions.
- C. Ensure that the customers create an IAM user in their account with read-only EC2 and CloudWatch permissions. Encrypt and store customer access and secret keys in a secrets management system.
- D. Ensure that the customers create an Amazon Cognito user in their account to use an IAM role with read-only EC2 and CloudWatch permissions. Encrypt and store the Amazon Cognito user and password in a secrets management system.
```

정답 : `A`

- 가장 보안적이고 권장되는 방식은 고객 계정에 IAM 역할을 생성하고, 회사의 AWS 계정을 신뢰 주체로 설정해 크로스 계정 액세스를 제공하는 것
- 이 방식에서는 회사 계정의 서비스가 AssumeRole API를 통해 임시 보안 자격 증명(STS)을 얻어 고객 리소스로 접근
- 장점
	- 장기 자격 증명(Access Key, Secret Key)을 저장하지 않아 보안 위험 없음
	- 고객이 언제든 신뢰 관계 해제 가능(권한 위임 철회 용이)
	- 최소 권한 정책만 부여 가능
	- AWS가 공식적으로 권장하는 멀티 계정 간 안전한 접근 패턴

오답 이유

**B. Token vending machine (임시 자격 증명 제공 API)**
- 자체 구현 시 **보안·운영 부담**이 매우 크며, AWS가 이미 STS를 통해 임시 자격 증명을 안전하게 제공하기 때문에 불필요합니다.
- 또한, 고객 계정에서 직접 IAM 역할을 신뢰하도록 하는 것이 더 단순하고 표준화된 접근입니다.
  

**C. 고객이 IAM 사용자 생성 후 Access Key 전달**
- **보안상 매우 위험**: 장기 자격 증명(Access Key, Secret Key)은 유출 위험이 크고, **회사가 고객 키를 저장하는 행위는 AWS 보안 모범 사례에 위배**됩니다.
- 키 교체/로테이션 관리도 어려움.

**D. Cognito 사용자 생성 후 자격 증명 저장**
- Cognito는 **애플리케이션 사용자 인증용 서비스**이지, 계정 간 AWS 리소스 접근을 위한 도구가 아닙니다.
- 자격 증명을 저장하는 것은 여전히 보안 위험을 증가시킴.


## #504
회사는 us-east-1 리전에 있는 수백 개의 AWS 계정에 걸친 여러 VPC를 서로 연결해야 합니다. 회사의 네트워킹 팀은 클라우드 네트워크를 관리하기 위한 전용 AWS 계정을 보유하고 있습니다.

VPC들을 연결하기 위한 가장 운영 효율적인 솔루션은 무엇입니까?

A. 각 VPC 간에 VPC 피어링 연결을 설정한다. 각 관련 서브넷의 라우팅 테이블을 업데이트한다.
B. 각 VPC에 NAT 게이트웨이와 인터넷 게이트웨이를 구성하여 인터넷을 통해 각 VPC를 연결한다.
C. 네트워킹 팀의 AWS 계정에 AWS Transit Gateway를 생성한다. 각 VPC에서 정적 라우트를 구성한다.
D. 각 VPC에 VPN 게이트웨이를 배포한다. 네트워킹 팀의 AWS 계정에 트랜짓 VPC를 생성하여 각 VPC에 연결한다.

```
A company needs to connect several VPCs in the us-east-1 Region that span hundreds of AWS accounts. The company's networking team has its own AWS account to manage the cloud network.  
  
What is the MOST operationally efficient solution to connect the VPCs?

- A. Set up VPC peering connections between each VPC. Update each associated subnet’s route table
- B. Configure a NAT gateway and an internet gateway in each VPC to connect each VPC through the internet
- C. Create an AWS Transit Gateway in the networking team’s AWS account. Configure static routes from each VPC.
- D. Deploy VPN gateways in each VPC. Create a transit VPC in the networking team’s AWS account to connect to each VPC.
```

정답 : `C`

- AWS Transit Gateway(TGW)는 대규모 다계정･다VPC 연결을 중앙집중식으로 관리하는 가장 운영 효율적인 방법
- TGW를 네트워킹 계정에 생성하고 AWS RAM으로 공유한 뒤 각 계정의 VPC를 Attachment로 연결하면, 메시 복잡도 없이 단일 허브에서 라우팅 정책을 제어 가능
- 라우트는 VPC 라우팅 테이블에 TGW를 향한 정적 경로를 추가하고, TGW 라우팅 테이블에서도 필요한 경로를 구성･전파하여 규모 확장과 운영 자동화를 쉽게 달성

오답 이유

- **A. VPC 피어링**
    - 피어링은 **풀 메시 구조**로 수백 VPC에 대해 **연결 수가 기하급수적으로 증가**합니다(관리 지옥).
    - **트랜짓 라우팅 미지원**으로 허브-스포크 구성이 불가하며 운영 효율이 매우 낮습니다.
    
- **B. NAT + IGW로 인터넷 경유 연결**
    - VPC 간 트래픽을 **인터넷으로 우회**시키는 것은 **보안·비용·성능** 측면에서 부적절합니다.
    - 사설 IP 기반의 **프라이빗 라우팅 요구**를 충족하지 못합니다.
    
- **D. VPN 게이트웨이 + 트랜짓 VPC**
    - 과거 우회 해법으로 **IPSec 터널 관리, 라우팅, HA** 등 운영 오버헤드가 큽니다.
    - **관리형 허브**인 TGW가 등장한 이후 권장되지 않는 패턴입니다(비용·복잡도 ↑).


## #505
회사는 데이터를 처리하기 위한 야간 배치 작업을 실행하는 Amazon EC2 인스턴스를 보유하고 있습니다. EC2 인스턴스는 온디맨드 과금을 사용하는 Auto Scaling 그룹에서 실행됩니다. 한 인스턴스에서 작업이 실패하면 다른 인스턴스가 해당 작업을 재처리합니다. 배치 작업은 매일 현지 시간으로 오전 12:00부터 오전 06:00 사이에 실행됩니다.

이 요구 사항을 가장 비용 효율적으로 충족할 수 있는 솔루션은 무엇입니까?

A. 배치 작업이 사용하는 Auto Scaling 그룹의 인스턴스 패밀리를 커버하는 1년 약정 Savings Plan을 구매한다.
B. Auto Scaling 그룹의 인스턴스에서 사용하는 특정 인스턴스 유형 및 운영 체제에 대해 1년 약정 예약 인스턴스를 구매한다.
C. Auto Scaling 그룹을 위한 새로운 시작 템플릿을 생성한다. 인스턴스를 스팟 인스턴스로 설정한다. CPU 사용률을 기준으로 스케일 아웃 정책을 설정한다.
D. Auto Scaling 그룹을 위한 새로운 시작 템플릿을 생성한다. 인스턴스 크기를 늘린다. CPU 사용률을 기준으로 스케일 아웃 정책을 설정한다.

```
A company has Amazon EC2 instances that run nightly batch jobs to process data. The EC2 instances run in an Auto Scaling group that uses On-Demand billing. If a job fails on one instance, another instance will reprocess the job. The batch jobs run between 12:00 AM and 06:00 AM local time every day.  
  
Which solution will provide EC2 instances to meet these requirements MOST cost-effectively?

- A. Purchase a 1-year Savings Plan for Amazon EC2 that covers the instance family of the Auto Scaling group that the batch job uses.
- B. Purchase a 1-year Reserved Instance for the specific instance type and operating system of the instances in the Auto Scaling group that the batch job uses.
- C. Create a new launch template for the Auto Scaling group. Set the instances to Spot Instances. Set a policy to scale out based on CPU usage.
- D. Create a new launch template for the Auto Scaling group. Increase the instance size. Set a policy to scale out based on CPU usage.
```

정답 : `C`

- 배치 작업 시간은 시간 제한(매일 00시~06시)이고, 실패 시 재처리 가능하므로 중단 가능(인터럽션 허용) 워크로드
- 이러한 특성에는 EC2 스팟 인스턴스가 최적이며, 오토스케일링과 함께 사용하면 필요한 시간 동안만 확장해 가장 낮은 비용으로 용량 확보
- CPU 기반 스케일 아웃은 배치 부하에 맞춰 동적으로 용량을 조절해 비용 절약

오답 이유

- **A. 1년 Savings Plan(Compute/EC2)**
    - Savings Plan은 **지속적·예측 가능한 사용량**에 유리하며, **하루 6시간만 쓰는 간헐적 배치**에는 할인 이점이 제한적입니다. 스팟 대비 비용 효율이 떨어집니다.

- **B. 1년 예약 인스턴스(RI)**
    - RI 역시 **상시 사용**을 전제로 한 할인 모델입니다. 사용 시간이 짧고 가용 시간대가 명확한 배치에는 부적합하며, 스팟 대비 비용 효율이 낮습니다.

- **D. 인스턴스 크기 증가 + CPU 스케일 아웃**
    - 인스턴스 크기를 키우면 **시간당 비용이 상승**합니다. 요구 성능을 충족하는 최소 사양의 스팟 인스턴스를 수평 확장하는 편이 **비용 효율**이 훨씬 높습니다.


## #506
한 소셜 미디어 회사가 웹사이트에 새로운 기능을 구축하고 있습니다. 이 기능은 사용자가 사진을 업로드할 수 있는 기능을 제공합니다. 회사는 대형 이벤트 동안 수요가 크게 증가할 것으로 예상하며, 웹사이트가 사용자의 업로드 트래픽을 처리할 수 있도록 해야 합니다.

이 요구 사항을 가장 확장성 있게 충족하는 솔루션은 무엇입니까?

A. 사용자의 브라우저에서 애플리케이션 서버로 파일을 업로드한다. 그런 다음 파일을 Amazon S3 버킷으로 전송한다.
B. AWS Storage Gateway 파일 게이트웨이를 프로비저닝한다. 사용자의 브라우저에서 파일 게이트웨이로 파일을 직접 업로드한다.
C. 애플리케이션에서 Amazon S3 프리사인드 URL을 생성한다. 사용자의 브라우저에서 S3 버킷으로 직접 파일을 업로드한다.
D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝한다. 사용자의 브라우저에서 파일 시스템으로 직접 업로드한다.

```
A social media company is building a feature for its website. The feature will give users the ability to upload photos. The company expects significant increases in demand during large events and must ensure that the website can handle the upload traffic from users.  
  
Which solution meets these requirements with the MOST scalability?

- A. Upload files from the user's browser to the application servers. Transfer the files to an Amazon S3 bucket.
- B. Provision an AWS Storage Gateway file gateway. Upload files directly from the user's browser to the file gateway.
- C. Generate Amazon S3 presigned URLs in the application. Upload files directly from the user's browser into an S3 bucket.
- D. Provision an Amazon Elastic File System (Amazon EFS) file system. Upload files directly from the user's browser to the file system.
```

정답 : `C`

- S3는 자동으로 수평 확장되는 객체 스토리지로 대규모 동시 업로드 스파이크에 적합
- 프리사인드 URL을 사용하면 애플리케이션 서버를 데이터 경로에서 제거(offload)하여 서버 병목과 네트워크 비용을 피하고
	- 클라이언트가 S3로 직접 PUT/멀티파트 업로드 수행 가능
- 서버는 인증/권한 부여 로직만 수행하므로 가장 높은 확장성 제공

오답 이유

- **A. 브라우저 → 앱 서버 → S3**
    - 애플리케이션 서버가 **병목/단일 장애 지점**이 됩니다. 스파이크 시 서버/네트워크 스케일링 비용과 복잡도가 커집니다.
    
- **B. Storage Gateway 파일 게이트웨이**
    - 온프레미스 NFS/SMB를 S3로 백업/동기화하는 **하이브리드 스토리지** 용도입니다. 브라우저가 직접 업로드할 **HTTP 엔드포인트가 아닙니다.**
    
- **D. EFS로 직접 업로드**
    - EFS는 **NFS 파일시스템**으로 브라우저가 직접 접근할 수 없습니다. 또한 인터넷 공개용이 아니며, 웹 대규모 업로드에 적합하지 않습니다.


## #507
한 회사는 여행 티켓팅을 위한 웹 애플리케이션을 보유하고 있습니다. 애플리케이션은 북미의 단일 데이터 센터에서 실행되는 데이터베이스에 기반합니다. 회사는 애플리케이션을 전 세계 사용자 기반에 제공하기 위해 확장하려고 합니다. 회사는 애플리케이션을 여러 AWS 리전에 배포해야 합니다. 예약 데이터베이스에 대한 업데이트의 평균 지연 시간은 1초 미만이어야 합니다.

회사는 여러 리전에 걸쳐 웹 플랫폼을 각각 별도로 배포하고자 합니다. 그러나 회사는 전역적으로 일관된 단일 기본(primary) 예약 데이터베이스를 유지해야 합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 솔루션을 권장해야 합니까?

A. 애플리케이션을 Amazon DynamoDB를 사용하도록 변환한다. 중앙 예약 테이블에 대해 글로벌 테이블을 사용한다. 각 리전 배포에서 올바른 리전 엔드포인트를 사용한다.
B. 데이터베이스를 Amazon Aurora MySQL 데이터베이스로 마이그레이션한다. 각 리전에 Aurora 읽기 복제본을 배포한다. 각 리전 배포에서 데이터베이스에 접근하기 위해 올바른 리전 엔드포인트를 사용한다.
C. 데이터베이스를 Amazon RDS for MySQL 데이터베이스로 마이그레이션한다. 각 리전에 MySQL 읽기 복제본을 배포한다. 각 리전 배포에서 데이터베이스에 접근하기 위해 올바른 리전 엔드포인트를 사용한다.
D. 애플리케이션을 Amazon Aurora Serverless 데이터베이스로 마이그레이션한다. 각 리전에 데이터베이스 인스턴스를 배포한다. 각 리전 배포에서 데이터베이스에 접근하기 위해 올바른 리전 엔드포인트를 사용한다. 각 리전에서 데이터베이스를 동기화하기 위해 AWS Lambda 함수를 사용하여 이벤트 스트림을 처리한다.

```
A company has a web application for travel ticketing. The application is based on a database that runs in a single data center in North America. The company wants to expand the application to serve a global user base. The company needs to deploy the application to multiple AWS Regions. Average latency must be less than 1 second on updates to the reservation database.  
  
The company wants to have separate deployments of its web platform across multiple Regions. However, the company must maintain a single primary reservation database that is globally consistent.  
  
Which solution should a solutions architect recommend to meet these requirements?

- A. Convert the application to use Amazon DynamoDB. Use a global table for the center reservation table. Use the correct Regional endpoint in each Regional deployment.
- B. Migrate the database to an Amazon Aurora MySQL database. Deploy Aurora Read Replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.
- C. Migrate the database to an Amazon RDS for MySQL database. Deploy MySQL read replicas in each Region. Use the correct Regional endpoint in each Regional deployment for access to the database.
- D. Migrate the application to an Amazon Aurora Serverless database. Deploy instances of the database to each Region. Use the correct Regional endpoint in each Regional deployment to access the database. Use AWS Lambda functions to process event streams in each Region to synchronize the databases.
```

정답 : `B`

- Aurora MySQL Global Database(글로벌 데이터베이스) 구성은 한 리전을 유일한 writer(Primary)로 두고, 다른 리전에는 릭기 전용 클러스터(읽기 복제본)를 배치
- Aurora Global Database는 스토리지 레벨 단방향 복제로 전송되어 전형적인 서브초 지연을 달성
- 선택지 B의 "각 리전에 Aurora 읽기 복제본"은 사실상 Aurora Global Database의 세컨더리 클러스터 배치를 의미, 각 리전 애플리케이션은 해당 리전 엔드포인트(읽기/쓰기 분리) 사용

오답 이유

- **A. DynamoDB 글로벌 테이블**
    - 글로벌 테이블은 **멀티 리전 멀티 라이터**로, 단일 Primary 유지 요건과 상충합니다. 또한 **최종적 일관성** 패턴이 기본이며, “단일 Primary로 전역 일관성 유지”라는 요구와 맞지 않습니다.
    
- **C. RDS for MySQL + 리전 간 읽기 복제본**
    - 전통적인 MySQL 복제는 **비동기**로 지연이 **초 단위를 넘길 수** 있어 평균 <1초 목표를 안정적으로 보장하기 어렵습니다. 스토리지 레벨 복제를 제공하는 **Aurora Global Database**가 적합합니다.
    
- **D. Aurora Serverless + Lambda 동기화**
    - 리전 간 DB 동기화를 **애플리케이션/람다**로 구현하는 것은 **데이터 일관성·지연·운영 복잡도** 측면에서 부적절합니다. 또한 Serverless v2라도 **글로벌 동기화 네이티브 기능**은 Aurora Global Database만큼의 보장(서브초 레플리케이션/Failover 특성)을 제공하지 않습니다.


## #508
한 회사는 여러 Microsoft Windows Server 워크로드를 us-west-1 리전의 Amazon EC2 인스턴스로 마이그레이션했습니다. 회사는 필요할 때 수동으로 백업하여 이미지를 생성합니다.

us-west-1 리전에 자연 재해가 발생할 경우, 회사는 us-west-2 리전에서 빠르게 워크로드를 복구하고자 합니다. 회사는 EC2 인스턴스에서 데이터 손실을 24시간 이하로 제한하고자 합니다. 또한 EC2 인스턴스의 모든 백업을 자동화하고자 합니다.

가장 관리 노력이 적은(LEAST administrative effort) 솔루션 조합은 무엇입니까? (두 개 선택)

A. 태그 기반으로 백업을 생성하기 위해 Amazon EC2 지원 Amazon Machine Image(AMI) 수명 주기 정책을 생성한다. 백업이 하루 두 번 실행되도록 스케줄링한다. 필요 시 이미지를 복사한다.
B. 태그 기반으로 백업을 생성하기 위해 Amazon EC2 지원 Amazon Machine Image(AMI) 수명 주기 정책을 생성한다. 백업이 하루 두 번 실행되도록 스케줄링한다. us-west-2 리전으로 복사를 구성한다.
C. AWS Backup을 사용하여 us-west-1과 us-west-2에 백업 볼트를 생성한다. 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성한다. us-west-2로 백업 데이터를 복사하기 위해 예약 작업으로 실행되는 AWS Lambda 함수를 생성한다.
D. AWS Backup을 사용하여 백업 볼트를 생성한다. 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성한다. 복사 대상 리전을 us-west-2로 지정한다. 백업 스케줄을 하루 두 번 실행되도록 지정한다.
E. AWS Backup을 사용하여 백업 볼트를 생성한다. 태그 값을 기반으로 EC2 인스턴스에 대한 백업 계획을 생성한다. 백업 스케줄을 하루 두 번 실행되도록 지정한다. 필요 시 us-west-2로 복사한다.

```
A company has migrated multiple Microsoft Windows Server workloads to Amazon EC2 instances that run in the us-west-1 Region. The company manually backs up the workloads to create an image as needed.  
  
In the event of a natural disaster in the us-west-1 Region, the company wants to recover workloads quickly in the us-west-2 Region. The company wants no more than 24 hours of data loss on the EC2 instances. The company also wants to automate any backups of the EC2 instances.  
  
Which solutions will meet these requirements with the LEAST administrative effort? (Choose two.)

- A. Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand.
- B. Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region.
- C. Create backup vaults in us-west-1 and in us-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2.
- D. Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily.
- E. Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2.
```

정답 : `B, D`

- B: Data Lifecycle Manager(DLM)를 이용한 태그 기반 AMI 자동 생성 + us-west-2로 자동 복사로 RPO(1일 2회 → 최대 12시간) 충족
- D: AWS Backup의 EC2 워크로드 지원을 활용해 태그 기반, 스케줄(1일 2회), us-west-2로 자동 복사까지 한 번에 구성 가능

오답 이유

- **A**: 크로스리전 복사를 “필요 시(on demand)”로 수행 → **수동 작업**이 남아 **자동화 요건 미충족**. DR 대비의 일관성 부족.
    
- **C**: AWS Backup 자체가 **크로스리전 자동 복사**를 지원하는데도 **Lambda로 별도 복사 로직**을 추가 → **불필요한 운영 복잡도** 증가.
    
- **E**: 스케줄은 자동화하나 **복사는 수동(on demand)** → DR 준비 자동화 미흡.


## #509
한 회사가 이미지 처리용 2계층 애플리케이션을 운영하고 있습니다.  
이 애플리케이션은 두 개의 가용 영역(Availability Zone)을 사용하며, 각 AZ에는 하나의 퍼블릭 서브넷과 하나의 프라이빗 서브넷이 있습니다.  
웹 계층용 Application Load Balancer(ALB)는 퍼블릭 서브넷을 사용하고,  
애플리케이션 계층의 Amazon EC2 인스턴스는 프라이빗 서브넷을 사용합니다.

사용자들은 애플리케이션이 예상보다 느리게 작동한다고 보고했습니다.  
웹 서버 로그의 보안 감사 결과, 소수의 IP 주소에서 수백만 건의 불법 요청이 들어오고 있음이 확인되었습니다.  
솔루션스 아키텍트는 회사가 장기적인 해결책을 조사하는 동안 **즉각적인 성능 문제를 해결해야 합니다.**

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 권장해야 합니까?

A. 웹 계층의 인바운드 보안 그룹을 수정한다. 리소스를 소비하는 IP 주소에 대해 거부(deny) 규칙을 추가한다.  
B. 웹 계층 서브넷의 네트워크 ACL을 수정한다. 리소스를 소비하는 IP 주소에 대해 인바운드 거부(deny) 규칙을 추가한다.  
C. 애플리케이션 계층의 인바운드 보안 그룹을 수정한다. 리소스를 소비하는 IP 주소에 대해 거부(deny) 규칙을 추가한다.  
D. 애플리케이션 계층 서브넷의 네트워크 ACL을 수정한다. 리소스를 소비하는 IP 주소에 대해 인바운드 거부(deny) 규칙을 추가한다.

```
A company operates a two-tier application for image processing. The application uses two Availability Zones, each with one public subnet and one private subnet. An Application Load Balancer (ALB) for the web tier uses the public subnets. Amazon EC2 instances for the application tier use the private subnets.  
  
Users report that the application is running more slowly than expected. A security audit of the web server log files shows that the application is receiving millions of illegitimate requests from a small number of IP addresses. A solutions architect needs to resolve the immediate performance problem while the company investigates a more permanent solution.  
  
What should the solutions architect recommend to meet this requirement?

- A. Modify the inbound security group for the web tier. Add a deny rule for the IP addresses that are consuming resources.
- B. Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.
- C. Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources.
- D. Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources.
```

정답 : `B`

- ALB가 퍼블릭 서브넷에 있으므로, 공격 트래픽은 퍼블릭 서브넷 레벨에서 들어옴
- AWS 보안 그룹은 "허용(Allow)"만 가능하고, "거부(Deny)" 규칙은 지원하지 않음
- 따라서 특정 IP 주소를 빠르게 차단하려면 서브넷 단위에서 동작하는 네트워크 ACL(NACL)에서 deny 규칙을 추가하는 것이 유일한 방법

오답 이유

- **A. Security Group에 deny rule 추가**
    - 보안 그룹은 _허용 규칙만 존재_하며, 명시적 거부(deny)를 설정할 수 없습니다. 불가능한 접근 방식입니다.
    
- **C. 애플리케이션 계층 SG 수정**
    - 공격 트래픽은 웹 계층(ALB)이 위치한 퍼블릭 서브넷에서 들어오므로,
        애플리케이션 계층(프라이빗 서브넷)에 deny rule을 추가해도 이미 ALB가 공격 트래픽을 수신합니다.
        문제 해결이 되지 않습니다.
    
- **D. 애플리케이션 계층 NACL 수정**
    - 공격 트래픽은 애플리케이션 계층에 도달하기 전인 **웹 계층(ALB)** 에서 발생하므로,
        프라이빗 서브넷(애플리케이션 계층)의 NACL을 수정해도 효과가 없습니다.


## #510
글로벌 마케팅 회사는 ap-southeast-2 리전과 eu-west-1 리전에서 애플리케이션을 운영합니다. eu-west-1의 VPC에서 실행되는 애플리케이션은 ap-southeast-2의 VPC에서 실행되는 데이터베이스와 보안적으로 통신해야 합니다.

이 요구 사항을 충족할 네트워크 설계는 무엇입니까?

- A. eu-west-1 VPC와 ap-southeast-2 VPC 간에 VPC 피어링 연결을 생성한다. eu-west-1 애플리케이션 보안 그룹에 ap-southeast-2 보안 그룹의 데이터베이스 서버 IP 주소에서 오는 트래픽을 허용하는 인바운드 규칙을 생성한다.
- B. ap-southeast-2 VPC와 eu-west-1 VPC 간에 VPC 피어링 연결을 구성한다. 서브넷 라우팅 테이블을 업데이트한다. ap-southeast-2 데이터베이스 보안 그룹에 eu-west-1의 애플리케이션 서버 보안 그룹 ID를 참조하는 인바운드 규칙을 생성한다.
- C. ap-southeast-2 VPC와 eu-west-1 VPC 간에 VPC 피어링 연결을 구성한다. 서브넷 라우팅 테이블을 업데이트한다. ap-southeast-2 데이터베이스 보안 그룹에 eu-west-1 애플리케이션 서버 IP 주소에서 오는 트래픽을 허용하는 인바운드 규칙을 생성한다.
- D. eu-west-1 VPC와 ap-southeast-2 VPC 사이에 트랜짓 게이트웨이를 만들고 피어링 어태치먼트를 구성한다. 트랜짓 게이트웨이가 적절히 피어링되고 라우팅이 구성된 후, 데이터베이스 보안 그룹에 eu-west-1 애플리케이션 서버의 보안 그룹 ID를 참조하는 인바운드 규칙을 생성한다.

```
A global marketing company has applications that run in the ap-southeast-2 Region and the eu-west-1 Region. Applications that run in a VPC in eu-west-1 need to communicate securely with databases that run in a VPC in ap-southeast-2.  
  
Which network design will meet these requirements?

- A. Create a VPC peering connection between the eu-west-1 VPC and the ap-southeast-2 VPC. Create an inbound rule in the eu-west-1 application security group that allows traffic from the database server IP addresses in the ap-southeast-2 security group.
- B. Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPC. Update the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that references the security group ID of the application servers in eu-west-1.
- C. Configure a VPC peering connection between the ap-southeast-2 VPC and the eu-west-1 VPC. Update the subnet route tables. Create an inbound rule in the ap-southeast-2 database security group that allows traffic from the eu-west-1 application server IP addresses.
- D. Create a transit gateway with a peering attachment between the eu-west-1 VPC and the ap-southeast-2 VPC. After the transit gateways are properly peered and routing is configured, create an inbound rule in the database security group that references the security group ID of the application servers in eu-west-1.
```

정답 : `C`

- 리전 간 프라이빗･암호화된 통신에는 인터-리전 VPC 피어링이 적합
- 데이터베이스에 대한 접근 제어는 DB가 속한 보안 그룹에서 해야하므로 DB SG에 규칙을 적용
- 보안 그룹 간 참조는 리전 간에 지원되지 않음. 따라서 eu-west-1의 애플리케이션 서브는 IP(또는 CIDR) 기준으로 허용해야 함
- 피어링 후에는 양쪽 VPC 서브넷 라우팅 테이블에 상대 VPC CIDR로 가는 경로(타깃: VPC 피어링)를 추가해야 통신이 성립

오답 이유

- **A**: 허용 규칙을 애플리케이션 SG(eu-west-1)에 두고 DB에서 오는 트래픽을 허용하는 것은 방향이 반대입니다. 앱이 DB에 접속하므로 **DB SG 쪽에서** 앱 소스를 허용해야 합니다. 또한 SG 간 참조도 리전 간 미지원.
    
- **B**: 라우팅과 피어링은 맞지만 **다른 리전의 SG ID를 참조**하려는 점이 문제입니다. **리전 간 SG 참조 불가**이므로 성립하지 않습니다.
    
- **D**: TGW 피어링은 이 단일 앱 ↔ DB 요구에 **과도한 구성(비용·복잡도↑)** 입니다. 그리고 여기서도 **리전 간 SG 참조 불가** 문제가 남습니다. 간단히 VPC 피어링으로 충분합니다.


## #511
회사는 PostgreSQL 데이터베이스 스키마를 사용하는 소프트웨어를 개발 중입니다. 회사는 개발자들을 위해 여러 개의 개발 환경과 데이터베이스를 구성해야 합니다. 평균적으로 각 개발 환경은 8시간 근무 시간의 절반 동안 사용됩니다.

이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. 각 개발 환경을 자체 Amazon Aurora PostgreSQL 데이터베이스로 구성한다.
B. 각 개발 환경을 자체 Amazon RDS for PostgreSQL 단일 AZ DB 인스턴스로 구성한다.
C. 각 개발 환경을 자체 Amazon Aurora 온디맨드 PostgreSQL 호환 데이터베이스로 구성한다.
D. 각 개발 환경을 Amazon S3 Object Select를 사용하는 자체 Amazon S3 버킷으로 구성한다.

```
A company is developing software that uses a PostgreSQL database schema. The company needs to configure multiple development environments and databases for the company's developers. On average, each development environment is used for half of the 8-hour workday.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Configure each development environment with its own Amazon Aurora PostgreSQL database
- B. Configure each development environment with its own Amazon RDS for PostgreSQL Single-AZ DB instances
- C. Configure each development environment with its own Amazon Aurora On-Demand PostgreSQL-Compatible database
- D. Configure each development environment with its own Amazon S3 bucket by using Amazon S3 Object Select
```

정답 : `C`

- 개발 환경은 하루 약 4시간만 사용 → 간헐적･변동 부하에 최적화된 Aurora Serverless(온디맨드 과금)가 가장 비용 효율적
- Aurora Serverless(Postgre SQL 호환)는 사용 시 초/분 단위로 ACU(용량) 과금하고, 유휴 시 자동 축소/일시 중지로 비용을 최소화할 수 있어 다수 개발 DB를 가장 싸게 운영 가능

오답 이유

- **A. Aurora 프로비저닝(고정 용량)**
    - 항상 프로비저닝된 용량 비용 발생 → **반나절만 쓰는 개발 DB**에는 **비용 낭비**가 큼.
    - 수십 개 환경으로 늘면 고정비 누적.
    
- **B. RDS for PostgreSQL Single-AZ**
    - 온디맨드이지만 **인스턴스 단위 고정 과금**. 자동 일시중지/세밀한 스케일 인이 어려워 **간헐적 사용 시 비효율**.
    - 스케줄 정지 자동화로 완화 가능하나 운영 복잡도↑, 최대 7일 정지 제한 등 제약.
    
- **D. S3 Object Select**
    - **관계형 DB가 아님**. PostgreSQL 스키마/트랜잭션/SQL 기능 요구를 충족하지 못함.
    - 개발 DB 대체 불가.


## #512
회사는 AWS Organizations를 사용하고 있으며, 리소스는 계정별 태그가 지정되어 있습니다. 또한 회사는 AWS Backup을 사용하여 AWS 인프라 리소스를 백업하고 있습니다. 회사는 모든 AWS 리소스를 백업해야 합니다.

가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?

A. AWS Config를 사용하여 태그가 없는 모든 리소스를 식별한다. 식별된 리소스에 프로그래밍 방식으로 태그를 지정한다. 백업 계획에서 태그를 사용한다.
B. AWS Config를 사용하여 실행 중이 아닌 모든 리소스를 식별한다. 해당 리소스를 백업 볼트에 추가한다.
C. 모든 AWS 계정 소유자에게 자신의 리소스를 검토하여 백업이 필요한 리소스를 식별하도록 요구한다.
D. Amazon Inspector를 사용하여 모든 비준수(noncompliant) 리소스를 식별한다.

```
A company uses AWS Organizations with resources tagged by account. The company also uses AWS Backup to back up its AWS infrastructure resources. The company needs to back up all AWS resources.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS Config to identify all untagged resources. Tag the identified resources programmatically. Use tags in the backup plan.
- B. Use AWS Config to identify all resources that are not running. Add those resources to the backup vault.
- C. Require all AWS account owners to review their resources to identify the resources that need to be backed up.
- D. Use Amazon Inspector to identify all noncompliant resources.
```

정답 : `A`

- 주어진 선택지 중에서 운영 오버헤드가 가장 낮은 방법은 태그 기반 백업(리소스 할당)을 쓰는 것
- AWS Config로 미태그 리소스를 탐지한 뒤 프로그램으로 태그를 보정하면, 이후에는 AWS Backup 백업 계획에서 태그 조건 한 번으로 모든 리소스를 자동 포함시킬 수 있어 운영 자동화 가능
- 선택지와 무관하게 이상적인 방법은 AWS Backup과 AWS Organizations의 백업 정책을 사용해 조직/OU 단위로 태그 기반 또는 전체 리소스를 일괄 백업하도록 하는 것

오답 이유

- **B. 실행 중 아님 기준 식별 후 백업 볼트 추가**
    - 리소스가 “실행 중이 아님” 여부는 **백업 대상 선정 기준이 아님**. 또한 Config로 찾은 리소스를 **수동으로 볼트에 추가**하는 흐름은 **운영 복잡**하며 자동화와 거리가 멉니다.
    
- **C. 계정 소유자 수동 검토**
    - **사람 기반 프로세스**는 누락/지연 위험이 크고, 수백/수천 리소스 환경에서 **운영 오버헤드**가 큽니다. “모든 리소스 백업” 보장도 어려움.
    
- **D. Amazon Inspector 사용**
    - Inspector는 **취약점/컴플라이언스 평가** 도구로 **백업 대상 식별**과 무관합니다. 백업 자동화 요건을 충족하지 못합니다.


## #513
한 소셜 미디어 회사는 AWS 클라우드에서 호스팅되는 애플리케이션에서 사용자가 이미지를 업로드할 수 있도록 하려 합니다. 회사는 이미지가 여러 장치 유형에서 표시될 수 있도록 자동으로 크기를 조정하는 솔루션이 필요합니다. 애플리케이션은 하루 종일 예측할 수 없는 트래픽 패턴을 보입니다. 회사는 확장성을 극대화하는 고가용성 솔루션을 찾고 있습니다.

요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Amazon S3에 호스팅된 정적 웹사이트를 생성하여 AWS Lambda 함수를 호출해 이미지를 리사이즈하고, 이미지를 Amazon S3 버킷에 저장한다.
B. Amazon CloudFront에 호스팅된 정적 웹사이트를 생성하여 AWS Step Functions를 호출해 이미지를 리사이즈하고, 이미지를 Amazon RDS 데이터베이스에 저장한다.
C. Amazon EC2 인스턴스에서 실행되는 웹 서버에 동적 웹사이트를 호스팅한다. EC2 인스턴스에서 실행되는 프로세스를 구성하여 이미지를 리사이즈하고, 이미지를 Amazon S3 버킷에 저장한다.
D. 자동으로 확장되는 Amazon Elastic Container Service(Amazon ECS) 클러스터에 동적 웹사이트를 호스팅하여 Amazon Simple Queue Service(Amazon SQS)에 리사이즈 작업을 생성한다. Amazon EC2 인스턴스에서 실행되는 이미지 리사이즈 프로그램을 설정하여 리사이즈 작업을 처리한다.

```
A social media company wants to allow its users to upload images in an application that is hosted in the AWS Cloud. The company needs a solution that automatically resizes the images so that the images can be displayed on multiple device types. The application experiences unpredictable traffic patterns throughout the day. The company is seeking a highly available solution that maximizes scalability.  
  
What should a solutions architect do to meet these requirements?

- A. Create a static website hosted in Amazon S3 that invokes AWS Lambda functions to resize the images and store the images in an Amazon S3 bucket.
- B. Create a static website hosted in Amazon CloudFront that invokes AWS Step Functions to resize the images and store the images in an Amazon RDS database.
- C. Create a dynamic website hosted on a web server that runs on an Amazon EC2 instance. Configure a process that runs on the EC2 instance to resize the images and store the images in an Amazon S3 bucket.
- D. Create a dynamic website hosted on an automatically scaling Amazon Elastic Container Service (Amazon ECS) cluster that creates a resize job in Amazon Simple Queue Service (Amazon SQS). Set up an image-resizing program that runs on an Amazon EC2 instance to process the resize jobs.
```

정답 : `A`

- 서버리스(S3 + Lambda) 구성이므로 예측 불가능한 트래픽 스파이크에 자동 대응
- 업로드 이벤트(S3 Put 이벤트)로 Lambda 트리거 → 원본을 읽어 썸네일/여러 해상도로 리사이즈 → 동일/별도 버킷･프리픽스로 저장하는 표준 아키텍처

오답 이유

- **B. CloudFront 정적 사이트 + Step Functions + RDS 저장**
    - 이미지 **바이너리 저장소로 RDS 부적합**(비용·성능·확장성 모두 불리). 보통 **S3에 저장**.
    - **Step Functions**는 워크플로 오케스트레이션 용도이며 단순 리사이즈 파이프라인엔 과함.
    
- **C. 단일 EC2 웹 서버에서 리사이즈**
    - 단일 인스턴스는 **병목·단일 장애 지점(SPOF)**. 수요 급증 시 **수평 확장성 제한** 및 운영 부담↑.
    
- **D. ECS + SQS + EC2 워커**
    - 확장 가능하긴 하나 **구성 복잡도와 운영 오버헤드**가 큼(클러스터/오토스케일/워커 관리). 요구 사항 대비 **과도한 설계**이며 서버리스 대비 비용·관리 비효율.


## #514
한 회사는 마이크로서비스 애플리케이션을 Amazon EC2 인스턴스에서 실행하고 있습니다. 회사는 확장성을 위해 애플리케이션을 Amazon Elastic Kubernetes Service (Amazon EKS) 클러스터로 마이그레이션하려고 합니다. 회사는 보안 규정을 유지하기 위해 Amazon EKS 컨트롤 플레인의 endpoint private access를 true로, endpoint public access를 false로 설정해야 합니다. 또한 데이터 플레인은 프라이빗 서브넷에 두어야 합니다. 그러나 노드가 클러스터에 조인할 수 없다는 오류 알림을 받았습니다.

노드가 클러스터에 조인할 수 있도록 하는 솔루션은 무엇입니까?

A. AWS Identity and Access Management (IAM)에서 AmazonEKSNodeRole IAM 역할에 필요한 권한을 부여한다.
B. 인터페이스 VPC 엔드포인트를 생성하여 노드가 컨트롤 플레인에 액세스할 수 있도록 한다.
C. 퍼블릭 서브넷에 노드를 다시 생성한다. EC2 노드의 보안 그룹을 제한한다.
D. 노드의 보안 그룹에서 아웃바운드 트래픽을 허용한다.

```
A company is running a microservices application on Amazon EC2 instances. The company wants to migrate the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster for scalability. The company must configure the Amazon EKS control plane with endpoint private access set to true and endpoint public access set to false to maintain security compliance. The company must also put the data plane in private subnets. However, the company has received error notifications because the node cannot join the cluster.  
  
Which solution will allow the node to join the cluster?

- A. Grant the required permission in AWS Identity and Access Management (IAM) to the AmazonEKSNodeRole IAM role.
- B. Create interface VPC endpoints to allow nodes to access the control plane.
- C. Recreate nodes in the public subnet. Restrict security groups for EC2 nodes.
- D. Allow outbound traffic in the security group of the nodes.
```

정답 : `B`

- EKS 클러스터 프라이빗 엔드포인트 전용(public access = false)인 경우, 워커 노드가 부트스트랩 단계에서 decribe-cluster 등 EKS/STS 등 AWS API에 접근해야 함
- 노드가 프라이빗 서브넷에 있고 NAT가 없다면, 이 API 호출이 실패해 노드가 클러스터에 조인하지 못함
- VPC 내부에서 해당 서비스에 사설로 접근하도록 인터페이스 VPC 엔드포인트(PrivateLink)를 생성해 인터넷/NAT 없이도 부트스트랩 및 조인 가능

오답 이유

- **A. IAM 권한 부여**
    - 권한 문제가 아니라 **네트워크 경로(사설 접근)** 문제입니다. 권한을 늘려도 **EKS/STS 엔드포인트에 닿지 못하면** 조인 실패는 지속됩니다.
    
- **C. 퍼블릭 서브넷으로 노드 재생성**
    - 보안 컴플라이언스 요구사항(데이터 플레인 프라이빗 서브넷, EKS 퍼블릭 엔드포인트 비활성화)과 **모순**됩니다. 또한 근본 원인은 **사설 경로 부재**입니다.
    
- **D. 노드 SG 아웃바운드 허용**
    - SG만 열어도 **엔드포인트로의 라우팅 경로**(NAT/VPC 엔드포인트)가 없으면 접근할 수 없습니다. **경로 자체를 제공**해야 합니다.


## #515
회사는 온프레미스 애플리케이션을 AWS로 마이그레이션하고 있습니다.  
회사는 Amazon Redshift를 솔루션으로 사용하려고 합니다.  

이 시나리오에서 Amazon Redshift에 적합한 사용 사례는 무엇입니까? (세 가지를 선택하십시오.)

A. 기존, 컨테이너화된, 이벤트 기반 애플리케이션이 데이터에 접근할 수 있도록 데이터 API를 지원한다.  
B. 클라이언트 측 및 서버 측 암호화를 지원한다.  
C. 애플리케이션이 활성 상태가 아닐 때 지정된 시간 동안 분석 워크로드를 구축한다.  
D. 백엔드 데이터베이스의 부하를 줄이기 위해 데이터를 캐싱한다.  
E. 페타바이트 규모의 데이터와 분당 수천만 건의 요청을 지원하도록 전 세계적으로 확장한다.  
F. AWS Management Console을 사용하여 클러스터의 보조 복제본을 생성한다.

```
A company is migrating an on-premises application to AWS. The company wants to use Amazon Redshift as a solution.  
  
Which use cases are suitable for Amazon Redshift in this scenario? (Choose three.)

- A. Supporting data APIs to access data with traditional, containerized, and event-driven applications
- B. Supporting client-side and server-side encryption
- C. Building analytics workloads during specified hours and when the application is not active
- D. Caching data to reduce the pressure on the backend database
- E. Scaling globally to support petabytes of data and tens of millions of requests per minute
- F. Creating a secondary replica of the cluster by using the AWS Management Console
```

정답 : `A, B, C`

- A: Amazon Redshift Data API를 사용하면 서버리스･컨테이너･이벤트 기반 애플리케이션이 Redshift에 접근 가능
	- JDBC/ODBC 커넥션을 관리하지 않고 HTTP 기반 API 호출로 SQL 쿼리 수행 가능
- B: Redshift는 TLS를 통한 전송 중 암호화(클라이언트 측)와 AWS KMS를 이용한 저장 중 암호화(서버 측)를 모두 지원
- C: Redshift는 데이터 웨어하우스(OLAP)로서 트랜잭션 처리(OLTP)가 아닌 분석 쿼리에 최적화
	- 따라서 애플리케이션 운영 시간 외에 분석･리포팅･ETL 등 분석 워크로드 수행이 이상적

오답 이유

-  **D. 데이터를 캐싱하여 백엔드 부하 감소**
	- 캐싱은 **Amazon ElastiCache (Redis/Memcached)** 와 같은 인메모리 캐시 서비스에 적합.
	- Redshift는 **대용량 분석용**으로 설계되어 있어 **실시간 캐시** 역할에는 부적절합니다.

-  **E. 전 세계 수천만 요청/분 처리 및 글로벌 확장**
	- 이는 **글로벌 OLTP 시스템**(예: DynamoDB, Aurora Global Database)에 해당.
	- Redshift는 **대용량 데이터 분석(OLAP)** 용도로 **대규모 요청 처리용이 아님**.

-  **F. 콘솔에서 보조 복제본 생성**
	- Redshift는 **복제 클러스터 개념**이 아닌, **스냅샷 백업 기반 복구 또는 cross-region 복제 스냅샷**만 지원.
	- 콘솔에서 “보조 복제본(standby replica)”을 수동 생성하는 기능은 없습니다.


## #516
회사는 고객이 자신의 금융 정보를 조회할 수 있도록 API 인터페이스를 제공합니다. 회사는 연중 피크 사용 시간 동안 더 많은 수의 요청을 예상합니다.

회사는 고객 만족을 보장하기 위해 API가 일관되게 낮은 지연 시간으로 응답하기를 요구합니다. 회사는 API를 위한 컴퓨트 호스트를 제공해야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족합니까?

A. Application Load Balancer와 Amazon Elastic Container Service (Amazon ECS)를 사용한다.
B. Amazon API Gateway와 프로비저닝된 동시성이 설정된 AWS Lambda 함수를 사용한다.
C. Application Load Balancer와 Amazon Elastic Kubernetes Service (Amazon EKS) 클러스터를 사용한다.
D. Amazon API Gateway와 예약된 동시성이 설정된 AWS Lambda 함수를 사용한다.

```
A company provides an API interface to customers so the customers can retrieve their financial information. Еhe company expects a larger number of requests during peak usage times of the year.  
  
The company requires the API to respond consistently with low latency to ensure customer satisfaction. The company needs to provide a compute host for the API.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use an Application Load Balancer and Amazon Elastic Container Service (Amazon ECS).
- B. Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency.
- C. Use an Application Load Balancer and an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.
- D. Use Amazon API Gateway and AWS Lambda functions with reserved concurrency.
```

정답 : `B`

- 프로비저닝된 동시성은 함수 인스턴스를 미리 준비해 콜드 스타트를 제거하므로 피크 시에도 일관된 낮은 지연 시간 제공
- API Gateway + Lambda 조합은 인프라 관리가 거의 없어 운영 오버헤드가 최소
- 수요 변동 시 프로비저닝된 동시성 용량만 조절하면 안정적 성능을 보장

오답 이유

- **A. ALB + ECS**
    - 컨테이너 클러스터/오토스케일/이미지 롤아웃 등 **운영 관리 부담**이 큼. 지연 시간 보장은 가능하나 **서버리스 대비 오버헤드 ↑**.
    
- **C. ALB + EKS**
    - 쿠버네티스 클러스터 운영(컨트롤 플레인/노드, 업그레이드, 배포 전략 등)으로 **가장 복잡**하고 운영 비용이 큼.
    
- **D. API Gateway + 예약된 동시성(Reserved Concurrency)**
    - **동시 실행 상한/전용 슬롯**을 예약할 뿐, **콜드 스타트 제거 기능은 아님** → 트래픽 급증/웜업 상황에서 **지연 시간 일관성 보장 부족**. 일관된 저지연은 **프로비저닝된 동시성**이 정답.


## #517
회사는 아카이브 목적을 위해 모든 AWS Systems Manager Session Manager 로그를 Amazon S3 버킷으로 전송하기를 원합니다.

가장 운영 효율적으로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?

A. Systems Manager 콘솔에서 S3 로깅을 활성화한다. 세션 데이터를 보낼 S3 버킷을 선택한다.
B. Amazon CloudWatch 에이전트를 설치한다. 모든 로그를 CloudWatch 로그 그룹으로 푸시한다. 보관을 위해 해당 로그 그룹에서 S3 버킷으로 로그를 내보낸다.
C. 모든 서버 로그를 중앙 S3 버킷에 업로드하는 Systems Manager 문서를 생성한다. Amazon EventBridge를 사용하여 계정의 모든 서버에 대해 해당 Systems Manager 문서를 매일 실행한다.
D. Amazon CloudWatch 에이전트를 설치한다. 모든 로그를 CloudWatch 로그 그룹으로 푸시한다. 들어오는 로그 이벤트를 Amazon Kinesis Data Firehose 전송 스트림으로 푸시하는 CloudWatch Logs 구독을 생성한다. 대상은 Amazon S3로 설정한다.

```
A company wants to send all AWS Systems Manager Session Manager logs to an Amazon S3 bucket for archival purposes.  
  
Which solution will meet this requirement with the MOST operational efficiency?

- A. Enable S3 logging in the Systems Manager console. Choose an S3 bucket to send the session data to.
- B. Install the Amazon CloudWatch agent. Push all logs to a CloudWatch log group. Export the logs to an S3 bucket from the group for archival purposes.
- C. Create a Systems Manager document to upload all server logs to a central S3 bucket. Use Amazon EventBridge to run the Systems Manager document against all servers that are in the account daily.
- D. Install an Amazon CloudWatch agent. Push all logs to a CloudWatch log group. Create a CloudWatch logs subscription that pushes any incoming log events to an Amazon Kinesis Data Firehose delivery stream. Set Amazon S3 as the destination.
```

정답 : `A`

- Session Manager는 콘솔에서 세션 로그를 S3와 CloudWatch Logs로 직접 전송하도록 기본 기능을 제공
- 콘솔에서 Session Manager Preferences에서 S3 로깅을 켜고 버킷/프리픽스만 지정하면 즉시 적용
	- 에이전트 설치, 파이프라인 구성, 스케줄 작업이 필요 없음

오답 이유

- **B. CloudWatch 에이전트 설치 + 로그 그룹 → S3 내보내기**
    - Session Manager 로그는 **에이전트 추가 설치 없이** S3/CloudWatch로 직접 전송 가능.
    - CloudWatch 내보내기 작업은 **주기적 배치/설정 관리**가 필요해 운영 부담↑.
    
- **C. SSM 문서 + EventBridge로 매일 업로드**
    - 세션 로그는 **세션 발생 시점에 자동 전송**하는 것이 바람직.
    - 매일 문서를 돌려 서버 로그를 업로드하는 방식은 **Session Manager 전용 로그 처리에 부적합**하고, 관리 복잡도↑.
    
- **D. CloudWatch 에이전트 + Logs Subscription → Firehose → S3**
    - 동작은 가능하나 **과도한 구성**(에이전트/구독/Firehose)으로 비용·운영 복잡도↑.
    - Session Manager의 **네이티브 S3 로깅**이 이미 존재하므로 비효율.


## #518
애플리케이션이 Amazon RDS MySQL DB 인스턴스를 사용하고 있습니다.  
RDS 데이터베이스의 디스크 공간이 부족해지고 있습니다.  
솔루션스 아키텍트는 다운타임 없이 디스크 공간을 늘리기를 원합니다.

가장 적은 노력으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. RDS에서 스토리지 자동 확장(storage autoscaling)을 활성화한다.  
B. RDS 데이터베이스 인스턴스 크기를 늘린다.  
C. RDS 데이터베이스 인스턴스의 스토리지 유형을 프로비저닝된 IOPS(Provisioned IOPS)로 변경한다.  
D. RDS 데이터베이스를 백업하고, 스토리지 용량을 늘린 후 데이터베이스를 복원하고, 이전 인스턴스를 중지한다.

```
An application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime.  
  
Which solution meets these requirements with the LEAST amount of effort?

- A. Enable storage autoscaling in RDS
- B. Increase the RDS database instance size
- C. Change the RDS database instance storage type to Provisioned IOPS
- D. Back up the RDS database, increase the storage capacity, restore the database, and stop the previous instance
```

정답 : `A`

- Amazon RDS Storage Auto Scaling 기능은 스토리지 사용량이 지정된 임계값에 도달하면 자동으로 디스크 크기를 확장
- 이 과정은 다운타임 없이(온라인 확장) 수행되며, MySQL을 포함한 대부분의 RDS 엔진에서 지원
- 단순히 콘솔이나 CLI에서 Auto Scaling 설정만 활성화하면 되므로 가장 적은 노력으로 문제를 해결

오답 이유

- **B. 인스턴스 크기(instance size) 증가**
    - 인스턴스 크기는 **CPU, RAM 등 컴퓨팅 리소스**를 늘릴 뿐이며, **디스크 용량(storage)** 은 늘어나지 않습니다.
    - 문제의 원인은 스토리지 부족이므로 부적합합니다.
    
- **C. 스토리지 유형을 Provisioned IOPS로 변경**
    - IOPS(입출력 성능) 향상에는 도움이 되지만, **용량 문제는 해결되지 않습니다.**
    - 또한 스토리지 타입 변경은 **리사이즈 작업**을 수반하여 다운타임이 발생할 수 있습니다.
    
- **D. 백업 후 복원 및 교체**
    - 백업 → 복원 → 스위칭은 복잡하고 **다운타임이 필연적**입니다.
    - 운영 효율성과 “no downtime” 요구사항 모두 위배됩니다.


## #519
한 컨설팅 회사가 전 세계 고객에게 전문 서비스를 제공합니다.  
이 회사는 고객이 AWS에서 데이터를 신속하게 수집하고 분석할 수 있도록 솔루션과 도구를 제공합니다.  
회사는 고객이 셀프 서비스(Self-Service) 방식으로 사용할 수 있도록 공통된 솔루션과 도구 세트를 중앙에서 관리하고 배포해야 합니다.  

이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?

A. 고객을 위해 AWS CloudFormation 템플릿을 생성한다.  
B. 고객을 위해 AWS Service Catalog 제품(Product)을 생성한다.  
C. 고객을 위해 AWS Systems Manager 템플릿을 생성한다.  
D. 고객을 위해 AWS Config 항목(Item)을 생성한다.

```
A consulting company provides professional services to customers worldwide. The company provides solutions and tools for customers to expedite gathering and analyzing data on AWS. The company needs to centrally manage and deploy a common set of solutions and tools for customers to use for self-service purposes.  
  
Which solution will meet these requirements?

- A. Create AWS CloudFormation templates for the customers.
- B. Create AWS Service Catalog products for the customers.
- C. Create AWS Systems Manager templates for the customers.
- D. Create AWS Config items for the customers.
```

정답 : `B`

- AWS Service Catalog는 조직이 공통 솔루션, 도구, CloudFormation 스택, AMI, 애플리케이션 구승 등을 중아에서 정의･관리･배포할 수 있게 해주는 서비스
- 이를 통해 관리자는 승인되 제품 카탈로그를 만들고, 사용자는 셀프 서비스 방식으로 배포 가능

오답 이유

- **A. CloudFormation 템플릿 생성**
    - CloudFormation은 인프라를 코드로 정의하기 위한 도구이지만, **템플릿 자체는 중앙 관리·승인·버전 관리·사용자 권한 제어 기능이 부족**합니다.
    - Service Catalog는 CloudFormation 템플릿을 **내부적으로 사용**하지만, 그 위에 **승인·권한·셀프서비스 UI**를 제공합니다.
    
- **C. Systems Manager 템플릿 생성**
    - Systems Manager는 **운영 자동화 및 구성 관리**용 서비스입니다.
    - 중앙 배포/셀프서비스 포털 개념보다는 **운영 태스크 자동화**(예: 패치, 명령 실행, 파라미터 저장 등)에 초점이 있습니다.
    
- **D. AWS Config 항목 생성**
    - AWS Config는 **리소스 구성 변경 감시 및 규정 준수 평가** 서비스입니다.
    - 고객이 사용할 솔루션/도구를 배포·관리하는 목적과는 무관합니다.


## #520
회사는 Amazon EC2 인스턴스에서 실행될 새 웹 애플리케이션을 설계 중입니다. 애플리케이션은 백엔드 데이터 저장소로 Amazon DynamoDB를 사용할 예정입니다. 애플리케이션 트래픽은 예측 불가능할 것입니다. 회사는 데이터베이스에 대한 읽기 및 쓰기 처리량이 중간에서 높을 것으로 예상합니다. 회사는 애플리케이션 트래픽에 따라 확장해야 합니다.

가장 비용 효율적으로 이러한 요구 사항을 충족하는 DynamoDB 테이블 구성은 무엇입니까?

A. DynamoDB Standard 테이블 클래스를 사용하여 프로비저닝된 읽기/쓰기를 구성한다. DynamoDB 자동 스케일링을 최대 정의된 용량으로 설정한다.
B. DynamoDB Standard 테이블 클래스를 사용하여 온디맨드 모드로 구성한다.
C. DynamoDB Standard-IA(드물게 액세스) 테이블 클래스를 사용하여 프로비저닝된 읽기/쓰기를 구성한다. DynamoDB 자동 스케일링을 최대 정의된 용량으로 설정한다.
D. DynamoDB Standard-IA(드물게 액세스) 테이블 클래스를 사용하여 온디맨드 모드로 구성한다.

```
A company is designing a new web application that will run on Amazon EC2 Instances. The application will use Amazon DynamoDB for backend data storage. The application traffic will be unpredictable. The company expects that the application read and write throughput to the database will be moderate to high. The company needs to scale in response to application traffic.  
  
Which DynamoDB table configuration will meet these requirements MOST cost-effectively?

- A. Configure DynamoDB with provisioned read and write by using the DynamoDB Standard table class. Set DynamoDB auto scaling to a maximum defined capacity.
- B. Configure DynamoDB in on-demand mode by using the DynamoDB Standard table class.
- C. Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity.
- D. Configure DynamoDB in on-demand mode by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class.
```

정답 : `A`

- 트래픽이 예측 불가능하지만 지속적으로 중간~높은 처리량이 예상되면, 일반적으로 프로비저닝 모드 + 자동 스케일링이 온디맨드보다 비용 효율적
- 자동 스케일링은 읽기/쓰기 용량을 트래픽 변화에 따라 자동 조정하여 과도한 예비용량을 줄이면서도 급증에 대응

오답 이유

- **B. 온디맨드 모드 + Standard**
    - 예측 불가 스파이크에는 간편하지만, 문제가 제시한 **“중간~높은” 처리량**이 **일상적**이라면 **프로비저닝+오토스케일** 대비 비용이 커질 가능성이 높습니다.
    
- **C. 프로비저닝 + Standard-IA**
    - **Standard-IA**는 저장비는 저렴하지만 **요청 비용이 높고, 드물게 접근하는 테이블/파티션**에 적합합니다. 본 시나리오는 **중~고 빈도 접근**이므로 부적합.
    
- **D. 온디맨드 + Standard-IA**
    - 위와 동일하게 **IA 클래스는 빈번 접근에 부적합**하며, 온디맨드와 결합하면 **요청 비용이 특히 비싸질 수 있음**.