---
created: 2025-10-04 10:57:43
last_modified: 2025-10-12 10:09:48
---
## #361
한 회사가 AWS에서 멀티플레이어 게임 애플리케이션을 호스팅하고 있습니다. 회사는 애플리케이션이 서브밀리초(sub-millisecond) 지연으로 데이터를 읽고, 과거 데이터에 대해 일회성 쿼리를 실행하기를 원합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 자주 액세스되는 데이터에는 Amazon RDS를 사용합니다. 데이터를 Amazon S3 버킷으로 내보내기 위해 주기적인 사용자 지정 스크립트를 실행합니다.
B. 데이터를 Amazon S3 버킷에 직접 저장합니다. 장기 보관을 위해 오래된 데이터를 S3 Glacier Deep Archive로 이동하도록 S3 수명 주기 정책을 구현합니다. Amazon Athena를 사용하여 Amazon S3의 데이터에 대해 일회성 쿼리를 실행합니다.
C. 자주 액세스되는 데이터에는 Amazon DynamoDB와 DynamoDB Accelerator(DAX)를 사용합니다. DynamoDB 테이블 내보내기를 사용해 데이터를 Amazon S3 버킷으로 내보냅니다. Amazon Athena를 사용하여 Amazon S3의 데이터에 대해 일회성 쿼리를 실행합니다.
D. 자주 액세스되는 데이터에는 Amazon DynamoDB를 사용합니다. Amazon Kinesis Data Streams로 스트리밍을 켭니다. Kinesis Data Firehose를 사용해 Kinesis Data Streams에서 데이터를 읽습니다. 레코드를 Amazon S3 버킷에 저장합니다.

```
A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.
- B. Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.
- C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.
- D. Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket.
```

정답 : `C`

- 서브밀리초 읽기는 DynamoDB Accelerator(DAX)가 제공(마이크로초~서브밀리초 수준의 캐시 읽기). DynamoDB 단독은 보통 한 자리수ms
- 과거 데이터 일회성 쿼리는 DynamoDB 테이블 내보내기(Export to S3)로 스냅샷을 테이블 성능에 영향 없이 S3로 내보낸 뒤 Athena로 서버리스 분석 가능

오답 이유

- **A (RDS + 스크립트 내보내기)**: 서브밀리초 읽기 보장 불가. 내보내기용 **주기적 스크립트 운영**이 필요해 오버헤드 증가.
    
- **B (S3 + Athena)**: S3는 객체 스토리지라 **실시간 서브밀리초 읽기 제공 불가**.
    
- **D (DynamoDB + Kinesis + Firehose)**: 동작 가능하지만 **구성 요소가 늘어나 운영 복잡도 증가**. ‘일회성’ 분석 요구에 비해 과도한 파이프라인.


## #362
한 회사는 결제 처리 시스템을 사용하고 있습니다. 이 시스템은 특정 결제 ID(payment ID)에 대한 메시지가 전송된 순서와 동일한 순서로 수신되어야 합니다. 그렇지 않으면 결제가 잘못 처리될 수 있습니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 하는 작업은 무엇입니까? (두 가지 선택)

A. 결제 ID를 파티션 키로 사용하여 Amazon DynamoDB 테이블에 메시지를 씁니다.  
B. 결제 ID를 파티션 키로 사용하여 Amazon Kinesis 데이터 스트림에 메시지를 씁니다.  
C. 결제 ID를 키로 사용하여 Amazon ElastiCache for Memcached 클러스터에 메시지를 씁니다.  
D. 메시지를 Amazon Simple Queue Service(Amazon SQS) 큐에 씁니다. 결제 ID를 메시지 속성으로 설정합니다.  
E. 메시지를 Amazon Simple Queue Service(Amazon SQS) FIFO 큐에 씁니다. 결제 ID를 메시지 그룹으로 설정합니다.  

```
A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly.  
  
Which actions should a solutions architect take to meet this requirement? (Choose two.)

- A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.
- B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.
- C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.
- D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID.
- E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.
```

정답 : `B, E`

- Amazon Kinesis Data Streams - 결제 ID를 파티션 키로 사용
	- 동일한 파티션 키를 가진 모든 메시지를 단일 샤드로 라우팅
	- 샤드 내에서는 엄격한 순서 보장이 이루어짐 → 동일한 결제 ID 메시지들을 전송 순서대로 처리 가능
- Amazon SQS FIFO Queue - 결제 ID를 메시지 그룹으로 사용
	- SQS FIFO 큐는 메시지 순서를 보장하며, MessageGroupId를 기준으로 그룹 단위 순서 보장을 제공
	- 동일한 결제 ID로 설정된 메시지 그룹 내에서는 순서가 보장되고 다른 결제 ID 그룹은 병렬 처리로 확장 가능

오답 이유

- **A. DynamoDB**
    - DynamoDB는 순차 처리(Ordered processing)를 **보장하지 않습니다.**
    - 데이터는 파티션 키 기준으로 정렬되더라도, **쓰기/읽기 순서**가 보장되지 않아 메시지 순서를 유지할 수 없습니다.
    
- **C. ElastiCache for Memcached**
    - 캐시 시스템으로, **메시지 순서 보장 기능이 없습니다.**
    - 키 기반 빠른 조회에는 적합하지만 메시지 큐/스트림으로 사용 불가.
    
- **D. SQS 표준 큐 (Standard Queue)**
    - 기본 SQS 큐는 **최고 처리량(High throughput)** 을 제공하지만, **메시지 순서가 보장되지 않습니다.**
    - “At-least-once” 전달 모델이므로 순서가 어긋날 가능성이 있습니다.


## #363
한 회사가 리더보드(leaderboard), 매치메이킹(matchmaking), 인증(authentication) 서비스를 동시에(concurrently) 호출해야 하는 게임 시스템을 구축하고 있습니다.  
이 시스템은 각 서비스로 **고유한 이벤트를 동시에 전송**해야 하며, AWS의 **이벤트 기반(event-driven)** 시스템을 사용해야 합니다.  
또한 **이벤트의 순서를 보장(guaranteed order)** 해야 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon EventBridge 이벤트 버스  
B. Amazon Simple Notification Service (Amazon SNS) FIFO 주제(Topics)  
C. Amazon Simple Notification Service (Amazon SNS) 표준 주제(Standard Topics)  
D. Amazon Simple Queue Service (Amazon SQS) FIFO 큐  

```
A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events.  
  
Which solution will meet these requirements?

- A. Amazon EventBridge event bus
- B. Amazon Simple Notification Service (Amazon SNS) FIFO topics
- C. Amazon Simple Notification Service (Amazon SNS) standard topics
- D. Amazon Simple Queue Service (Amazon SQS) FIFO queues
```

정답 : `B`

- 요구사항
	- 이벤트 기반 아키텍처
	- 여러 서비스(리더보드, 매치메이킹, 인증)로 동시에 이벤트 전송 필요 → Pub/Sub 모델 필요
	- 이벤트 순서 보장 필요 → FIFO 메커니즘 필요
- Amazon SNS FIFO 토픽
	- SNS는 하나의 이벤트를 여러 구독자(SQS, Lambda 등)에 동시에 전달 가능
	- FIFO 토픽은 MessageGroupId 기준으로 순서 보장 및 중복 방지 기능 제공

오답 이유

- **A. Amazon EventBridge**
    - EventBridge는 **순서 보장(Order Guarantee)** 을 제공하지 않습니다.
    - 또한 이벤트는 각 타깃으로 비동기 라우팅되지만 **전달 순서가 뒤섞일 수 있습니다.**
    
- **C. SNS Standard Topics**
    - SNS 표준 주제는 **최고 처리량, 최소 지연**을 제공하지만 **전달 순서 보장 없음.**
    - 이벤트가 각 구독자에게 **비순차적**으로 전달될 수 있습니다.
    
- **D. Amazon SQS FIFO Queue**
    - FIFO 큐는 **단일 소비자 그룹에 순서 보장**은 가능하지만,
        - 이벤트를 **여러 서비스로 동시에 분배(Pub/Sub)** 할 수 없습니다.
        - 즉, 한 큐에 한 소비자 모델로 동작하므로 “동시 전달” 요건 불충족.


## #364
한 병원이 환자 증상을 수집하는 새로운 애플리케이션을 설계하고 있습니다. 병원은 아키텍처에 Amazon Simple Queue Service(Amazon SQS)와 Amazon Simple Notification Service(Amazon SNS)를 사용하기로 했습니다.

솔루션스 아키텍트가 인프라 설계를 검토하고 있습니다. 데이터는 전송 중과 저장 시 모두 암호화되어야 합니다. 또한 병원의 승인된 인원만 데이터에 액세스할 수 있어야 합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계 조합을 수행해야 합니까? (두 가지 선택)

A. SQS 구성 요소에서 서버 측 암호화를 켭니다. 기본 키 정책을 업데이트하여 키 사용을 승인된 주체 집합으로 제한합니다.
B. AWS Key Management Service(AWS KMS) 고객 관리형 키를 사용하여 SNS 구성 요소에서 서버 측 암호화를 켭니다. 키 정책을 적용하여 키 사용을 승인된 주체 집합으로 제한합니다.
C. SNS 구성 요소에서 암호화를 켭니다. 기본 키 정책을 업데이트하여 키 사용을 승인된 주체 집합으로 제한합니다. 주제 정책에 조건을 설정하여 TLS를 통한 암호화된 연결만 허용합니다.
D. AWS KMS 고객 관리형 키를 사용하여 SQS 구성 요소에서 서버 측 암호화를 켭니다. 키 정책을 적용하여 키 사용을 승인된 주체 집합으로 제한합니다. 큐 정책에 조건을 설정하여 TLS를 통한 암호화된 연결만 허용합니다.
E. AWS KMS 고객 관리형 키를 사용하여 SQS 구성 요소에서 서버 측 암호화를 켭니다. IAM 정책을 적용하여 키 사용을 승인된 주체 집합으로 제한합니다. 큐 정책에 조건을 설정하여 TLS를 통한 암호화된 연결만 허용합니다.

```
A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture.  
  
A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data.  
  
Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)

- A. Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.
- B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.
- C. Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.
- D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.
- E. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.
```

정답 : `B, D`

- SNS에 SSE-KMS를 켜고 키 정책으로 권한을 병원 승인 주체로 제한 → 저장 시 암호화와 키 거버넌스 충족
- SQS에 SSE-KMS(CMK) 적용 + 키 정책으로 승인 주체만 사용하게 제한 + 큐 정책에 aws:SecureTransport 조건으로 TLS(HTTPS)만 허용
	- 전송 중/저장 시 암호화를 강제하고 키 컴플라이언스 팀ㅇ이 관리

오답 이유

- **A**: KMS **고객 관리형 키 사용**이 명시되지 않았고, **TLS 강제 조건**도 없음. “컴플라이언스 팀이 키를 관리” 요건과 “전송 중 암호화 강제”를 모두 충족하지 못함.
    
- **C**: “암호화”는 모호하며 **고객 관리형 KMS 키(CMK)** 사용을 보장하지 않습니다. 또한 “기본 키 정책 업데이트”는 바람직한 키 거버넌스 방식이 아니며, 요구 조건인 **컴플라이언스 팀 주도 키 관리**를 명확히 담보하지 못합니다.
    
- **E**: KMS 키 사용의 최종 권한 경계는 **키 정책**입니다. **IAM 정책만**으로는 충분하지 않으며, 교차 서비스/계정 시 올바른 제어가 되지 않습니다.


## #365
한 회사가 Amazon RDS로 지원되는 웹 애플리케이션을 운영하고 있습니다.  
새로운 데이터베이스 관리자가 실수로 데이터베이스 테이블의 정보를 수정하여 데이터 손실이 발생했습니다.  
회사는 이러한 유형의 사고에서 복구할 수 있도록, 최근 30일 이내의 어느 시점이든 **변경 5분 전 상태로 데이터베이스를 복원할 수 있는 기능**을 원합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트가 설계에 포함해야 할 기능은 무엇입니까?

A. 읽기 전용 복제본(Read replicas)  
B. 수동 스냅샷(Manual snapshots)  
C. 자동 백업(Automated backups)  
D. 멀티 AZ 배포(Multi-AZ deployments)

```
A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days.  
  
Which feature should the solutions architect include in the design to meet this requirement?

- A. Read replicas
- B. Manual snapshots
- C. Automated backups
- D. Multi-AZ deployments
```

정답 : `C`

- RDS 자동 백업은 Point-In-Time Recovery(PITR) 기능을 제공
- 이를 통해 보존 기간(최대 35일) 내에서 원하는 시점(예: 변경 5분 전) 으로 데이터베이스를 복원 가능
- 자동 백업은 매일 전체 백업과 트랜잭션 로그(변경 내역) 지속 백업을 조합해 특정 시점 복원이 가능

오답 이유

- **A. Read replicas**
    - 읽기 전용 트래픽 분산용이며, 실시간으로 원본 DB의 변경사항이 복제됩니다.
    - 실수로 데이터가 수정되면 **복제본에도 즉시 반영**되므로 복구에 도움이 되지 않습니다.
    
- **B. Manual snapshots**
    - 사용자가 직접 스냅샷을 찍는 시점으로만 복원할 수 있습니다.
    - “5분 전 시점으로 복원” 같은 세밀한 시점 복구는 불가능.
    
- **D. Multi-AZ deployments**
    - 고가용성과 장애 복구를 위한 기능입니다.
    - 주 DB 인스턴스의 데이터를 스탠바이로 **동기식 복제**하므로, 논리적 오류(예: 잘못된 UPDATE)는 그대로 반영되어 복구 불가.



## #366
한 회사의 웹 애플리케이션은 AWS Lambda 함수와 Amazon DynamoDB 데이터베이스 앞단에 Amazon API Gateway API로 구성됩니다. Lambda 함수는 비즈니스 로직을 처리하고, DynamoDB 테이블은 데이터를 호스팅합니다. 애플리케이션은 개별 사용자를 식별하기 위해 Amazon Cognito 사용자 풀을 사용합니다. 솔루션스 아키텍트는 구독이 있는 사용자만 프리미엄 콘텐츠에 접근하도록 애플리케이션을 업데이트해야 합니다.

가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. API Gateway API에서 API 캐싱과 스로틀링을 활성화합니다.
B. API Gateway API에 AWS WAF를 설정합니다. 구독이 있는 사용자를 필터링하는 규칙을 생성합니다.
C. DynamoDB 테이블의 프리미엄 콘텐츠에 세분화된 IAM 권한을 적용합니다.
D. 구독이 없는 사용자의 접근을 제한하기 위해 API 사용 계획과 API 키를 구현합니다.

```
A company’s web application consists of an Amazon API Gateway API in front of an AWS Lambda function and an Amazon DynamoDB database. The Lambda function handles the business logic, and the DynamoDB table hosts the data. The application uses Amazon Cognito user pools to identify the individual users of the application. A solutions architect needs to update the application so that only users who have a subscription can access premium content.  
  
Which solution will meet this requirement with the LEAST operational overhead?

- A. Enable API caching and throttling on the API Gateway API.
- B. Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription.
- C. Apply fine-grained IAM permissions to the premium content in the DynamoDB table.
- D. Implement API usage plans and API keys to limit the access of users who do not have a subscription.
```

정답 : `D`

- API Gateway는 Cognito 사용자 풀 인증(토큰 검증)과 API 키 요구를 동시에 적용 가능
- 구독한 사용자에게만 API 키를 발급하고 해당 키를 프리미엄 엔드포인트가 속한 Usage Plan에 묶으면, 구독자만 호출 가능하게 쉽게 구분 가능
- 애플리케이션 코드나 데이터 계층 구조를 크게 바꾸지 않고(운영 오버헤드 최소), API Gateway 설정만으로 구독자 접근 제어 및 호출량 제어까지 함께 관리 가능

오답 이유

- **A. 캐싱/스로틀링**: 성능·비용 최적화용 설정일 뿐, **구독자 여부에 따른 접근 통제** 기능이 아닙니다.
    
- **B. AWS WAF 규칙**: WAF는 IP/패턴 기반 L7 필터링·보호에 적합하며, **사용자 구독 상태 같은 비즈니스 속성으로 권한 부여**를 하기에 적합하지 않습니다.
    
- **C. DynamoDB 세분화 권한**: 현재 구조는 **Lambda가 DynamoDB에 접근**합니다(클라이언트가 직접 테이블에 접근하지 않음). 세분화 권한을 적용해도 **Lambda 실행 역할**이 사용되므로 **사용자별 권한 분기**가 되지 않습니다. 또한 Cognito **사용자 풀**만 쓰는 상황에서 **아이덴티티 풀 + 직접 액세스**로 바꾸면 아키텍처 변경과 운영 부담이 큽니다.


## #367
한 회사는 전 세계 사용자를 위한 UDP 기반 애플리케이션의 요청을 라우팅하기 위해 Amazon Route 53 지연 시간 기반 라우팅을 사용하고 있습니다. 애플리케이션은 미국, 아시아, 유럽에 있는 회사의 온프레미스 데이터 센터의 이중화된 서버에서 호스팅됩니다. 회사의 컴플라이언스 요구 사항은 애플리케이션이 온프레미스에서 호스팅되어야 한다고 명시합니다. 회사는 애플리케이션의 성능과 가용성을 개선하고자 합니다.

이 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 세 개의 AWS 리전에 세 개의 Network Load Balancer(NLB)를 구성하여 온프레미스 엔드포인트를 대상으로 지정합니다. AWS Global Accelerator를 사용하여 가속기를 만들고 NLB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 액세스하도록 합니다.
B. 세 개의 AWS 리전에 세 개의 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 대상으로 지정합니다. AWS Global Accelerator를 사용하여 가속기를 만들고 ALB를 엔드포인트로 등록합니다. 가속기 DNS를 가리키는 CNAME을 사용하여 애플리케이션에 액세스하도록 합니다.
C. 세 개의 AWS 리전에 세 개의 Network Load Balancer(NLB)를 구성하여 온프레미스 엔드포인트를 대상으로 지정합니다. Route 53에서 세 개의 NLB를 가리키는 지연 시간 기반 레코드를 만들고, 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 액세스하도록 합니다.
D. 세 개의 AWS 리전에 세 개의 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 대상으로 지정합니다. Route 53에서 세 개의 ALB를 가리키는 지연 시간 기반 레코드를 만들고, 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS를 가리키는 CNAME을 사용하여 애플리케이션에 액세스하도록 합니다.

```
A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company’s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application.  
  
What should a solutions architect do to meet these requirements?

- A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.
- B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.
- C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.
- D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.
```

정답 : `A`

- 세 리전에 NLB를 두고, 각 NLB의 타깃으로 온프레미스 IP를 등록한 뒤 AWS Global Accelerator(UDP 리스너)를 구성해 각 리전 NLB를 엔드포인트로 등록
- Global Accelerator의 Anycast 정적 IP로 가장 가까운 엣지에서 온보딩 후 AWS 글로벌 백본으로 전달되어 지연과 패킷 손실이 감소
	- 리전･엔드포인트 헬스 체크 기반 자동 페일오버로 가용성도 향상

오답 이유

- **B (ALB + GA)**: ALB는 **HTTP/HTTPS(L7)** 전용이며 **UDP를 지원하지 않습니다.**
    
- **C (NLB + Route 53 + CloudFront)**: **CloudFront는 UDP를 지원하지 않습니다.** 또한 여기서는 애플리케이션 호스팅은 온프레미스여야 하므로, UDP 전송 가속에는 **Global Accelerator** 가 적합합니다.
    
- **D (ALB + Route 53 + CloudFront)**: ALB가 **UDP 미지원**, CloudFront도 **UDP 미지원**으로 요건 불충족.


## #368
한 솔루션스 아키텍트는 모든 신규 사용자에게 특정 복잡성 요구 사항과 필수 비밀번호 회전 주기를 적용하고자 합니다.

이 요구 사항을 달성하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 전체 AWS 계정에 대해 전반적인 비밀번호 정책을 설정합니다.  
B. AWS 계정의 각 IAM 사용자별로 비밀번호 정책을 설정합니다.  
C. 타사 소프트웨어를 사용하여 비밀번호 요구 사항을 설정합니다.  
D. Create_newuser 이벤트에 Amazon CloudWatch 규칙을 연결하여 적절한 요구 사항으로 비밀번호를 설정합니다.

```
A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords.  
  
What should the solutions architect do to accomplish this?

- A. Set an overall password policy for the entire AWS account.
- B. Set a password policy for each IAM user in the AWS account.
- C. Use third-party vendor software to set password requirements.
- D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.
```

정답 : `A`

- AWS IAM에서는 계정 단위로 비밀번호 정책을 설정 가능
- 이 정책은 해당 계정의 모든 IAM 사용자에게 자동 적용되며, 비밀번호의 복잡도, 길이, 숫자/기호 포함 여부, 회전 주기 등을 지정 가능
- 따라서 신규 IAM 사용자가 생성될 때 자동으로 정책이 적용되어, 별도의 추가 작업이나 이벤트 기반 규칙 설정이 필요 없음

오답 이유

- **B. 각 IAM 사용자별로 비밀번호 정책을 설정합니다.**
    → IAM은 **사용자 개별 단위 비밀번호 정책 설정을 지원하지 않습니다.**
    비밀번호 정책은 **계정 전체 공통 설정**입니다.
    
- **C. 타사 소프트웨어 사용**
    → 불필요하며, AWS가 이미 **IAM 콘솔/CLI/API**를 통해 기본적으로 이 기능을 제공합니다.
    추가 비용과 관리 복잡도만 증가합니다.
    
- **D. CloudWatch 규칙으로 Create_newuser 이벤트 처리**
    → 기술적으로 이벤트를 감지할 수는 있지만, **비밀번호 정책 적용 기능이 AWS 기본 IAM에서 제공**되므로 이 방법은 **불필요하고 비효율적**입니다.
    비밀번호 복잡성은 CloudWatch 이벤트로 강제할 수 없습니다.



## #369
한 회사가 애플리케이션을 Amazon EC2 Linux 인스턴스로 마이그레이션했습니다. 이 EC2 인스턴스 중 하나가 일정에 따라 여러 개의 1시간 작업을 실행합니다. 이 작업들은 서로 다른 팀에서 작성되었고 공통 프로그래밍 언어가 없습니다. 회사는 이러한 작업이 단일 인스턴스에서 실행되는 동안 성능과 확장성에 대해 우려하고 있습니다. 솔루션스 아키텍트는 이러한 우려를 해소할 수 있는 솔루션을 구현해야 합니다.

다음 중 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Batch를 사용하여 작업을 잡으로 실행합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 잡을 스케줄합니다.
B. EC2 인스턴스를 컨테이너로 변환합니다. AWS App Runner를 사용하여 온디맨드로 컨테이너를 생성해 작업을 잡으로 실행합니다.
C. 작업들을 AWS Lambda 함수로 복사합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 Lambda 함수를 스케줄합니다.
D. 작업을 실행하는 EC2 인스턴스의 Amazon Machine Image(AMI)를 생성합니다. 여러 복사본을 실행하기 위해 해당 AMI로 Auto Scaling 그룹을 생성합니다.

```
A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).
- B. Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.
- C. Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).
- D. Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance.
```

정답 : `A`

- AWS Batch는 각 작업을 잡으로 정의하고, 언어/런타임이 서로 다른 작업도 컨테이너로 캡슐화해 격리･병렬 실행이 가능
	- 필요 시 여러 vCPU/메모리 사양으로 동시 확장하며, 관리형 큐･스케줄링재시도를 제공해 운영 부담이 적음
- EventBridge와 연동하면 시간 기반 스케줄(매시간 등)을 간단히 설정해 단일 EC2 병목 없이 확장 가능한 서버리스 수준의 오케스트레이션 달성 가능

오답 이유

- **B (App Runner)**: App Runner는 **HTTP 엔드포인트를 노출하는 장기 실행 웹 서비스**에 적합합니다. **배치·스케줄형 잡 실행**에 맞지 않습니다.
    
- **C (Lambda)**: Lambda의 **최대 실행 시간은 15분**이므로 **1시간 작업**을 수행할 수 없습니다.
    
- **D (ASG로 EC2 복제)**: 인스턴스 수평 확장은 가능하지만 **작업 분배·스케줄링·실패 재시도** 등을 직접 구현/운영해야 하므로 **운영 오버헤드가 큼**.


## #370
한 회사가 VPC에서 공개 3계층 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 프라이빗 서브넷에서 실행되는 EC2 인스턴스는 인터넷을 통해 라이선스 서버와 통신해야 합니다. 회사는 운영 유지보수를 최소화하는 관리형 솔루션이 필요합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 퍼블릭 서브넷에 NAT 인스턴스를 프로비저닝합니다. 각 프라이빗 서브넷의 라우트 테이블을 기본 경로가 NAT 인스턴스를 가리키도록 수정합니다.
B. 프라이빗 서브넷에 NAT 인스턴스를 프로비저닝합니다. 각 프라이빗 서브넷의 라우트 테이블을 기본 경로가 NAT 인스턴스를 가리키도록 수정합니다.
C. 퍼블릭 서브넷에 NAT 게이트웨이를 프로비저닝합니다. 각 프라이빗 서브넷의 라우트 테이블을 기본 경로가 NAT 게이트웨이를 가리키도록 수정합니다.
D. 프라이빗 서브넷에 NAT 게이트웨이를 프로비저닝합니다. 각 프라이빗 서브넷의 라우트 테이블을 기본 경로가 NAT 게이트웨이를 가리키도록 수정합니다.

```
A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance.  
  
Which solution meets these requirements?

- A. Provision a NAT instance in a public subnet. Modify each private subnet's route table with a default route that points to the NAT instance.
- B. Provision a NAT instance in a private subnet. Modify each private subnet's route table with a default route that points to the NAT instance.
- C. Provision a NAT gateway in a public subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.
- D. Provision a NAT gateway in a private subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.
```

정답 : `C`

- NAT Gateway는 AWS가 관리하는 고가용성(멀티 AZ 권장) NAT 서비스로, 패치/스케일링/HA를 직접 관리할 필요가 없음
- 프라이빗 서브넷 인스턴스는 아웃바운드 인터넷 접근을 하되 공인 IP가 노출되지 않음

오답 이유

- **A. NAT 인스턴스(퍼블릭)**: 가능은 하지만 EC2 기반이라 **패치/확장/장애 조치/고가용성 구성**을 직접 관리해야 함 → 운영 부담 큼.
    
- **B. NAT 인스턴스(프라이빗)**: 프라이빗 서브넷에 두면 **인터넷 게이트웨이로의 경로가 없어** NAT 기능을 수행할 수 없음.
    
- **D. NAT 게이트웨이(프라이빗)**: NAT 게이트웨이는 **퍼블릭 서브넷(EIP + IGW)** 에 있어야 인터넷으로 트래픽을 전달 가능. 프라이빗 서브넷에 두면 동작하지 않음.


## #371
한 회사가 디지털 미디어 스트리밍 애플리케이션을 호스팅할 Amazon EKS 클러스터를 생성해야 합니다.
EKS 클러스터는 스토리지로 Amazon EBS 볼륨을 사용하는 관리형 노드 그룹을 사용합니다.
회사는 AWS KMS에 저장된 고객 관리형 키를 사용하여 저장 데이터(At-rest)를 모두 암호화해야 합니다.

다음 중 운영 오버헤드를 최소화하면서 이 요구 사항을 충족하는 조합은 무엇입니까? (두 가지 선택)

A. 고객 관리형 키를 사용해 데이터 암호화를 수행하는 Kubernetes 플러그인을 사용합니다.
B. EKS 클러스터를 생성한 후, EBS 볼륨을 찾아 고객 관리형 키를 사용하여 암호화를 활성화합니다.
C. EKS 클러스터가 생성될 AWS 리전에서 기본 EBS 암호화를 활성화합니다. 기본 키로 고객 관리형 키를 선택합니다.
D. EKS 클러스터를 생성합니다. 고객 관리형 키에 대한 권한을 부여하는 정책을 가진 IAM 역할을 생성합니다. 해당 역할을 EKS 클러스터에 연결합니다.
E. 고객 관리형 키를 EKS 클러스터의 Kubernetes Secret으로 저장합니다. 이 키를 사용하여 EBS 볼륨을 암호화합니다.

```
A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS).  
  
Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)

- A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption.
- B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.
- C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.
- D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.
- E. Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes.
```

정답 : `C, D`

- 리전 단에서 EBS 기본 암호화를 고객 관리형 KMS로 설정하면, 이후 생성되는 노드 그룹의 EBS 루트/데이터 볼륨이 자동으로 해당 CMK로 암호화
- EKS 관리형 노드 그룹이 EC2 인스턴스/볼륨을 생성할 때 지정한 CMK를 사용할 수 있도록 KMS 키 정책/권한이 필요

오답 이유

- **A**: EBS 볼륨 암호화는 **AWS 레벨에서 투명하게 수행**됩니다. 별도 **Kubernetes 플러그인**으로 디스크 암호화를 구현할 필요가 없으며, 오히려 운영 복잡도 증가.
    
- **B**: **이미 생성된 EBS 볼륨을 직접 암호화로 전환할 수 없습니다.** 스냅샷 복사 후 재생성 같은 절차가 필요해 **오버헤드가 큼**.
    
- **E**: **KMS 키 재료를 Kubernetes Secret에 저장하는 것은 잘못**이며 보안상 위험합니다. EBS 암호화는 KMS와의 서비스 통합으로 처리합니다.


## #372
한 회사가 Oracle 데이터베이스를 AWS로 마이그레이션하려고 합니다. 데이터베이스는 지리 코드로 식별되는 고해상도 GIS 이미지 수백만 개를 포함한 단일 테이블로 구성되어 있습니다.

자연재해가 발생하면 수만 개의 이미지가 몇 분마다 업데이트됩니다. 각 지리 코드마다 연결된 이미지(또는 행)는 하나뿐입니다. 회사는 이러한 이벤트 동안 고가용성과 확장성을 제공하는 솔루션을 원합니다.

다음 중 가장 비용 효율적으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 데이터베이스 테이블에 이미지와 지리 코드를 저장합니다. Amazon RDS Multi-AZ DB 인스턴스에서 실행되는 Oracle을 사용합니다.
B. 이미지를 Amazon S3 버킷에 저장합니다. Amazon DynamoDB를 사용하고 지리 코드를 키로, 이미지 S3 URL을 값으로 사용합니다.
C. 이미지와 지리 코드를 Amazon DynamoDB 테이블에 저장합니다. 고부하 시간에 DynamoDB Accelerator(DAX)를 구성합니다.
D. 이미지를 Amazon S3 버킷에 저장합니다. 지리 코드와 이미지 S3 URL을 데이터베이스 테이블에 저장합니다. Amazon RDS Multi-AZ DB 인스턴스에서 실행되는 Oracle을 사용합니다.

```
A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code.  
  
When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events.  
  
Which solution meets these requirements MOST cost-effectively?

- A. Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.
- B. Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.
- C. Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.
- D. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.
```

정답 : `B`

- 대용량 이미지 저장은 객체 스토리지인 Amazon S3가 가장 비용 효율적이고 내구성/가용성이 매우 높음
- 매우 잦은 업데이트와 단일 키-이미지 매핑은 Amazon DynamoDB의 파티션 키(=지리 코드) 설계로 수평 확장이 용이하며, 짧은 지연과 높은 쓰기/읽기 처리량 제공
- 쓰기 집중 시에도 프로비저닝/온디맨드 모드 선택으로 탄력적 확장 가능하며, 이미지 자체는 S3에 저장하고 메타데이터(예: S3 URL, 버전, 타임스탬프)만 DynamoDB에 저장해 비용과 성능을 동시에 최적화

오답 이유

- **A (RDS Oracle에 이미지와 코드 저장)**: 관계형 DB에 **대용량 바이너리 이미지(BLOB)** 를 저장하면 저장·I/O 비용과 확장성이 비효율적입니다. 대량 동시 업데이트에 대한 수평 확장성이 떨어집니다.
    
- **C (이미지까지 DynamoDB에 저장)**: DynamoDB는 **아이템 크기 400KB 제한**이 있어 고해상도 이미지를 저장할 수 없습니다. 또한 이미지 저장 자체는 객체 스토리지에 적합합니다. DAX는 **읽기 캐시**이므로 쓰기 폭증 문제 해결에는 부적합합니다.
    
- **D (S3 + RDS Oracle 메타데이터)**: 메타데이터를 RDS에 두면 **대량 업데이트 시 확장성과 비용** 측면에서 불리합니다. DynamoDB가 동일 요구를 **더 낮은 운영 오버헤드와 높은 확장성**으로 충족합니다.


## #373
한 회사가 자동차의 IoT 센서에서 데이터를 수집하는 애플리케이션을 보유하고 있습니다. 데이터는 Amazon Kinesis Data Firehose를 통해 스트리밍되어 Amazon S3에 저장됩니다. 데이터는 매년 조 단위의 S3 객체를 생성합니다. 매일 아침, 회사는 지난 30일의 데이터를 사용해 일련의 머신 러닝(ML) 모델을 재학습합니다.

연 4회, 회사는 지난 12개월의 데이터를 사용하여 분석을 수행하고 다른 ML 모델을 학습합니다. 데이터는 최대 1년 동안 최소 지연으로 사용할 수 있어야 합니다. 1년이 지나면 데이터는 보관 목적으로 유지되어야 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?

A. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후 객체를 S3 Glacier Deep Archive로 전환하도록 S3 수명 주기(Lifecycle) 정책을 생성합니다.
B. S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후 객체를 S3 Glacier Deep Archive로 자동 이동하도록 S3 Intelligent-Tiering을 구성합니다.
C. S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용합니다. 1년 후 객체를 S3 Glacier Deep Archive로 전환하도록 S3 수명 주기 정책을 생성합니다.
D. S3 Standard 스토리지 클래스를 사용합니다. 30일 후 S3 Standard-Infrequent Access(S3 Standard-IA)로, 1년 후 S3 Glacier Deep Archive로 전환하도록 S3 수명 주기 정책을 생성합니다.

```
A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models.  
  
Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes.  
  
Which storage solution meets these requirements MOST cost-effectively?

- A. Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.
- B. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automatically move objects to S3 Glacier Deep Archive after 1 year.
- C. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.
- D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.
```

정답 : `D`

- 접근 패턴이 명확: 최근 30일은 매일 액세스, 30일~1년 구간은 연 4회 액세스, 1년 이후는 아카이브
- S3 Standard는 잦은 접근에 적합, 30일 이후에는 Standard-IA(밀리초 지연, 낮은 저장비)로 비용 절감
- 1년 이후에는 Glaicer Deep Archive로 최저 비용 보관
- Intelligent-Tiering은 객체당 모니터링 비용이 발생하며, 문제의 전제처럼 연간 조 단위 객체 규모에서는 이 고정 비용이 매우 커져 패턴이 명확한 본 시나리오보다 비용 비효율적일 가능성이 큼

오답 이유

- **A. S3 Intelligent-Tiering + 1년 후 Deep Archive 전환**
    - 접근 패턴이 이미 **예측 가능**하므로 Intelligent-Tiering의 자동 계층화 장점이 작음.
    - 무엇보다 **객체 모니터링 비용**이 조 단위 객체에서 누적되어 **총비용 증가** 우려.
    
- **B. Intelligent-Tiering에서 “S3 Glacier Deep Archive로 자동 이동” 설정**
    - Intelligent-Tiering은 자체 **Archive Access/Deep Archive Access 티어**로의 전환 규칙을 지원하며, **별도 S3 Glacier Deep Archive 클래스로의 자동 전환**을 직접 설정하는 방식은 아님(개념 혼동). 또한 모니터링 비용 문제 동일.
    
- **C. 처음부터 Standard-IA 사용**
    - 최근 30일은 **매일** 접근하므로 Standard-IA 사용 시 **조회 비용이 급증**하고 권장되지 않음(IA는 드문 접근용, 30일 최소 보관 요건 등 제약).


## #374
한 회사가 us-east-1 리전 내에서 서로 분리된 3개의 VPC에 여러 비즈니스 애플리케이션을 운영하고 있습니다. 이 애플리케이션들은 VPC 간 통신이 가능해야 합니다. 또한 단일 온프레미스 데이터 센터에서 실행되는 지연 시간에 민감한 애플리케이션으로 매일 수백 GB의 데이터를 지속적으로 전송할 수 있어야 합니다.

솔루션스 아키텍트는 비용 효율성을 극대화하는 네트워크 연결 솔루션을 설계해야 합니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 데이터 센터에서 AWS로 3개의 AWS Site-to-Site VPN 연결을 구성합니다. 각 VPC마다 하나의 VPN 연결을 구성하여 연결을 설정합니다.
B. 각 VPC에 서드파티 가상 네트워크 어플라이언스를 실행합니다. 데이터 센터와 각 가상 어플라이언스 간에 IPsec VPN 터널을 설정합니다.
C. 데이터 센터에서 us-east-1의 Direct Connect 게이트웨이로 3개의 AWS Direct Connect 연결을 설정합니다. 각 VPC가 하나의 Direct Connect 연결을 사용하도록 구성하여 연결을 설정합니다.
D. 데이터 센터에서 AWS로 1개의 AWS Direct Connect 연결을 설정합니다. Transit Gateway를 생성하여 각 VPC를 Transit Gateway에 연결합니다. Direct Connect 연결과 Transit Gateway 간의 연결을 설정합니다.

```
A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latency-sensitive application that runs in a single on-premises data center.  
  
A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness.  
  
Which solution meets these requirements?

- A. Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.
- B. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.
- C. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.
- D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.
```

정답 : `D`

- 지연 민감 + 대용량(수백 GB/일) 전송에는 전용선인 AWS Direct Connect가 적합 → 안정적인 대역폭, 지연
- 여러 VPC간 통신은 AWS Transit Gateway(TGW) 가 가장 단순하고 확장성 높은 허브-스포크 모델을 제공
- DX + TGW 연동(DX 게이트웨이 ↔ TGW 연결) 으로 단일 DX 회선만으로 온프레미스 ↔ 다수 VPC 연결을 공유할 수 있어 가성비 최적
	- TGW에 붙은 PVC들 끼리의 상호 통신도 지원

오답 이유

- **A. 3개의 Site-to-Site VPN**: 인터넷 기반으로 **지연/대역폭 변동**이 크며, **대용량·지연 민감** 요건에 부적합. 관리/운영도 늘어납니다.
    
- **B. VPC별 서드파티 VPN 어플라이언스**: 인터넷 경유 문제는 동일하고, **어플라이언스 운영 비용/복잡도**가 증가합니다.
    
- **C. VPC별 3개의 DX 회선**: 비용이 과도합니다. 또한 **Direct Connect Gateway는 VPC 간 라우팅을 제공하지 않으므로** VPC 간 통신 요구를 직접 충족하지 못합니다(추가로 피어링 등 필요).



## #375
한 전자상거래 회사가 주문 처리 작업을 완료하기 위해 여러 서버리스 함수와 AWS 서비스를 포함하는 분산 애플리케이션을 구축하고 있습니다. 이러한 작업에는 워크플로의 일부로 수동 승인이 필요합니다. 솔루션스 아키텍트는 주문 처리 애플리케이션을 위한 아키텍처를 설계해야 합니다. 솔루션은 여러 AWS Lambda 함수를 결합하여 반응형 서버리스 애플리케이션을 구성할 수 있어야 합니다. 또한 Amazon EC2 인스턴스, 컨테이너 또는 온프레미스 서버에서 실행되는 데이터와 서비스를 오케스트레이션할 수 있어야 합니다.

다음 중 운영 오버헤드를 가장 적게 들이면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Step Functions를 사용하여 애플리케이션을 구축한다.
B. 모든 애플리케이션 구성 요소를 AWS Glue 작업에 통합한다.
C. Amazon Simple Queue Service(Amazon SQS)를 사용하여 애플리케이션을 구축한다.
D. AWS Lambda 함수와 Amazon EventBridge 이벤트를 사용하여 애플리케이션을 구축한다.

```
An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete order-processing tasks. These tasks require manual approvals as part of the workflow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS Step Functions to build the application.
- B. Integrate all the application components in an AWS Glue job.
- C. Use Amazon Simple Queue Service (Amazon SQS) to build the application.
- D. Use AWS Lambda functions and Amazon EventBridge events to build the application.
```

정답 : `A`

- Step Functions는 서버리스 오케스트레이션으로 여러 람다 함수를 손쉽게 결합하고, 서비스 통합을 통해 EC2/컨테이너/온프레미스 작업도 코드 최소화로 호출 및 조율 가능
- 수동 승인은 Task Token(Callback), Wait 상태, Approval 패턴 등으로 구현 가능하여 주문 승인 플로우에 적합

오답 이유

- **B. AWS Glue**: ETL/데이터 통합 전용으로, **업무 워크플로 오케스트레이션**과 **사람 승인 절차**를 다루는 일반 애플리케이션 플로우에 부적합.
    
- **C. Amazon SQS**: 큐잉/버퍼링은 가능하지만 **상태 관리, 분기, 재시도 정책, 휴먼 승인** 같은 **완전한 오케스트레이션** 기능이 부족함. 별도 컴포넌트로 다 구현해야 해 운영 부담↑.
    
- **D. Lambda + EventBridge**: 이벤트 라우팅은 좋지만 **복잡한 상태 기반 오케스트레이션**(승인 대기, 보상 트랜잭션, 단계별 타임아웃/재시도)을 직접 코드/규칙로 관리해야 하므로 운영 복잡도↑.


## #376
한 회사가 Amazon RDS for MySQL DB 인스턴스를 시작했습니다. 데이터베이스에 대한 대부분의 연결은 서버리스 애플리케이션에서 발생합니다. 데이터베이스로의 애플리케이션 트래픽은 임의의 간격으로 크게 변합니다. 높은 수요 시점에는 사용자가 애플리케이션에서 데이터베이스 연결 거부 오류를 경험한다고 보고합니다.

가장 낮은 운영 오버헤드로 이 문제를 해결할 수 있는 솔루션은 무엇입니까?

A. RDS Proxy에서 프록시를 생성합니다. 사용자의 애플리케이션이 RDS Proxy를 통해 DB 인스턴스를 사용하도록 구성합니다.
B. 사용자의 애플리케이션과 DB 인스턴스 사이에 Amazon ElastiCache for Memcached를 배치합니다.
C. DB 인스턴스를 더 높은 I/O 용량을 가진 다른 인스턴스 클래스로 마이그레이션합니다. 사용자의 애플리케이션이 새 DB 인스턴스를 사용하도록 구성합니다.
D. DB 인스턴스에 대해 Multi-AZ를 구성합니다. 사용자의 애플리케이션이 DB 인스턴스 간에 전환하도록 구성합니다.

```
A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application traffic to the database changes significantly at random intervals. At times of high demand, users report that their applications experience database connection rejection errors.  
  
Which solution will resolve this issue with the LEAST operational overhead?

- A. Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.
- B. Deploy Amazon ElastiCache for Memcached between the users’ applications and the DB instance.
- C. Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users’ applications to use the new DB instance.
- D. Configure Multi-AZ for the DB instance. Configure the users’ applications to switch between the DB instances.
```

정답 : `A`

- 서버리스 워크로드는 트래픽 급증 시 동시 실행 증가로 데이터베이스 연결 폭주가 발생하기 쉬움
- Amazon RDS Proxy는 관리형 커넥션 풀링/멀티플렉싱을 제공
	- 애플리케이션의 폭발적인 연결은 안정적으로 흡수
	- 백엔드 DB로의 실제 연결 수를 제한해 연결 거부와 타임 아웃을 줄임
- 프록시 생성 후 애플리케이션의 엔드포인트만 프록시로 변경하면 돼 운영 오버헤드가 가장 낮음

오답 이유

- **B. ElastiCache (Memcached)**: 캐싱은 읽기 지연/부하 완화에는 도움되지만 **DB 연결 수 제한 문제**를 해결하지 못합니다. 연결 풀링 기능이 아닙니다.
    
- **C. 상위 인스턴스 클래스로 변경**: 일시적으로 성능 여유는 늘 수 있으나 **연결 폭주 자체**를 제어하지 못해 **connection limit** 문제는 재발합니다. 비용 증가도 큼.
    
- **D. Multi-AZ 구성**: 고가용성/장애조치 목적이며 **접속 수용 능력이나 연결 관리**를 늘려주지 않습니다. 또한 애플리케이션이 인스턴스 간 전환을 직접 처리할 필요도 없습니다.


## #377
한 회사가 최근 Amazon EC2 인스턴스의 운영 체제 버전, 패치 상태, 설치 소프트웨어에 대한 정보를 중앙집중화하기 위한 새로운 감사 시스템을 배포했습니다. 솔루션스 아키텍트는 EC2 Auto Scaling 그룹을 통해 프로비저닝되는 모든 인스턴스가 시작 및 종료되자마자 감사 시스템으로 보고서를 성공적으로 전송하도록 보장해야 합니다.

다음 중 이러한 목표를 가장 효율적으로 달성하는 솔루션은 무엇입니까?

A. 예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 감사 시스템으로 데이터를 전송합니다.
B. EC2 Auto Scaling 라이프사이클 훅을 사용하여 인스턴스가 시작되고 종료될 때 사용자 지정 스크립트를 실행하여 감사 시스템으로 데이터를 전송합니다.
C. EC2 Auto Scaling 시작 구성(Launch Configuration)을 사용하여 사용자 데이터(User Data)를 통해 사용자 지정 스크립트를 실행하여 인스턴스가 시작되고 종료될 때 감사 시스템으로 데이터를 전송합니다.
D. 인스턴스 운영 체제에서 사용자 지정 스크립트를 실행하여 감사 시스템으로 데이터를 전송합니다. 인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹이 해당 스크립트를 호출하도록 구성합니다.

```
A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated.  
  
Which solution achieves these goals MOST efficiently?

- A. Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.
- B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.
- C. Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.
- D. Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated.
```

정답 : `B`

- 라이프사이클 훅은 인스턴스라 Launching/Terminating 상태로 전환될 때 훅을 걸어 지정된 작업을 신뢰성 있게 수행할 수 있음
- 훅은 대기(heartbeat)와 타임아웃을 제공하므로, 감사 시스템으로의 보고가 완료될 때까지 인스턴스 장태 전이를 제어 가능
- SQS/SNS/EventBridge와 연계하거나, AWS Lambda/System Manager Run Command를 호출해 스크립트를 실행하는 등의 유연한 오케스트레이션이 가능해 가장 효율적이고 운영 오버헤드가 낮음

오답 이유

- **A. 예약 Lambda로 원격 실행**
    - 스케줄 기반은 **즉시성 보장 불가**(“시작/종료되자마자” 요구 충족 어려움). 모든 인스턴스를 주기적으로 스캔하는 것은 **비효율/지연**이 큼.
    
- **C. User Data로 시작 시만 처리**
    - User Data는 **부팅 시점 작업**에 적합하지만 **종료(terminate) 시점**에는 실행되지 않습니다. 종료 보고 요건을 충족하지 못함.
    
- **D. 인스턴스 내 스크립트 + ASG가 호출**
    - ASG가 인스턴스 내 스크립트를 직접 “호출”하는 메커니즘은 없습니다. 종료 시 실행도 **OS 수준에서 신뢰성 보장 어려움**(예: 강제 종료, Spot 중단 등). 라이프사이클 훅이 정석.


## #378
한 회사가 실시간 멀티플레이어 게임을 개발 중이며, 클라이언트와 Auto Scaling 그룹의 서버 간 통신에 UDP를 사용합니다. 낮 동안 수요 급증이 예상되므로 게임 서버 플랫폼은 이에 맞게 적응해야 합니다. 개발자들은 게이머 점수와 기타 비정형(non-relational) 데이터를 개입 없이 확장되는 데이터베이스 솔루션에 저장하고자 합니다.

솔루션스 아키텍트는 어떤 솔루션을 권장해야 합니까?

A. 트래픽 분산에는 Amazon Route 53을 사용하고, 데이터 저장에는 Amazon Aurora Serverless를 사용합니다.
B. 트래픽 분산에는 Network Load Balancer를 사용하고, 데이터 저장에는 Amazon DynamoDB 온디맨드를 사용합니다.
C. 트래픽 분산에는 Network Load Balancer를 사용하고, 데이터 저장에는 Amazon Aurora Global Database를 사용합니다.
D. 트래픽 분산에는 Application Load Balancer를 사용하고, 데이터 저장에는 Amazon DynamoDB 글로벌 테이블을 사용합니다.

```
A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention.  
  
Which solution should a solutions architect recommend?

- A. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.
- B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.
- C. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.
- D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage.
```

정답 : `B`

- L4에서 UDP를 지원하는 것은 NLB이며, 오토 스케일링 그룹의 백엔드 서버로 확장/축소 시에도 안정적으로 분산 가능
- DynamoDB 온디맨드는 프로비저닝 없이 트래픽에 맞춰 자동으로 스케일하며, 운영 개입이 최소
	- 실시간 게임 점수･프로필 같은 키-값/문서형 데이터에 적합

오답 이유

- **A. Route 53 + Aurora Serverless**
    - Route 53은 **DNS**로, **L4 UDP 로드밸런싱을 제공하지 않음**. Aurora는 **관계형**이며 요구사항은 **비정형 데이터**.
    
- **C. NLB + Aurora Global Database**
    - NLB는 적합하나, Aurora Global Database 역시 **관계형**으로 비정형 데이터 및 무개입 확장 요구에 부적합.
    
- **D. ALB + DynamoDB 글로벌 테이블**
    - **ALB는 L7(HTTP/HTTPS)** 전용으로 **UDP 미지원**. DynamoDB 글로벌 테이블은 다중 리전 복제 시 유용하지만, 문제 요구(무개입 확장) 충족에 **필수는 아님**이며 ALB가 치명적으로 부적합.



## #379
한 회사가 AWS Lambda와 통합된 Amazon API Gateway API 백엔드를 사용하는 프런트엔드 애플리케이션을 호스팅하고 있습니다. API가 요청을 받으면, Lambda 함수는 많은 라이브러리를 로드합니다. 그런 다음 Lambda 함수는 Amazon RDS 데이터베이스에 연결하고 데이터를 처리한 후, 데이터를 프런트엔드 애플리케이션으로 반환합니다. 회사는 운영 변경을 최소화하면서 모든 사용자에 대해 응답 지연 시간을 가능한 한 낮게 유지하고자 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 쿼리를 더 빠르게 하기 위해 프런트엔드 애플리케이션과 데이터베이스 사이에 연결을 설정하여 API를 우회합니다.
B. 요청을 처리하는 Lambda 함수에 대해 프로비저닝된 동시성을 구성합니다.
C. 유사한 데이터셋의 더 빠른 검색을 위해 쿼리 결과를 Amazon S3에 캐시합니다.
D. Lambda가 한 번에 설정할 수 있는 연결 수를 늘리기 위해 데이터베이스의 크기를 늘립니다.

```
A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations.  
  
Which solution will meet these requirements?

- A. Establish a connection between the frontend application and the database to make queries faster by bypassing the API.
- B. Configure provisioned concurrency for the Lambda function that handles the requests.
- C. Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.
- D. Increase the size of the database to increase the number of connections Lambda can establish at one time.
```

정답 : `B`

- 문제의 병목은 콜드스타트(많은 라이브러리 로드) + 초기 연결 설정에 따른 지연
- 프로비저닝된 동시성은 람다 인스턴스를 사전 초기화해 두므로 라이브러리 로드/런타임 초기화 지연을 제거해 일관된 낮은 지연 제공
- 운영 변화가 적고(설정만으로 적용), 트래픽 패턴에 맞춰 예약/자동 스케일 조합도 가능해 요구사항에 가장 부합

오답 이유

- **A. API 우회하여 DB 직접 연결**
    - 아키텍처 변경이 큼(보안/자격 증명/연결 관리 복잡도 증가)이며, 지연 개선도 보장되지 않습니다. 백엔드 계층(비즈니스 로직) 무시로 보안·거버넌스 저하.
    
- **C. S3 캐시**
    - 캐시 적중시에만 효과가 있고 **일반화된 지연 감소 보장 불가**. 일관성/만료 관리 등 운영 부담이 늘어납니다.
    
- **D. DB 사이즈 증가**
    - 연결 한도는 늘 수 있으나 **콜드스타트로 인한 지연**을 해결하지 못합니다. 비용만 증가하고 “모든 사용자에 낮은 지연”과 직접적 연관이 약함.


## #380
한 회사가 온프레미스 워크로드를 AWS 클라우드로 마이그레이션하고 있습니다. 회사는 이미 여러 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 사용하고 있습니다. 회사는 업무 시간 외에 EC2 인스턴스와 DB 인스턴스를 자동으로 시작/중지하는 솔루션을 원합니다. 이 솔루션은 비용과 인프라 유지보수를 최소화해야 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 탄력적 리사이즈(elastic resize)를 사용하여 EC2 인스턴스를 스케일합니다. 업무 시간 외에는 DB 인스턴스를 0으로 스케일합니다.
B. EC2 인스턴스와 DB 인스턴스를 일정에 따라 자동으로 시작/중지하는 파트너 솔루션을 AWS Marketplace에서 찾아봅니다.
C. 다른 EC2 인스턴스를 시작합니다. crontab 스케줄을 구성하여 기존 EC2 인스턴스와 DB 인스턴스를 일정에 따라 시작/중지하는 셸 스크립트를 실행합니다.
D. EC2 인스턴스와 DB 인스턴스를 시작/중지하는 AWS Lambda 함수를 생성합니다. Amazon EventBridge가 이 Lambda 함수를 일정에 따라 호출하도록 구성합니다.

```
A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance.  
  
Which solution will meet these requirements?

- A. Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.
- B. Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.
- C. Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.
- D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.
```

정답 : `D`

- 서버리스 구성으로 별도 구성 없이 일정에 따라 Ec2 인스턴스 및 RDS DB 인스턴스를 제어할 수 있어 비용 및 운영 오버헤드 최소화
- EventBridge 크론/율 스케줄로 정해진 업무 시간 외 자동 중지, 업무 시작 전 자동 시작을 쉽게 구현

오답 이유

- **A:** EC2에 “elastic resize” 개념은 없으며, **RDS를 0으로 스케일**하는 기능도 일반 RDS에는 없습니다(일부 엔진/옵션의 일시 정지 기능과는 다름). 요구 사항과 불일치.
    
- **B:** 마켓플레이스 솔루션은 **추가 비용**이 들고 관리 복잡성이 증가할 수 있습니다. 동일 기능을 네이티브 **Lambda + EventBridge** 로 간단히 해결 가능.
    
- **C:** 스케줄용으로 **추가 EC2 인스턴스**를 운용하면 비용/패치/장애 관리 등 **운영 부담**이 불필요하게 증가합니다. 서버리스를 쓰는 편이 효율적.