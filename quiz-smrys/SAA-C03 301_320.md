---
created: 2025-10-03 09:53:48
last_modified: 2025-10-03 11:24:54
---
## #301
한 대학 연구소는 온프레미스 Windows 파일 서버에서 Amazon FSx for Windows File Server로 30TB 데이터를 마이그레이션해야 합니다. 연구소에는 다른 학과와 공유하는 1Gbps 네트워크 링크가 있습니다.

연구소는 데이터 전송 성능을 최대화할 수 있는 데이터 마이그레이션 서비스를 구현하려고 합니다. 그러나 다른 학과에 미치는 영향을 최소화하기 위해 서비스에서 사용하는 대역폭을 제어할 수 있어야 합니다. 데이터 마이그레이션은 향후 5일 이내에 완료되어야 합니다.

이 요구 사항을 충족하는 AWS 솔루션은 무엇입니까?

A. AWS Snowcone  
B. Amazon FSx File Gateway  
C. AWS DataSync  
D. AWS Transfer Family  

```
A university research laboratory needs to migrate 30 TB of data from an on-premises Windows file server to Amazon FSx for Windows File Server. The laboratory has a 1 Gbps network link that many other departments in the university share.  
  
The laboratory wants to implement a data migration service that will maximize the performance of the data transfer. However, the laboratory needs to be able to control the amount of bandwidth that the service uses to minimize the impact on other departments. The data migration must take place within the next 5 days.  
  
Which AWS solution will meet these requirements?

- A. AWS Snowcone
- B. Amazon FSx File Gateway
- C. AWS DataSync
- D. AWS Transfer Family
```

정답 : `C`

- AWS DataSync는 멀티 스레드, 프로토콜 최적화, 병렬 전송을 통해 네트워크 기반 데이터 마이그레이션 속도를 극대화. 최대 수백 TB까지 빠른 전송 가능
- DataSync는 대역폭 제한(스로틀링) 기능을 제공하여, 특정 시간대에 사용할 네트워크 속도를 조정 가능
- 30TB 데이터를 1Gbps 링크로 5일 내 전송은 이론적으로 가능(1Gbps ≈ 125MB/s → 하루 약 10TB 전송 가능)

오답 이유

- **A. AWS Snowcone**: 물리 장비를 배송받아 데이터를 옮기는 방식. 빠른 네트워크가 이미 존재하므로 불필요하게 시간 지연 발생 (배송+설정).
    
- **B. Amazon FSx File Gateway**: 온프레미스 애플리케이션이 **클라우드 기반 FSx**에 접근할 수 있도록 제공하는 캐싱/브리지 솔루션이지, **대규모 데이터 마이그레이션**용이 아님.
    
- **D. AWS Transfer Family**: SFTP/FTPS/FTP 프로토콜 기반 파일 전송 서비스. 주로 **사용자 단위 업로드/다운로드**용이지, 대규모 마이그레이션을 위한 고속 최적화 기능 없음.


## #302
한 회사가 사용자가 모바일 기기에서 슬로 모션 비디오 클립을 스트리밍할 수 있는 모바일 앱을 만들고자 합니다. 현재 앱은 비디오 클립을 캡처한 뒤 원시(raw) 형식으로 Amazon S3 버킷에 업로드합니다. 앱은 이 비디오 클립을 S3 버킷에서 직접 가져옵니다. 그러나 원시 형식의 비디오는 용량이 큽니다.

사용자들은 모바일 기기에서 버퍼링과 재생 문제를 겪고 있습니다. 회사는 운영 오버헤드를 최소화하면서 앱의 성능과 확장성을 극대화할 수 있는 솔루션을 구현하고자 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (두 개 선택)

A. 콘텐츠 전송과 캐싱을 위해 Amazon CloudFront를 배포합니다.
B. AWS DataSync을 사용하여 다른 리전의 S3 버킷으로 비디오 파일을 복제합니다.
C. Amazon Elastic Transcoder를 사용하여 비디오 파일을 보다 적절한 형식으로 변환합니다.
D. 콘텐츠 전송과 캐싱을 위해 Local Zones에 Amazon EC2 인스턴스의 Auto Scaling 그룹을 배포합니다.
E. 비디오 파일을 보다 적절한 형식으로 변환하기 위해 Amazon EC2 인스턴스의 Auto Scaling 그룹을 배포합니다.

```
A company wants to create a mobile app that allows users to stream slow-motion video clips on their mobile devices. Currently, the app captures video clips and uploads the video clips in raw format into an Amazon S3 bucket. The app retrieves these video clips directly from the S3 bucket. However, the videos are large in their raw format.  
  
Users are experiencing issues with buffering and playback on mobile devices. The company wants to implement solutions to maximize the performance and scalability of the app while minimizing operational overhead.  
  
Which combination of solutions will meet these requirements? (Choose two.)

- A. Deploy Amazon CloudFront for content delivery and caching.
- B. Use AWS DataSync to replicate the video files across AW'S Regions in other S3 buckets.
- C. Use Amazon Elastic Transcoder to convert the video files to more appropriate formats.
- D. Deploy an Auto Sealing group of Amazon EC2 instances in Local Zones for content delivery and caching.
- E. Deploy an Auto Scaling group of Amazon EC2 instances to convert the video files to more appropriate formats.
```

정답 : `A, C`

- CloudFront: 전 세계 엣지에서 캐싱/가속으로 지연을 줄이고, S3 원본 부담을 낮춰 성능･확장성을 크게 개선
- Elastic Transcoder: 원시 대용량 대신 모바일 친화적 비트레이트/코덱/해상도로 트랜스코딩하여 버퍼링 감소와 대역폭 절감
	- 현업에서는 AWS Elemental MediaConvert가 권장

오답 이유

- **B (DataSync 복제)**: 지역 간 복제는 운영 비용과 복잡성만 늘리고, **스트리밍 성능 문제(대용량 원본, 캐싱 부재)**의 근본 원인을 해결하지 못합니다. CloudFront로 글로벌 엣지 캐싱을 쓰는 것이 정석입니다.
    
- **D (Local Zones + EC2 캐싱)**: CDN을 대체하는 과도한 설계입니다. **CloudFront가 관리형으로 더 저비용/저운영오버헤드**이며 전 세계 커버리지를 제공합니다.
    
- **E (EC2로 자체 트랜스코딩)**: 가능하지만 **관리형 트랜스코딩 서비스**(Elastic Transcoder/MediaConvert) 대비 **운영 오버헤드와 비용**이 증가합니다(확장, 큐 관리, 장애 처리, 패치 등).


## #303
회사는 Amazon Elastic Container Service (Amazon ECS) 클러스터에 배포된 새 애플리케이션을 출시하며 ECS 태스크에 Fargate 실행 유형을 사용하고 있습니다. 회사는 출시 시 애플리케이션에 높은 트래픽이 예상되므로 CPU 및 메모리 사용량을 모니터링하고 있습니다. 그러나 사용률이 감소할 때 비용을 절감하고자 합니다.

솔루션스 아키텍트는 무엇을 권장해야 합니까?

A. 이전 트래픽 패턴을 기반으로 특정 기간에 스케일링하도록 Amazon EC2 Auto Scaling을 사용합니다.
B. Amazon CloudWatch 알람을 트리거하는 지표 임계값 초과를 기반으로 AWS Lambda 함수를 사용해 Amazon ECS를 스케일링합니다.
C. Amazon CloudWatch 알람을 트리거하는 ECS 지표 임계값 초과 시 스케일링하도록 간단한 스케일링 정책이 있는 Amazon EC2 Auto Scaling을 사용합니다.
D. Amazon CloudWatch 알람을 트리거하는 ECS 지표 임계값 초과 시 스케일링하도록 대상 추적 정책이 있는 AWS Application Auto Scaling을 사용합니다.

```
A company is launching a new application deployed on an Amazon Elastic Container Service (Amazon ECS) cluster and is using the Fargate launch type for ECS tasks. The company is monitoring CPU and memory usage because it is expecting high traffic to the application upon its launch. However, the company wants to reduce costs when utilization decreases.  
  
What should a solutions architect recommend?

- A. Use Amazon EC2 Auto Scaling to scale at certain periods based on previous traffic patterns.
- B. Use an AWS Lambda function to scale Amazon ECS based on metric breaches that trigger an Amazon CloudWatch alarm.
- C. Use Amazon EC2 Auto Scaling with simple scaling policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.
- D. Use AWS Application Auto Scaling with target tracking policies to scale when ECS metric breaches trigger an Amazon CloudWatch alarm.
```

정답 : `D`

- Fargate 실행 유형에서는 EC2 오토 스케일링이 아니라 ECS 서비스 스케일링을 사용해야 하고 이는 AWS Application Auto Scaling을 통해 이루어짐
- 가장 간단하고 비용 효율적인 방법은 대상 추적(Target Tracking) 정책
	- 서비스의 CPU/메모리 사용률 목표치를 설정해 자동으로 태스크 수를 증감

오답 이유

- **A. EC2 Auto Scaling**: Fargate는 EC2 인스턴스를 관리하지 않습니다. EC2 ASG로는 ECS 태스크 수 조절을 할 수 없습니다.
    
- **B. Lambda로 수동 스케일**: 가능은 하지만 불필요한 커스텀 로직과 운영 오버헤드를 유발합니다. 관리형인 Application Auto Scaling이 정석입니다.
    
- **C. EC2 Auto Scaling + 간단 스케일링**: 마찬가지로 EC2 대상이며 Fargate/ECS 서비스 스케일링과 무관합니다.


## #304
한 회사가 최근 다른 AWS 리전에 재해 복구(Disaster Recovery) 사이트를 구축했습니다. 회사는 주기적으로 두 리전에 있는 NFS 파일 시스템 간에 대량의 데이터를 양방향으로 전송해야 합니다.

다음 중 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS DataSync를 사용합니다.
B. AWS Snowball 디바이스를 사용합니다.
C. Amazon EC2에 SFTP 서버를 설정합니다.
D. AWS Database Migration Service (AWS DMS)를 사용합니다.

```
A company recently created a disaster recovery site in a different AWS Region. The company needs to transfer large amounts of data back and forth between NFS file systems in the two Regions on a periodic basis.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS DataSync.
- B. Use AWS Snowball devices.
- C. Set up an SFTP server on Amazon EC2.
- D. Use AWS Database Migration Service (AWS DMS).
```

정답 : `A`

- AWS DataSync는 NFS/SMB/S3/FSx/EFS 간의 대규모 데이터 이동을 자동화･가속화 하는 관리형 서비스
- 에이전트 설치 후 작업만 정의하면 증분 전송, 압축/가속, 스케줄링, 검증, 암호화, 대역폭 제한 등 지원
- 리전 간 NFS ↔ NFS 주기적 동기화를 최소 운영 오버헤드로 수행 가능

오답 이유

- **B. AWS Snowball**: 대용량 **오프라인 일회성/비정기** 이동에 적합합니다. 주기적으로 양방향 전송하려면 장비 주문/배송/반납 등 운영 부담이 큼.
    
- **C. EC2 SFTP 서버**: 프로토콜 변환 및 예약/증분/무결성 검증/오류 재시도 등을 **직접 구현·운영**해야 하므로 오버헤드가 큼. 확장성/관리성도 떨어짐.
    
- **D. AWS DMS**: **데이터베이스 복제/마이그레이션** 전용 서비스입니다. 파일 시스템(NFS) 간 파일 전송 요구에 부적합합니다.


## #305
회사가 AWS 클라우드에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 설계하고 있습니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있는 기능이 필요합니다. 이 솔루션은 완전 관리형이어야 합니다.

다음 중 어떤 AWS 솔루션이 이러한 요구 사항을 충족합니까?

A. 데이터를 마운트 가능한 파일 시스템으로 공유하는 AWS DataSync 작업을 생성합니다. 파일 시스템을 애플리케이션 서버에 마운트합니다.  
B. Amazon EC2 Windows 인스턴스를 생성합니다. Windows 파일 공유 역할을 인스턴스에 설치 및 구성합니다. 애플리케이션 서버를 파일 공유에 연결합니다.  
C. Amazon FSx for Windows File Server 파일 시스템을 생성합니다. 파일 시스템을 원본 서버에 연결합니다. 애플리케이션 서버를 파일 시스템에 연결합니다.  
D. Amazon S3 버킷을 생성합니다. 애플리케이션에 S3 버킷에 대한 액세스를 허용하는 IAM 역할을 할당합니다. 애플리케이션 서버에 S3 버킷을 마운트합니다.

```
A company is designing a shared storage solution for a gaming application that is hosted in the AWS Cloud. The company needs the ability to use SMB clients to access data. The solution must be fully managed.  
  
Which AWS solution meets these requirements?

- A. Create an AWS DataSync task that shares the data as a mountable file system. Mount the file system to the application server.
- B. Create an Amazon EC2 Windows instance. Install and configure a Windows file share role on the instance. Connect the application server to the file share.
- C. Create an Amazon FSx for Windows File Server file system. Attach the file system to the origin server. Connect the application server to the file system.
- D. Create an Amazon S3 bucket. Assign an IAM role to the application to grant access to the S3 bucket. Mount the S3 bucket to the application server.
```

정답 : `C`

- Amazon FSx for Windows File Server는 SMB 프로토콜을 기본 지원하는 완전관리형 파일 스토리지 서비스
- ACL(액세스 제어), 고가용성, 자동 백업 등을 지원하므로 SMB 클라이언트를 사용하는 Windows/Linux 애플리케이션과 호환성 보장

오답 이유

- **A. AWS DataSync**: DataSync는 **데이터 전송/복제 서비스**이지 공유 파일 스토리지 서비스가 아님. 지속적인 SMB 파일 공유를 제공하지 않음.
    
- **B. EC2 Windows 인스턴스**: Windows 파일 서버를 직접 운영 가능하지만 **완전 관리형이 아님**. 관리 및 유지보수(패치, 확장성, 장애 대응 등) 부담이 큼.
    
- **D. Amazon S3**: S3는 객체 스토리지이며, **SMB 프로토콜을 지원하지 않음**. 추가 도구를 통해 마운트 가능하지만 완전 관리형 SMB 솔루션은 아님.



## #306
회사는 Amazon EC2 인스턴스에서 실행되는 지연 시간에 민감한 애플리케이션을 위해 인메모리 데이터베이스를 실행하려고 합니다. 이 애플리케이션은 분당 100,000건 이상의 트랜잭션을 처리하며 높은 네트워크 처리량이 필요합니다. 솔루션스 아키텍트는 데이터 전송 요금을 최소화하면서 비용 효율적인 네트워크 설계를 제공해야 합니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 동일한 AWS 리전 내에서 모든 EC2 인스턴스를 동일한 가용 영역에 시작합니다. EC2 인스턴스를 시작할 때 클러스터 전략을 가진 배치 그룹(placement group)을 지정합니다.
B. 동일한 AWS 리전 내에서 모든 EC2 인스턴스를 서로 다른 가용 영역에 시작합니다. EC2 인스턴스를 시작할 때 파티션 전략을 가진 배치 그룹을 지정합니다.
C. 네트워크 사용량 목표를 기준으로 서로 다른 가용 영역에 EC2 인스턴스를 시작하도록 Auto Scaling 그룹을 배포합니다.
D. 단계적 스케일링 정책을 사용하는 Auto Scaling 그룹을 배포하여 서로 다른 가용 영역에 EC2 인스턴스를 시작합니다.

```
A company wants to run an in-memory database for a latency-sensitive application that runs on Amazon EC2 instances. The application processes more than 100,000 transactions each minute and requires high network throughput. A solutions architect needs to provide a cost-effective network design that minimizes data transfer charges.  
  
Which solution meets these requirements?

- A. Launch all EC2 instances in the same Availability Zone within the same AWS Region. Specify a placement group with cluster strategy when launching EC2 instances.
- B. Launch all EC2 instances in different Availability Zones within the same AWS Region. Specify a placement group with partition strategy when launching EC2 instances.
- C. Deploy an Auto Scaling group to launch EC2 instances in different Availability Zones based on a network utilization target.
- D. Deploy an Auto Scaling group with a step scaling policy to launch EC2 instances in different Availability Zones.
```

정답 : `A`

- 클러스터 배치 그룹은 동일 AZ 내 물리적으로 가까운 랙에 인스턴스를 배치해 초저지연과 고대역폭을 제공하고
	- 인메모리 DB와 같은 고빈도 트랜잭션/저지연 워크로드에 최적
- 동일 AZ 내 트래픽은 교차 AZ 데이터 전송 요금이 발생하지 않음
- 추가 복잡도 없이 배치 그룹만 지정하면 돼 운영 오버헤드가 낮음

오답 이유

- **B. 파티션 배치 그룹, 멀티 AZ**: 파티션 전략은 대규모 분산/내결함성에 유리하지만, 인스턴스가 여러 AZ로 흩어져 **교차 AZ 트래픽 비용**과 **지연 증가**가 발생할 수 있어 요구(저지연·저비용)에 부적합.
    
- **C. 네트워크 타겟 기반 멀티 AZ Auto Scaling**: 스케일링 정책은 용량 조절에는 도움되지만, **저지연·고처리량** 자체를 보장하지 못하고 **교차 AZ 비용**을 유발할 수 있음.
    
- **D. 단계적 스케일링 멀티 AZ**: C와 동일한 문제. 스케일링 방식의 차이일 뿐, **네트워크 성능 최적화/전송 비용 최소화** 요구를 충족하지 못함.


## #307
회사는 주로 온프레미스에서 애플리케이션 서버를 운영해왔지만, AWS로 마이그레이션하기로 결정했습니다. 회사는 온프레미스에서 Internet Small Computer Systems Interface(iSCSI) 스토리지를 확장해야 하는 필요성을 최소화하고자 합니다. 회사는 최근에 액세스한 데이터만 로컬에 저장되기를 원합니다.

이 요구사항을 충족하기 위해 회사가 사용해야 하는 AWS 솔루션은 무엇입니까?

A. Amazon S3 File Gateway  
B. AWS Storage Gateway Tape Gateway  
C. AWS Storage Gateway Volume Gateway stored volumes  
D. AWS Storage Gateway Volume Gateway cached volumes  

```
A company that primarily runs its application servers on premises has decided to migrate to AWS. The company wants to minimize its need to scale its Internet Small Computer Systems Interface (iSCSI) storage on premises. The company wants only its recently accessed data to remain stored locally.  
  
Which AWS solution should the company use to meet these requirements?

- A. Amazon S3 File Gateway
- B. AWS Storage Gateway Tape Gateway
- C. AWS Storage Gateway Volume Gateway stored volumes
- D. AWS Storage Gateway Volume Gateway cached volumes
```

정답 : `D`

- Volume Gateway (cached volumes): 자주 액세스하는 데이터만 로컬에 캐시하고, 나머지 데이터는 S3에 저장
- 온프레미스 iSCSI 스토리지 확장을 최소화하면서 요구사항 충족

오답 이유

- **A. Amazon S3 File Gateway**: S3 객체 스토리지를 **NFS/SMB 파일 인터페이스**로 제공하는 서비스. iSCSI 블록 스토리지 요구사항에는 맞지 않음.
    
- **B. Tape Gateway**: 백업/아카이브 목적의 **가상 테이프 라이브러리(VTL)**. 운영 스토리지나 최근 데이터 캐싱과 무관.
    
- **C. Stored Volumes**: 전체 데이터 세트를 온프레미스에 저장하고, 비동기적으로 S3에 백업 → 로컬 스토리지 확장을 여전히 요구하므로 문제 조건 불만족.



## #308
한 회사는 통합 결제를 사용하는 여러 AWS 계정을 보유하고 있습니다. 이 회사는 90일 동안 여러 활성 고성능 Amazon RDS for Oracle 온디맨드 DB 인스턴스를 실행하고 있습니다. 회사의 재무팀은 통합 결제 계정과 다른 모든 AWS 계정에서 AWS Trusted Advisor에 액세스할 수 있습니다.  

재무팀은 RDS 비용을 절감하기 위해 RDS에 대한 Trusted Advisor 체크 권장 사항에 액세스하기 위해 적절한 AWS 계정을 사용해야 합니다. 재무팀은 RDS 비용을 줄이기 위해 적절한 Trusted Advisor 체크를 검토해야 합니다.  

이 요구 사항을 충족하기 위해 재무팀이 수행해야 할 단계 조합은 무엇입니까? (2가지를 선택하십시오.)  

A. RDS 인스턴스가 실행 중인 계정에서 Trusted Advisor 권장 사항을 사용한다.  
B. 통합 결제 계정에서 Trusted Advisor 권장 사항을 사용하여 모든 RDS 인스턴스 체크를 동시에 확인한다.  
C. Amazon RDS 예약 인스턴스 최적화에 대한 Trusted Advisor 체크를 검토한다.  
D. Amazon RDS 유휴 DB 인스턴스에 대한 Trusted Advisor 체크를 검토한다.  
E. Amazon Redshift 예약 노드 최적화에 대한 Trusted Advisor 체크를 검토한다.  

```
A company has multiple AWS accounts that use consolidated billing. The company runs several active high performance Amazon RDS for Oracle On-Demand DB instances for 90 days. The company’s finance team has access to AWS Trusted Advisor in the consolidated billing account and all other AWS accounts.  
  
The finance team needs to use the appropriate AWS account to access the Trusted Advisor check recommendations for RDS. The finance team must review the appropriate Trusted Advisor check to reduce RDS costs.  
  
Which combination of steps should the finance team take to meet these requirements? (Choose two.)

- A. Use the Trusted Advisor recommendations from the account where the RDS instances are running.
- B. Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time.
- C. Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.
- D. Review the Trusted Advisor check for Amazon RDS Idle DB Instances.
- E. Review the Trusted Advisor check for Amazon Redshift Reserved Node Optimization.
```

정답 : `A, C`

- AWS Trusted Advisor: 비용 최적화, 성능, 보안, 내결함성, 서비스 제한 등의 관점에서 리소스 사용 현황 점검
	- RDS 비용 절감 관련 주요 체크
		- RDS 예약 인스턴스 최적화: 일정 기간 동안 온디맨드로 실행 중인 RDS 인스턴스를 Reserved Instance로 전환 권장
		- RDS 유휴 인스턴스: 사용률이 낮거나 연결 없는 인스턴스 식별

오답 이유

- **B. 통합 결제 계정에서 Trusted Advisor 권장 사항을 사용하여 모든 RDS 인스턴스 체크를 동시에 확인한다.**
    → 잘못됨. 통합 결제 계정에서는 비용 관련 리포트를 볼 수 있지만, 개별 리소스 수준의 Trusted Advisor 체크(예: RDS 최적화)는 리소스가 실행되는 계정에서만 확인 가능.
    
- **D. Amazon RDS 유휴 DB 인스턴스 체크**
    → 문제의 조건은 **활성 DB 인스턴스**로, 유휴 인스턴스가 아니므로 관련 없음.
    
- **E. Amazon Redshift 예약 노드 최적화 체크**
    → RDS 비용 절감과 무관. Redshift 관련 체크임.


## #309
솔루션스 아키텍트는 스토리지 비용을 최적화해야 합니다. 솔루션스 아키텍트는 더 이상 액세스되지 않거나 거의 액세스되지 않는 Amazon S3 버킷을 식별해야 합니다.  

다음 중 최소한의 운영 오버헤드로 이 목표를 달성할 수 있는 솔루션은 무엇입니까?  

A. 고급 활동 지표에 대해 S3 Storage Lens 대시보드를 사용하여 버킷 액세스 패턴을 분석한다.  
B. AWS Management Console의 S3 대시보드를 사용하여 버킷 액세스 패턴을 분석한다.  
C. 버킷에 대해 Amazon CloudWatch BucketSizeBytes 지표를 활성화한다. Amazon Athena를 사용하여 메트릭 데이터를 분석하여 버킷 액세스 패턴을 확인한다.  
D. S3 객체 모니터링을 위해 AWS CloudTrail을 활성화한다. CloudWatch Logs와 통합된 CloudTrail 로그를 사용하여 버킷 액세스 패턴을 분석한다.  

```
A solutions architect needs to optimize storage costs. The solutions architect must identify any Amazon S3 buckets that are no longer being accessed or are rarely accessed.  
  
Which solution will accomplish this goal with the LEAST operational overhead?

- A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.
- B. Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console.
- C. Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena.
- D. Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs.
```

정답 : `A`

- S3 Storage Lens
	- S3 스토리지 사용 및 액세스 패턴을 계정 단위 또는 버킷 단위로 분석하는 관리형 서비스
	- 고급 지표를 활성화하면 액세스 빈도/패턴까지 확인 가능
	- 추가적인 로그 분석 파이프라인이 필요 없어 운영 오버헤드 최소화

오답 이유

- **B. AWS Management Console의 S3 대시보드 사용**
    → 단순 스토리지 크기/기본 정보만 제공. 액세스 패턴 분석 불가.
    
- **C. CloudWatch BucketSizeBytes + Athena 분석**
    → BucketSizeBytes 지표는 **스토리지 크기**만 알려줌. 접근 패턴(최근 액세스 여부)을 알 수 없음.
    
- **D. CloudTrail 로그 분석**
    → CloudTrail은 모든 S3 요청 이벤트를 캡처하지만 로그 볼륨이 많아지고, Athena/CloudWatch Logs와 통합해 분석하려면 운영 오버헤드가 크다.


## #310
한 회사는 인공지능/머신러닝(AI/ML) 연구를 하는 고객에게 데이터셋을 판매합니다. 데이터셋은 용량이 크고 포맷된 파일이며, 미 동부(us-east-1) 리전에 있는 Amazon S3 버킷에 저장되어 있습니다. 회사는 고객이 특정 데이터셋에 대한 접근을 구매하는 데 사용하는 웹 애플리케이션을 호스팅합니다. 웹 애플리케이션은 Application Load Balancer 뒤의 여러 Amazon EC2 인스턴스에 배포되어 있습니다. 구매가 완료되면 고객은 파일에 접근할 수 있는 S3 서명 URL을 받습니다.

고객은 북미와 유럽 전역에 분포해 있습니다. 회사는 데이터 전송에 관련된 비용을 줄이면서 성능을 유지하거나 개선하고자 합니다.

이 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 기존 S3 버킷에서 S3 Transfer Acceleration을 구성합니다. 고객 요청을 S3 Transfer Acceleration 엔드포인트로 유도합니다. 접근 제어는 계속 S3 서명 URL을 사용합니다.
B. 기존 S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 구축합니다. 고객 요청을 CloudFront URL로 유도합니다. 접근 제어는 CloudFront 서명 URL로 전환합니다.
C. eu-central-1 리전에 두 번째 S3 버킷을 설정하고, 버킷 간 S3 크로스 리전 복제를 구성합니다. 고객 요청을 가장 가까운 리전으로 유도합니다. 접근 제어는 계속 S3 서명 URL을 사용합니다.
D. 웹 애플리케이션을 수정하여 데이터셋을 최종 사용자에게 스트리밍할 수 있게 합니다. 웹 애플리케이션이 기존 S3 버킷에서 데이터를 읽도록 구성합니다. 접근 제어는 애플리케이션에서 직접 구현합니다.

```
A company sells datasets to customers who do research in artificial intelligence and machine learning (AI/ML). The datasets are large, formatted files that are stored in an Amazon S3 bucket in the us-east-1 Region. The company hosts a web application that the customers use to purchase access to a given dataset. The web application is deployed on multiple Amazon EC2 instances behind an Application Load Balancer. After a purchase is made, customers receive an S3 signed URL that allows access to the files.  
  
The customers are distributed across North America and Europe. The company wants to reduce the cost that is associated with data transfers and wants to maintain or improve performance.  
  
What should a solutions architect do to meet these requirements?

- A. Configure S3 Transfer Acceleration on the existing S3 bucket. Direct customer requests to the S3 Transfer Acceleration endpoint. Continue to use S3 signed URLs for access control.
- B. Deploy an Amazon CloudFront distribution with the existing S3 bucket as the origin. Direct customer requests to the CloudFront URL. Switch to CloudFront signed URLs for access control.
- C. Set up a second S3 bucket in the eu-central-1 Region with S3 Cross-Region Replication between the buckets. Direct customer requests to the closest Region. Continue to use S3 signed URLs for access control.
- D. Modify the web application to enable streaming of the datasets to end users. Configure the web application to read the data from the existing S3 bucket. Implement access control directly in the application.
```

정답 : `B`

- CloudFront는 전 세계 엣지에서 캐싱/전달을 제공하여 **유럽·북미 사용자에게 지연을 낮추고 처리량을 높여 성능을 개선**
- **S3 → CloudFront 오리진 전송은 무료**(동일 리전 기준)이고, **사용자에게 나가는 데이터 전송 요금은 CloudFront가 S3 직접 전송보다 일반적으로 저렴**하여 **데이터 전송 비용을 절감**
- 접속 제어는 **CloudFront 서명 URL/쿠키**로 안전하게 대체 가능

오답 이유

- **A. S3 Transfer Acceleration**: 주로 **업로드 가속**에 이점이 크며, **추가 가속 요금**이 붙어 비용 절감 목표와 상충될 수 있습니다. 또한 엣지 캐싱이 없어 반복 다운로드 비용/성능 이점이 제한적입니다.
    
- **C. 리전 복제(CRR)**: **이중 저장 비용 + 복제 트래픽 비용**이 발생합니다. 여전히 S3에서 직접 전송하므로 데이터 전송 단가 절감 효과가 작고, 캐싱 이점도 없습니다.
    
- **D. 앱 스트리밍 구현**: 애플리케이션 변경이 필요하고 운영 오버헤드가 큽니다. 또한 네트워크 구간은 그대로라 **전송 비용 절감 효과가 없습니다.**


## #311
회사는 보험 견적을 처리하는 웹 애플리케이션을 AWS로 설계하고 있습니다. 사용자는 애플리케이션에 견적을 요청합니다. 견적은 유형(quote type)별로 분리되어야 하며, 24시간 이내에 응답되어야 하고, 유실되면 안 됩니다. 솔루션은 운영 효율을 극대화하고 유지 관리 부담을 최소화해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 견적 유형별로 여러 Amazon Kinesis 데이터 스트림을 생성합니다. 웹 애플리케이션이 적절한 데이터 스트림으로 메시지를 보내도록 구성합니다. 각 백엔드 애플리케이션 서버 그룹이 자신의 데이터 스트림에서 메시지를 풀링하도록 Kinesis Client Library(KCL)를 사용하도록 구성합니다.
B. 각 견적 유형에 대해 AWS Lambda 함수와 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Lambda 함수를 해당 SNS 주제에 구독시킵니다. 애플리케이션이 적절한 SNS 주제로 견적 요청을 게시하도록 구성합니다.
C. 단일 Amazon Simple Notification Service(Amazon SNS) 주제를 생성합니다. Amazon Simple Queue Service(Amazon SQS) 큐들을 SNS 주제에 구독시킵니다. SNS 메시지 필터링을 구성하여 견적 유형에 따라 적절한 SQS 큐로 메시지를 게시합니다. 각 백엔드 애플리케이션 서버는 자체 SQS 큐를 사용하도록 구성합니다.
D. 견적 유형별로 여러 Amazon Kinesis Data Firehose 딜리버리 스트림을 생성하여 Amazon OpenSearch Service 클러스터로 데이터 스트림을 전송합니다. 애플리케이션이 적절한 딜리버리 스트림으로 메시지를 보내도록 구성합니다. 각 백엔드 애플리케이션 서버 그룹이 OpenSearch Service에서 메시지를 검색하여 처리하도록 구성합니다.

```
A company is using AWS to design a web application that will process insurance quotes. Users will request quotes from the application. Quotes must be separated by quote type, must be responded to within 24 hours, and must not get lost. The solution must maximize operational efficiency and must minimize maintenance.  
  
Which solution meets these requirements?

- A. Create multiple Amazon Kinesis data streams based on the quote type. Configure the web application to send messages to the proper data stream. Configure each backend group of application servers to use the Kinesis Client Library (KCL) to pool messages from its own data stream.
- B. Create an AWS Lambda function and an Amazon Simple Notification Service (Amazon SNS) topic for each quote type. Subscribe the Lambda function to its associated SNS topic. Configure the application to publish requests for quotes to the appropriate SNS topic.
- C. Create a single Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon Simple Queue Service (Amazon SQS) queues to the SNS topic. Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to use its own SQS queue.
- D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon OpenSearch Service cluster. Configure the application to send messages to the proper delivery stream. Configure each backend group of application servers to search for the messages from OpenSearch Service and process them accordingly.
```

정답 : `C`

- SQS는 다중 AZ 내구성으로 메시지를 저장(보존기간 1~14일 설정 가능)하고, 가시성 타임아웃/재시도로 안전하게 전달
- SNS 메시지 필터링(Message Attribute)으로 한 개의 주제에서 견적 유형별 SQS 큐로 자동 라우팅이 가능해 구성과 운영이 단순
- 완전관리형 SNS+SQS 조합으로 서버 운영･확장 부담이 적고, 백엔드는 큐만 폴링하면 됨
- 24시간 이내 처리 용이: 큐 보존기간을 최소 1일 이상으로 두고, 백엔드 오토스케일/동시성으로 처리량을 조절하면 SLA 충족 용이

오답 이유

- **A. Kinesis Data Streams + KCL**
    - Kinesis는 스트리밍 처리/리플레이에 적합하지만 **컨슈머 샤딩/체크포인트/스케일링** 등 운영 복잡도가 큼. 기본 보존 24시간이긴 하나 **작업 큐/업무 메시징**에는 SQS가 더 적합하고 운영 부담이 낮음.
    
- **B. SNS 주제별 + Lambda 구독**
    - 유형 분리는 되지만 **Lambda 재시도/실패 시 DLQ 구성** 등 세심한 운영이 필요하며, 대량 트래픽에서 동시성/스로틀 관리 이슈 가능. 또한 “유실 방지”를 강하게 요구할 때는 **SQS 영속 큐**가 더 명확합니다.
    
- **D. Firehose → OpenSearch**
    - 분석/검색 파이프라인용이며 **업무 트랜잭션 처리 큐**로 부적절. 메시지 내구성/재시도语義가 요구사항과 맞지 않습니다.


## #312
한 회사의 애플리케이션은 여러 Amazon EC2 인스턴스에서 실행됩니다. 각 EC2 인스턴스에는 여러 개의 Amazon Elastic Block Store (Amazon EBS) 데이터 볼륨이 연결되어 있습니다. 애플리케이션의 EC2 인스턴스 구성과 데이터는 매일 밤 백업되어야 합니다. 또한 애플리케이션은 다른 AWS 리전에서 복구 가능해야 합니다.

다음 중 가장 운영상 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 애플리케이션의 EBS 볼륨에 대해 매일 밤 스냅샷을 예약하고 스냅샷을 다른 리전으로 복사하는 AWS Lambda 함수를 작성합니다.
B. AWS Backup을 사용하여 백업 계획을 생성하여 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다.
C. AWS Backup을 사용하여 백업 계획을 생성하여 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다.
D. 애플리케이션의 EBS 볼륨에 대해 매일 밤 스냅샷을 예약하고 스냅샷을 다른 가용 영역으로 복사하는 AWS Lambda 함수를 작성합니다.

```
A company has an application that runs on several Amazon EC2 instances. Each EC2 instance has multiple Amazon Elastic Block Store (Amazon EBS) data volumes attached to it. The application’s EC2 instance configuration and data need to be backed up nightly. The application also needs to be recoverable in a different AWS Region.  
  
Which solution will meet these requirements in the MOST operationally efficient way?

- A. Write an AWS Lambda function that schedules nightly snapshots of the application’s EBS volumes and copies the snapshots to a different Region.
- B. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EC2 instances as resources.
- C. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EBS volumes as resources.
- D. Write an AWS Lambda function that schedules nightly snapshots of the application's EBS volumes and copies the snapshots to a different Availability Zone.
```

정답 : `B`

- 요구사항에는 EC2 인스턴스 구성(메타데이터)과 데이터(EBS 볼륨)를 모두 백업해야하며, 다른 리전에서 복구 가능해야 함
- AWS Backup은 EC2 인스턴스 단위 백업을 지원하여 인스턴스 구성(AMI/인스턴스 메타데이터 포함)과 연결된 모든 EBS 볼륨을 함께 보호
- 또한, 백업 복사(Cross-Region copy) 정책으로 자동으로 다른 리전에 복제가 가능해 운영 오버헤드 최소화

오답 이유

- **A. Lambda로 EBS 스냅샷 + 크로스 리전 복사**: 스냅샷 스케줄링/복사/보존/태깅/복구 절차를 **직접 관리**해야 하므로 운영 부담이 큼. 또한 **인스턴스 구성**(네트워크/보안그룹/태그/런치 설정 등)을 포괄적으로 캡처하지 못함.
    
- **C. AWS Backup에 EBS 볼륨만 리소스로 추가**: 볼륨 데이터는 보호되지만 **EC2 인스턴스 구성 정보**는 별도로 다뤄야 하므로 복구 자동화/운영 효율이 떨어짐.
    
- **D. 스냅샷을 다른 가용 영역(AZ)으로 복사**: 요구사항은 **다른 리전**에서의 복구이며, AZ 간 복사는 리전 장애 대비가 되지 않음.


## #313
한 회사가 AWS에서 모바일 앱을 구축하고 있습니다. 회사는 수백만 명의 사용자에게 도달하기 위해 서비스를 확장하려고 합니다. 회사는 인증된 사용자가 모바일 기기에서 회사의 콘텐츠를 시청할 수 있도록 하는 플랫폼을 구축해야 합니다.

솔루션스 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 권장해야 합니까?

A. 콘텐츠를 퍼블릭 Amazon S3 버킷에 게시합니다. AWS Key Management Service (AWS KMS) 키를 사용하여 콘텐츠를 스트리밍합니다.
B. 모바일 앱과 AWS 환경 간에 IPsec VPN을 설정하여 콘텐츠를 스트리밍합니다.
C. Amazon CloudFront를 사용합니다. 콘텐츠 스트리밍을 위해 서명된 URL을 제공합니다.
D. 모바일 앱과 AWS 환경 간에 AWS Client VPN을 설정하여 콘텐츠를 스트리밍합니다.

```
A company is building a mobile app on AWS. The company wants to expand its reach to millions of users. The company needs to build a platform so that authorized users can watch the company’s content on their mobile devices.  
  
What should a solutions architect recommend to meet these requirements?

- A. Publish content to a public Amazon S3 bucket. Use AWS Key Management Service (AWS KMS) keys to stream content.
- B. Set up IPsec VPN between the mobile app and the AWS environment to stream content.
- C. Use Amazon CloudFront. Provide signed URLs to stream content.
- D. Set up AWS Client VPN between the mobile app and the AWS environment to stream content.
```

정답 : `C`

- 요구사항은 수백만 사용자 규모로 확장 가능해야 하고, 인증된 사용자만 접근 가능해야 함 → 확장성과 보안 모두 필요
- Amazon CloudFront는 전 세계 엣지 로케이션을 통해 대규모 스트리밍 콘텐츠를 낮은 지연(latency)로 제공
- Signed URLs 또는 Signed Cookies를 통해 인증된 사용자만 콘텐츠에 접근 가능하도록 제어 가능

오답 이유

- **A. 퍼블릭 S3 + KMS**: 퍼블릭 버킷은 **누구나 접근 가능**하므로 보안 요건 불충족. KMS는 데이터 암호화용이지 사용자 인증/스트리밍 제어에 적합하지 않음.
    
- **B. IPsec VPN**: 모바일 기기 수백만 대와 VPN 연결은 **확장성 전혀 없음**. 관리 및 성능 모두 불가능.
    
- **D. Client VPN**: AWS Client VPN은 **엔터프라이즈 직원 원격 액세스용**이지, 퍼블릭 콘텐츠 배포용이 아님. 마찬가지로 수백만 사용자를 대상으로 확장 불가능.



## #314
한 회사는 글로벌 영업팀이 사용하는 온프레미스 MySQL 데이터베이스를 보유하고 있으며, 이 데이터베이스는 드물게 액세스되는 패턴을 가지고 있습니다. 영업팀은 데이터베이스의 다운타임이 최소화되기를 요구합니다. 데이터베이스 관리자는 향후 더 많은 사용자가 늘어날 것을 예상하여 특정 인스턴스 유형을 선택하지 않고 이 데이터베이스를 AWS로 마이그레이션하려고 합니다.

솔루션스 아키텍트는 어떤 서비스를 권장해야 합니까?

A. Amazon Aurora MySQL  
B. Amazon Aurora Serverless for MySQL  
C. Amazon Redshift Spectrum  
D. Amazon RDS for MySQL

```
A company has an on-premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future.  
  
Which service should a solutions architect recommend?

- A. Amazon Aurora MySQL
- B. Amazon Aurora Serverless for MySQL
- C. Amazon Redshift Spectrum
- D. Amazon RDS for MySQL
```

정답 : `B`

- Aurora Serverless는 사용량이 없으면 자동으로 일시 중지(pause)되며, 사용량이 증가하면 자동으로 확장/축소
- 따라서 관리자가 미리 크기를 정할 필요가 없고, 사용량이 드물 경우 비용 절감 효과도 큼
- Aurora 기반이므로 다운타임 최소화 및 고가용성도 지원

오답 이유

- **A. Amazon Aurora MySQL**: 확장성과 성능은 뛰어나지만 인스턴스 크기를 직접 선택해야 합니다. 드문 사용 패턴에 최적화되지 않음.
    
- **C. Amazon Redshift Spectrum**: 이는 데이터 웨어하우스 분석용 서비스이며, OLTP 트랜잭션 DB 마이그레이션에 적합하지 않습니다.
    
- **D. Amazon RDS for MySQL**: 관리형 MySQL을 제공하지만 인스턴스 타입을 직접 선택해야 하고, 드문 사용 패턴에 따른 자동 일시중지 같은 기능은 제공하지 않습니다.


## #315
한 회사가 온프레미스 데이터 센터의 여러 애플리케이션에 영향을 미친 침해 사고를 겪었습니다. 공격자는 서버에서 실행 중인 커스텀 애플리케이션의 취약점을 악용했습니다. 회사는 이제 애플리케이션을 Amazon EC2 인스턴스에서 실행하도록 마이그레이션하고 있습니다. 회사는 EC2 인스턴스의 취약점을 능동적으로 스캔하고, 발견 사항을 상세히 기술한 보고서를 보내는 솔루션을 구현하고자 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Shield를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. 발견 사항을 AWS CloudTrail에 기록하도록 AWS Lambda 함수를 생성합니다.
B. Amazon Macie와 AWS Lambda 함수를 배포하여 EC2 인스턴스의 취약점을 스캔합니다. 모든 발견 사항을 AWS CloudTrail에 기록합니다.
C. Amazon GuardDuty를 활성화합니다. GuardDuty 에이전트를 EC2 인스턴스에 배포합니다. 발견 사항을 상세히 기술한 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 구성합니다.
D. Amazon Inspector를 활성화합니다. Amazon Inspector 에이전트를 EC2 인스턴스에 배포합니다. 발견 사항을 상세히 기술한 보고서의 생성 및 배포를 자동화하도록 AWS Lambda 함수를 구성합니다.

```
A company experienced a breach that affected several applications in its on-premises data center. The attacker took advantage of vulnerabilities in the custom applications that were running on the servers. The company is now migrating its applications to run on Amazon EC2 instances. The company wants to implement a solution that actively scans for vulnerabilities on the EC2 instances and sends a report that details the findings.  
  
Which solution will meet these requirements?

- A. Deploy AWS Shield to scan the EC2 instances for vulnerabilities. Create an AWS Lambda function to log any findings to AWS CloudTrail.
- B. Deploy Amazon Macie and AWS Lambda functions to scan the EC2 instances for vulnerabilities. Log any findings to AWS CloudTrail.
- C. Turn on Amazon GuardDuty. Deploy the GuardDuty agents to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.
- D. Turn on Amazon Inspector. Deploy the Amazon Inspector agent to the EC2 instances. Configure an AWS Lambda function to automate the generation and distribution of reports that detail the findings.
```

정답 : `D`

- Amazon Inspector는 EC2(및 컨테이너 이미지, 람다 등)에 대한 자동 취약점 스캔과 패키지/OS 수준 CVE 진단을 제공하는 서비스
- 에이전트를 설치하거나 Inspector2를 활성화하면 워크로드를 지속적으로 평가하고 취약점(심각도, CVE, 영향 받는 리소스)를 Finding으로 생성
- Findings는 EventBridge로 연동되어 람다로 보고서 생성 및 배포(이메일/SNS/티켓팅)를 자동화하기 쉬움

오답 이유

- **A. AWS Shield**: DDoS 보호 서비스로, **애플리케이션/호스트 취약점 스캐닝 기능이 없음**.
    
- **B. Amazon Macie**: S3 내 **민감 데이터(PII 등) 탐지** 서비스. EC2 취약점 스캔 용도가 아님.
    
- **C. Amazon GuardDuty**: 계정/네트워크/워크로드의 **위협 탐지(이상 행위)** 서비스. 악성 트래픽, 의심스러운 API 호출 등을 감지하지만 **소프트웨어 취약점(CVE) 스캔** 목적이 아님. 또한 “GuardDuty 에이전트”는 존재하지 않음.


## #316
한 회사는 Amazon EC2 인스턴스를 사용하여 Amazon Simple Queue Service(Amazon SQS) 큐에서 메시지를 폴링하고 처리하는 스크립트를 실행하고 있습니다. 회사는 큐에 추가되는 메시지 수가 증가하더라도 메시지를 처리할 수 있는 능력을 유지하면서 운영 비용을 줄이고자 합니다.

솔루션스 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 권장해야 합니까?

A. 메시지를 더 빨리 처리하기 위해 EC2 인스턴스 크기를 늘립니다.
B. Amazon EventBridge를 사용하여 인스턴스가 활용도가 낮을 때 EC2 인스턴스를 종료합니다.
C. EC2 인스턴스에서 실행 중인 스크립트를 적절한 런타임을 가진 AWS Lambda 함수로 마이그레이션합니다.
D. AWS Systems Manager Run Command를 사용하여 필요할 때 스크립트를 실행합니다.

```
A company uses an Amazon EC2 instance to run a script to poll for and process messages in an Amazon Simple Queue Service (Amazon SQS) queue. The company wants to reduce operational costs while maintaining its ability to process a growing number of messages that are added to the queue.  
  
What should a solutions architect recommend to meet these requirements?

- A. Increase the size of the EC2 instance to process messages faster.
- B. Use Amazon EventBridge to turn off the EC2 instance when the instance is underutilized.
- C. Migrate the script on the EC2 instance to an AWS Lambda function with the appropriate runtime.
- D. Use AWS Systems Manager Run Command to run the script on demand.
```

정답 : `C`

- EC2 인스턴스에서 스크립트를 계속 실행 → 인스턴스는 상시 실행되어야 하므로 비용 발생 + 운영 관리 부담
- AWS Lambda는 SQS와 네이티브 통합을 지원하고 이벤트 기반으로 메시지를 처리.
- 메시지가 증가하면 람다가 자동으로 확장되어 운영 비용은 사용한 만큼만 지불

오답 이유

- **A. EC2 인스턴스 크기 증가**: 성능은 개선될 수 있지만 비용 증가 + 운영 관리 부담 지속. 확장성 문제 해결 불가.
    
- **B. EventBridge로 EC2 중지**: 큐에 메시지가 쌓여도 즉시 처리 불가. 운영 효율성과 확장성 모두 미흡.
    
- **D. Systems Manager Run Command**: 수동 실행 기반이며, 메시지 큐에서 이벤트 기반으로 자동 처리하는 요구사항에 맞지 않음.


## #317
한 회사는 레거시 애플리케이션을 사용하여 CSV 형식의 데이터를 생성합니다. 레거시 애플리케이션은 출력 데이터를 Amazon S3에 저장합니다. 회사는 Amazon Redshift와 Amazon S3에만 저장된 데이터를 분석하기 위해 복잡한 SQL 쿼리를 수행할 수 있는 신규 상용(COTS) 애플리케이션을 배포하고 있습니다. 그러나 COTS 애플리케이션은 레거시 애플리케이션이 생성하는 .csv 파일을 처리할 수 없습니다.

회사는 레거시 애플리케이션을 다른 형식의 데이터를 생성하도록 업데이트할 수 없습니다. 회사는 COTS 애플리케이션이 레거시 애플리케이션이 생성한 데이터를 사용할 수 있도록 하는 솔루션을 구현해야 합니다.

다음 중 운영 오버헤드가 가장 적은 솔루션은 무엇입니까?

A. 일정에 따라 실행되는 AWS Glue ETL 작업을 생성합니다. ETL 작업이 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift에 저장하도록 구성합니다.
B. .csv 파일을 .sql 파일로 변환하는 Python 스크립트를 Amazon EC2 인스턴스에서 개발합니다. cron 일정으로 스크립트를 호출하여 출력 파일을 Amazon S3에 저장합니다.
C. AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트로 Lambda 함수를 호출합니다. Lambda 함수가 ETL 작업을 수행하여 .csv 파일을 처리하고 처리된 데이터를 DynamoDB 테이블에 저장하도록 구성합니다.
D. Amazon EventBridge를 사용하여 주간 일정으로 Amazon EMR 클러스터를 시작합니다. EMR 클러스터가 ETL 작업을 수행하여 .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift 테이블에 저장하도록 구성합니다.

```
A company uses a legacy application to produce data in CSV format. The legacy application stores the output data in Amazon S3. The company is deploying a new commercial off-the-shelf (COTS) application that can perform complex SQL queries to analyze data that is stored in Amazon Redshift and Amazon S3 only. However, the COTS application cannot process the .csv files that the legacy application produces.  
  
The company cannot update the legacy application to produce data in another format. The company needs to implement a solution so that the COTS application can use the data that the legacy application produces.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Create an AWS Glue extract, transform, and load (ETL) job that runs on a schedule. Configure the ETL job to process the .csv files and store the processed data in Amazon Redshift.
- B. Develop a Python script that runs on Amazon EC2 instances to convert the .csv files to .sql files. Invoke the Python script on a cron schedule to store the output files in Amazon S3.
- C. Create an AWS Lambda function and an Amazon DynamoDB table. Use an S3 event to invoke the Lambda function. Configure the Lambda function to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in the DynamoDB table.
- D. Use Amazon EventBridge to launch an Amazon EMR cluster on a weekly schedule. Configure the EMR cluster to perform an extract, transform, and load (ETL) job to process the .csv files and store the processed data in an Amazon Redshift table.
```

정답 : `A`

- AWS Glue는 서버리스 ETL 서비스로, S3에 저장된 CSV 파일을 자동으로 변환하여 Redshift에 적재할 수 있음
- Glue는 S3 이벤트 기반 트리거나 스케줄링을 지원하고, 관리형이므로 인프라 운영 오버헤드가 거의 없음
- COTS 애플리케이션 지원하는 Redshift에 데이터를 바로 적재할 수 있으므로 요구사항 충족

오답 이유

- **B. Python + EC2**
    - EC2 인스턴스를 유지 관리해야 하며, OS 패치, 스케일링, cron 스케줄 관리까지 직접 해야 함.
    - Glue와 같은 서버리스 관리형 서비스 대비 운영 오버헤드가 큼.
    
- **C. Lambda + DynamoDB**
    - DynamoDB는 문제 요구사항에 언급된 대상이 아님(COTS 애플리케이션은 Redshift와 S3만 사용 가능).
    - 설계 자체가 요구사항에 부적합.
    
- **D. EMR + EventBridge**
    - EMR은 강력한 빅데이터 처리 클러스터이지만, 단순 CSV → Redshift 변환에는 과도한 솔루션.
    - 클러스터 관리, 비용, 스케줄링 관리 등 운영 오버헤드가 Glue보다 훨씬 큼.


## #318
한 회사가 최근 IT 환경 전체를 AWS 클라우드로 마이그레이션했습니다. 회사는 사용자가 적절한 변경 관리 프로세스를 거치지 않고 크기가 과도하게 큰 Amazon EC2 인스턴스를 프로비저닝하고, 보안 그룹 규칙을 수정하고 있다는 사실을 발견했습니다. 솔루션스 아키텍트는 이러한 인벤토리 및 구성 변경을 추적하고 감사할 수 있는 전략을 수립해야 합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 작업을 수행해야 합니까? (두 가지를 선택하십시오.)

A. AWS CloudTrail을 활성화하고 이를 감사에 사용합니다.  
B. Amazon EC2 인스턴스에 데이터 수명 주기 정책(Data Lifecycle Policies)을 사용합니다.  
C. AWS Trusted Advisor를 활성화하고 보안 대시보드를 참조합니다.  
D. AWS Config를 활성화하고 규정을 위한 규칙을 생성합니다.  
E. AWS CloudFormation 템플릿을 사용하여 이전 리소스 구성을 복원합니다.

```
A company recently migrated its entire IT environment to the AWS Cloud. The company discovers that users are provisioning oversized Amazon EC2 instances and modifying security group rules without using the appropriate change control process. A solutions architect must devise a strategy to track and audit these inventory and configuration changes.  
  
Which actions should the solutions architect take to meet these requirements? (Choose two.)

- A. Enable AWS CloudTrail and use it for auditing.
- B. Use data lifecycle policies for the Amazon EC2 instances.
- C. Enable AWS Trusted Advisor and reference the security dashboard.
- D. Enable AWS Config and create rules for auditing and compliance purposes.
- E. Restore previous resource configurations with an AWS CloudFormation template.
```

정답 : `A, D`

- CloudTrail은 AWS 계정 내에서 발생하는 모든 API 호출을 기록
	- EC2 인스턴스 크기 변경, 보안 그룹 규칙 수정 같은 작업 내역을 추적하고 감사 가능
- AWS Config
	- 리소스 구성을 지속적으로 모니터링하고 규칙 기반 평가를 통해 컴플라이언스를 확인
	- 예: "보안 그룹에서 0.0.0.0/0으로 SSH 허용 금지" 같은 규칙을 설정하여 위반 시 탐지 가능
	- 변경 이력 추적, 구성 스냅샷 제공 → 인벤토리 및 감사 목적에 적합

오답 이유

- **B. Data Lifecycle Policies (EC2 Instance Lifecycle Manager)**
    - 이는 EBS 스냅샷 자동화 같은 백업 관리 용도로 사용됩니다. 인스턴스 크기 조정이나 보안 그룹 변경을 추적하는 기능과는 무관합니다.
    
- **C. Trusted Advisor**
    - Trusted Advisor는 비용 절감, 보안 최적화, 성능 개선 권장사항을 제공하지만 **실시간 변경 추적 및 규정 준수 감시 기능**은 제한적입니다.
    - 보안 대시보드에서 권장사항을 볼 수 있지만, 구성 변경을 추적·감사하는 목적에는 적합하지 않음.
    
- **E. CloudFormation 복원**
    - 이는 리소스를 원래 상태로 되돌리는 데 유용할 수 있지만, 변경 추적/감사 기능을 제공하지 않습니다. 문제의 요구사항은 “변경 감시와 감사”이지 “자동 복원”이 아님.


## #319
한 회사는 AWS 클라우드에 수백 개의 Amazon EC2 Linux 기반 인스턴스를 보유하고 있습니다. 시스템 관리자는 인스턴스를 관리하기 위해 공유 SSH 키를 사용해 왔습니다. 최근 감사 이후 회사의 보안 팀은 모든 공유 키 제거를 의무화하고 있습니다. 솔루션스 아키텍트는 EC2 인스턴스에 안전한 액세스를 제공하는 솔루션을 설계해야 합니다.

가장 적은 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결합니다.
B. AWS Security Token Service(AWS STS)를 사용하여 필요할 때 일회성 SSH 키를 생성합니다.
C. 공유 SSH 액세스를 일련의 배스천 인스턴스에 허용합니다. 다른 모든 인스턴스는 배스천 인스턴스에서만 SSH 액세스를 허용하도록 구성합니다.
D. Amazon Cognito 커스텀 작성자(custom authorizer)를 사용하여 사용자를 인증합니다. 임시 SSH 키를 생성하기 위해 AWS Lambda 함수를 호출합니다.

```
A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company’s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances.  
  
Which solution will meet this requirement with the LEAST amount of administrative overhead?

- A. Use AWS Systems Manager Session Manager to connect to the EC2 instances.
- B. Use AWS Security Token Service (AWS STS) to generate one-time SSH keys on demand.
- C. Allow shared SSH access to a set of bastion instances. Configure all other instances to allow only SSH access from the bastion instances.
- D. Use an Amazon Cognito custom authorizer to authenticate users. Invoke an AWS Lambda function to generate a temporary SSH key.
```

정답 : `A`

- Session Manager는 SSH 키가 필요없는 에이전트 기반 접속 제공, IAM 권한으로 사용자를 인증･권한부여
- 인바운드 포트(22) 오픈 불필요, 보안 그룹 단순화, 접속 로그/명령 감사(CloudTrail/CloudWatch Logs/세션 기록) 등 보안과 가시성을 동시 확보 가능
- 서버/키 파일 관리, 배스천 운영 등이 필요 없어 운영 오버헤드 최소화

오답 이유

- **B. AWS STS로 일회성 SSH 키 생성**
    - STS는 **AWS API용 임시 자격 증명**을 발급하는 서비스로 SSH 키를 네이티브하게 생성/배포하지 않습니다.
    - 별도의 키 생성·전달·회수 자동화를 직접 구성해야 하며, 키 배포/만료 관리 등 **운영 부담이 큼**.
    - 결과적으로 Session Manager 대비 보안·감사 일관성이 떨어집니다.
    
- **C. 배스천 인스턴스 공유 SSH**
    - 배스천 자체의 패치/모니터링/확장/고가용성/로그 수집/침해 대응 등 **운영 책임**이 큽니다.
    - 여전히 SSH 키(또는 자격 증명) 관리를 요구하며, 네트워크 포트 개방 필요 → **공격 표면 증가**.
    - 요구사항(공유 키 제거, 최소 오버헤드)과 상충.
    
- **D. Cognito 커스텀 작성자 + Lambda로 임시 SSH 키**
    - 인증/토큰 → Lambda → 키 생성/배포 파이프라인을 직접 설계·운영해야 해 **과도하게 복잡**.
    - SSH 키 수명/회수/로깅 표준화도 별도 구현 필요.
    - 일반적 모범사례가 아니며, Session Manager가 제공하는 기능을 **불필요하게 재구현**.


## #320
한 회사는 온프레미스 데이터 소스에서 데이터를 수집(ingest)하기 위해 Amazon EC2 인스턴스 플릿을 사용하고 있습니다. 데이터는 JSON 형식이며 수집 속도는 최대 1 MB/s까지 올라갈 수 있습니다. EC2 인스턴스가 재부팅되면, 전송 중이던(in-flight) 데이터가 손실됩니다. 회사의 데이터 사이언스 팀은 수집된 데이터를 거의 실시간(near-real time)으로 쿼리하고자 합니다.

다음 중 최소한의 데이터 손실로 확장 가능하면서 거의 실시간 데이터 쿼리를 제공하는 솔루션은 무엇입니까?

A. 데이터를 Amazon Kinesis Data Streams로 게시합니다. Kinesis Data Analytics를 사용하여 데이터를 쿼리합니다.
B. 데이터를 Amazon Redshift를 대상으로 하는 Amazon Kinesis Data Firehose로 게시합니다. Amazon Redshift를 사용하여 데이터를 쿼리합니다.
C. 수집된 데이터를 EC2 인스턴스 스토어에 저장합니다. Amazon S3를 대상으로 하는 Amazon Kinesis Data Firehose로 데이터를 게시합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.
D. 수집된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. Amazon ElastiCache for Redis로 데이터를 게시합니다. 데이터를 쿼리하기 위해 Redis 채널을 구독합니다.

```
A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company’s data science team wants to query ingested data in near-real time.  
  
Which solution provides near-real-time data querying that is scalable with minimal data loss?

- A. Publish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data.
- B. Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.
- C. Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.
- D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.
```

정답 : `A`

- Kinesis Data Streams(KDS)
	- 내구성 있는 스트리밍 스토리지를 제공
	- 다중 AZ에 복제되어 인스턴스 재부팅/장애 시에도 최소한의 데이터 손실로 보호
- Kinesis Data Analytics(KDA): KDS로 들어오는 스트림을 대상으로 표준 SQL로 거의 실시간(밀리초~초 단위) 분석/쿼리 가능
- 샤드(Shard) 단위로 수평 확장되기 때문에 1MB/s 수준부터 그 이상까지 쉽게 확장 가능하며 관리형 서비스로 운영 오버헤드가 낮음

오답 이유

- **B. Firehose → Redshift**
    - Firehose는 Redshift 로딩 시 **버퍼링(크기/시간) 후 배치 COPY**가 필요하여 **분 단위 지연**이 일반적입니다. “거의 실시간” 쿼리 요건에 미흡.
    - 또, Redshift는 웨어하우스 특성상 초단위 지연의 스트리밍 질의에는 덜 적합.
    
- **C. Instance Store + Firehose → S3 + Athena**
    - **Instance Store는 휘발성**이어서 인스턴스 재부팅 시 데이터 손실 위험이 큼(문제의 근본 원인 악화).
    - S3/Athena 조합은 **파일 기반 배치 쿼리**로, 파티션/파일 클로징/카탈로그 반영까지 시간이 걸려 **실시간성 부족**.
    
- **D. EBS + ElastiCache Redis Pub/Sub**
    - Redis Pub/Sub는 **비영구적(비내구성) 메시징**으로, 구독하지 못하면 메시지가 소실될 수 있음 → **데이터 손실 위험**이 큼.
    - 또한 Redis는 분석용 질의 엔진이 아니며, **확장/영속/쿼리 기능** 측면에서 요구사항과 부합하지 않음.