---
created: 2025-10-16 16:32:38
last_modified: 2025-10-17 13:52:34
---
## #541
한 회사가 AWS에서 웹 애플리케이션을 구축하려고 합니다. 웹사이트에 대한 클라이언트 액세스 요청은 예측할 수 없고 오랫동안 유휴 상태일 수 있습니다. 구독료를 지불한 고객만 로그인하고 웹 애플리케이션을 사용할 수 있어야 합니다.

가장 비용 효율적으로 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (세 가지 선택)

A. Amazon DynamoDB에서 사용자 정보를 가져오는 AWS Lambda 함수를 생성합니다. RESTful API를 수락하기 위해 Amazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda 함수로 보냅니다.
B. Amazon RDS에서 사용자 정보를 가져오기 위해 Application Load Balancer 뒤에 Amazon Elastic Container Service(Amazon ECS) 서비스를 생성합니다. RESTful API를 수락하기 위해 Amazon API Gateway 엔드포인트를 생성합니다. API 호출을 Lambda 함수로 보냅니다.
C. 사용자를 인증하기 위해 Amazon Cognito 사용자 풀(user pool)을 생성합니다.
D. 사용자를 인증하기 위해 Amazon Cognito 자격 증명 풀(identity pool)을 생성합니다.
E. AWS Amplify를 사용하여 HTML, CSS, JS로 프런트엔드 웹 콘텐츠를 제공합니다. 통합된 Amazon CloudFront 구성을 사용합니다.
F. PHP, CSS, JS로 Amazon S3 정적 웹 호스팅을 사용합니다. 프런트엔드 웹 콘텐츠를 제공하기 위해 Amazon CloudFront를 사용합니다.

```
A company wants to build a web application on AWS. Client access requests to the website are not predictable and can be idle for a long time. Only customers who have paid a subscription fee can have the ability to sign in and use the web application.  
  
Which combination of steps will meet these requirements MOST cost-effectively? (Choose three.)

- A. Create an AWS Lambda function to retrieve user information from Amazon DynamoDB. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.
- B. Create an Amazon Elastic Container Service (Amazon ECS) service behind an Application Load Balancer to retrieve user information from Amazon RDS. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.
- C. Create an Amazon Cognito user pool to authenticate users.
- D. Create an Amazon Cognito identity pool to authenticate users.
- E. Use AWS Amplify to serve the frontend web content with HTML, CSS, and JS. Use an integrated Amazon CloudFront configuration.
- F. Use Amazon S3 static web hosting with PHP, CSS, and JS. Use Amazon CloudFront to serve the frontend web content.
```

정답 : `A, C, E`

- 트래픽이 예측 불가/장시간 유휴 → 서버를 상시 유지하지 않는 서버리스(API Gateway + Lambda + DynamoDB)가 가장 비용 효율적
- 결제 고객만 로그인 → Cognito 사용자 풀이 표준 인증(회원가입/로그인/토큰) 제공
- 정적 프런트 엔드 제공은 Amplify Hosting(+자동 CloudFront)로 간단하고 저비용

오답 이유

- **B.** ECS+RDS는 **상시 프로비저닝 비용**과 운영 복잡도가 커서, 유휴 시간이 긴 워크로드에 **비용 비효율적**입니다. 또한 선택지 내용이 API Gateway → Lambda로 보내는 구조와도 일관되지 않습니다.
    
- **D.** **Cognito 자격 증명 풀(identity pool)** 은 **AWS 리소스에 대한 임시 자격 증명 연동**(인가/연동) 용도이며, **사용자 인증**은 **사용자 풀**이 담당합니다. 요구사항 “로그인” 충족에 부적합.
    
- **F.** S3 정적 웹 호스팅은 **서버사이드 실행(PHP)** 을 지원하지 않습니다. S3는 정적 파일만 서빙 가능합니다(서버리스 백엔드는 별도 필요).


## #542
한 미디어 회사가 Amazon CloudFront 배포를 사용하여 인터넷을 통해 콘텐츠를 제공합니다.  
회사는 프리미엄 고객만 미디어 스트림 및 파일 콘텐츠에 액세스할 수 있도록 하려 합니다.  
회사는 모든 콘텐츠를 Amazon S3 버킷에 저장하고 있습니다.  
또한 회사는 영화 대여나 음악 다운로드와 같은 특정 목적을 위해 고객에게 주문형(on-demand)으로 콘텐츠를 제공합니다.  

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 프리미엄 고객에게 S3 서명 쿠키(signed cookies)를 생성하여 제공합니다.  
B. 프리미엄 고객에게 CloudFront 서명 URL(signed URL)을 생성하여 제공합니다.  
C. Origin Access Control(OAC)을 사용하여 비프리미엄 고객의 액세스를 제한합니다.  
D. 필드 수준 암호화(field-level encryption)를 생성 및 활성화하여 비프리미엄 고객을 차단합니다.

```
A media company uses an Amazon CloudFront distribution to deliver content over the internet. The company wants only premium customers to have access to the media streams and file content. The company stores all content in an Amazon S3 bucket. The company also delivers content on demand to customers for a specific purpose, such as movie rentals or music downloads.  
  
Which solution will meet these requirements?

- A. Generate and provide S3 signed cookies to premium customers.
- B. Generate and provide CloudFront signed URLs to premium customers.
- C. Use origin access control (OAC) to limit the access of non-premium customers.
- D. Generate and activate field-level encryption to block non-premium customers.
```

정답 : `B`

- 요구사항은 프리미엄 고객만 접근 가능하고, 콘텐츠는 S3에 저장, CloudFront로 배포, 온디맨드
- CloudFront Signed URL은 콘텐츠 만료 시간(time-based)과 사용자 지정 정책을 부여하여 특정 사용자에게만, 일정 시간 동안만 접근 허용 가능
- 따라서 CloudFront Signed URL을 프리미엄 고객에게만 제공하면 비프리미엄 사용자는 콘텐츠를 요청하더라도 CloudFront에서 차단

오답 이유

- **A.** S3 signed cookies는 존재하지 않으며, S3는 **signed URL**만 지원합니다. 또한 CloudFront를 사용 중이므로 **CloudFront signed URL/cookie**가 필요합니다.
    
- **C.** OAC(Origin Access Control)는 **CloudFront에서 S3로의 접근 제한(퍼블릭 접근 차단)**을 설정하는 기능입니다. 이는 **비프리미엄 사용자 제어가 아니라 퍼블릭 접근 보호**용입니다.
    
- **D.** 필드 수준 암호화(Field-level encryption)는 **민감한 데이터 보호(예: 개인정보 암호화)** 용도로 사용되며, **사용자 접근 제어** 기능이 아닙니다.


## #543
한 회사는 개별적으로 결제되는 여러 AWS 계정에서 Amazon EC2 인스턴스를 실행하고 있습니다.  
이 회사는 최근에 Savings Plan을 구매했습니다.  
비즈니스 요구사항의 변경으로 인해, 회사는 많은 수의 EC2 인스턴스를 해제(decommissioned)했습니다.  
회사는 Savings Plan 할인을 다른 AWS 계정에서도 사용하고자 합니다.  

이 요구사항을 충족하기 위한 단계 조합은 무엇입니까? (두 가지를 선택하십시오.)

A. AWS 관리 계정의 AWS Account Management Console에서 결제 환경설정(billing preferences) 섹션에서 할인 공유(discount sharing)를 켭니다.  
B. 기존 Savings Plan을 구매한 계정의 AWS Account Management Console에서 결제 환경설정 섹션에서 할인 공유(discount sharing)를 켭니다. 모든 계정을 포함시킵니다.  
C. AWS Organizations 관리 계정에서 AWS Resource Access Manager (AWS RAM)을 사용하여 Savings Plan을 다른 계정과 공유합니다.  
D. 새 결제(payer) 계정에서 AWS Organizations를 생성합니다. 관리 계정에서 다른 AWS 계정을 초대하여 조직에 가입시킵니다.  
E. 기존 EC2 인스턴스와 Savings Plan이 있는 기존 AWS 계정에서 AWS Organizations를 생성합니다. 관리 계정에서 다른 AWS 계정을 초대하여 조직에 가입시킵니다.

```
A company runs Amazon EC2 instances in multiple AWS accounts that are individually bled. The company recently purchased a Savings Pian. Because of changes in the company’s business requirements, the company has decommissioned a large number of EC2 instances. The company wants to use its Savings Plan discounts on its other AWS accounts.  
  
Which combination of steps will meet these requirements? (Choose two.)

- A. From the AWS Account Management Console of the management account, turn on discount sharing from the billing preferences section.
- B. From the AWS Account Management Console of the account that purchased the existing Savings Plan, turn on discount sharing from the billing preferences section. Include all accounts.
- C. From the AWS Organizations management account, use AWS Resource Access Manager (AWS RAM) to share the Savings Plan with other accounts.
- D. Create an organization in AWS Organizations in a new payer account. Invite the other AWS accounts to join the organization from the management account.
- E. Create an organization in AWS Organizations in the existing AWS account with the existing EC2 instances and Savings Plan. Invite the other AWS accounts to join the organization from the management account.
```

정답 : `A, E`

- Savings Plan 할인은 같은 Consolidated Billing(통합 결제)를 사용하는 조직 내 계정 간에 자동으로 공유
- 이를 위해 먼저 AWS Organizations를 생성하고(E), 관리 계정에서 할인 공유를 활성화(A) 해야 Savings Plan 혜택이 다른 계정에도 적용

오답 이유

- B. Savings Plan을 구매한 개별 계정에서는 할인 공유를 설정할 수 없습니다. 공유 설정은 오직 관리 계정(billing management account)에서만 가능합니다.

- C. AWS Resource Access Manager (AWS RAM)는 리소스(VPC 서브넷, Transit Gateway 등)를 공유하기 위한 서비스이지, Savings Plan은 공유할 수 없습니다.

- D. 새 결제 계정을 만드는 것은 불필요한 단계입니다. 기존 계정 중 하나를 관리 계정으로 지정해 Organizations를 구성할 수 있습니다.


## #544
한 소매 회사는 공개 REST API를 위해 리전별(regional) Amazon API Gateway API를 사용하고 있습니다.  
API Gateway 엔드포인트는 Amazon Route 53 별칭(alias) 레코드를 가리키는 사용자 지정 도메인 이름(custom domain name)입니다.  
솔루션스 아키텍트는 고객에게 미치는 영향을 최소화하고 데이터 손실을 최소화하면서 새로운 버전의 API를 출시할 수 있는 솔루션을 만들어야 합니다.  

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. API Gateway에 카나리 릴리스 배포 스테이지(canar release deployment stage)를 생성합니다. 최신 API 버전을 배포합니다. 트래픽의 적절한 비율을 카나리 스테이지로 지정합니다. API 검증 후, 카나리 스테이지를 프로덕션 스테이지로 승격(promote)합니다.  
B. OpenAPI YAML 파일 형식의 새로운 버전의 API로 새로운 API Gateway 엔드포인트를 생성합니다. API Gateway의 import-to-update 작업을 병합(merge) 모드로 사용하여 API를 업데이트합니다. 새 버전의 API를 프로덕션 스테이지에 배포합니다.  
C. OpenAPI JSON 파일 형식의 새로운 버전의 API로 새로운 API Gateway 엔드포인트를 생성합니다. API Gateway의 import-to-update 작업을 덮어쓰기(overwrite) 모드로 사용하여 API를 업데이트합니다. 새 버전의 API를 프로덕션 스테이지에 배포합니다.  
D. 새로운 API 정의 버전으로 새로운 API Gateway 엔드포인트를 생성합니다. 새 API Gateway API에 대한 사용자 지정 도메인 이름을 생성합니다. Route 53 별칭 레코드를 새 API Gateway API의 사용자 지정 도메인 이름으로 지정합니다.

```
A retail company uses a regional Amazon API Gateway API for its public REST APIs. The API Gateway endpoint is a custom domain name that points to an Amazon Route 53 alias record. A solutions architect needs to create a solution that has minimal effects on customers and minimal data loss to release the new version of APIs.  
  
Which solution will meet these requirements?

- A. Create a canary release deployment stage for API Gateway. Deploy the latest API version. Point an appropriate percentage of traffic to the canary stage. After API verification, promote the canary stage to the production stage.
- B. Create a new API Gateway endpoint with a new version of the API in OpenAPI YAML file format. Use the import-to-update operation in merge mode into the API in API Gateway. Deploy the new version of the API to the production stage.
- C. Create a new API Gateway endpoint with a new version of the API in OpenAPI JSON file format. Use the import-to-update operation in overwrite mode into the API in API Gateway. Deploy the new version of the API to the production stage.
- D. Create a new API Gateway endpoint with new versions of the API definitions. Create a custom domain name for the new API Gateway API. Point the Route 53 alias record to the new API Gateway API custom domain name.
```

정답 : `A`

- API Gateway의 Canary Release 배포 기능은 새 버전의 API를 프로덕션 환경에서 트래픽의 일부에만 적용해 테스트할 수 있게 해줌
- 고객 영향과 데이터 손실을 최소화하면서 새로운 API 버전을 점진적으로 배표하고, 검증 후 쉽게 프로덕션으로 승격 가능

오답 이유

- B. 병합(merge) 모드는 기존 리소스와 새로운 리소스를 병합하기 때문에 예측하기 어려운 충돌이 발생할 수 있습니다. 트래픽 제어나 점진적 배포를 지원하지 않아 고객 영향이 클 수 있습니다.

- C. 덮어쓰기(overwrite) 모드는 기존 API 구성을 완전히 교체하므로, 프로덕션 환경에 즉시 영향을 주며 데이터 손실이나 장애 가능성이 높습니다.

- D. 새로운 도메인 이름을 생성하고 Route 53 레코드를 변경하면 배포 중 DNS 전파 지연이 발생할 수 있으며, 고객이 일시적으로 접근 불가능한 상태가 될 수 있습니다. 고객 영향이 큽니다.


## #545
한 회사는 기본 웹사이트가 사용 불가능한 경우, 사용자를 백업 정적 오류 페이지로 안내하고자 합니다. 기본 웹사이트의 DNS 레코드는 Amazon Route 53에 호스팅되어 있습니다. 도메인은 Application Load Balancer(ALB)를 가리키고 있습니다. 회사는 변경 및 인프라 오버헤드를 최소화하는 솔루션이 필요합니다.

어떤 솔루션이 이러한 요구사항을 충족할 수 있습니까?

A. Route 53 레코드를 지연 시간 기반 라우팅 정책(latency routing policy)으로 업데이트합니다. Amazon S3 버킷에 호스팅된 정적 오류 페이지를 레코드에 추가하여 트래픽이 가장 응답이 빠른 엔드포인트로 전송되도록 합니다.
B. Route 53 활성-수동(active-passive) 장애 조치(failover) 구성을 설정합니다. Route 53 상태 확인(health check)이 ALB 엔드포인트가 비정상임을 감지하면, 트래픽을 Amazon S3 버킷에 호스팅된 정적 오류 페이지로 라우팅합니다.
C. ALB와 정적 오류 페이지를 호스팅하는 Amazon EC2 인스턴스를 엔드포인트로 하는 Route 53 활성-활성(active-active) 구성을 설정합니다. ALB의 상태 확인이 실패한 경우에만 Route 53이 인스턴스로 요청을 전송하도록 구성합니다.
D. Route 53 레코드를 다중 값 응답 라우팅 정책(multivalue answer routing policy)으로 업데이트합니다. 상태 확인을 생성하고, 상태 확인이 통과되면 트래픽을 웹사이트로 전송하고, 상태 확인이 통과되지 않으면 트래픽을 Amazon S3에 호스팅된 정적 오류 페이지로 전송합니다.

```
A company wants to direct its users to a backup static error page if the company's primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53. The domain is pointing to an Application Load Balancer (ALB). The company needs a solution that minimizes changes and infrastructure overhead.  
  
Which solution will meet these requirements?

- A. Update the Route 53 records to use a latency routing policy. Add a static error page that is hosted in an Amazon S3 bucket to the records so that the traffic is sent to the most responsive endpoints.
- B. Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page that is hosted in an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.
- C. Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance that hosts a static error page as endpoints. Configure Route 53 to send requests to the instance only if the health checks fail for the ALB.
- D. Update the Route 53 records to use a multivalue answer routing policy. Create a health check. Direct traffic to the website if the health check passes. Direct traffic to a static error page that is hosted in Amazon S3 if the health check does not pass.
```

정답 : `B`

- Route 53의 active-passive failover 라우팅은 기본 리소스가 비정상일 때 자동으로 보조 리소스로 트래픽을 전환하는 기능
- ALB가 기본 엔드포인트이고, Amazon S3의 정적 웹사이트가 백업 페이지 역할을 하므로 failover 라우팅 정책과 health check를 사용하는 것이 가장 단순하고 관리 오버헤드가 적음

오답 이유

- A. 지연 시간 기반 라우팅(latency routing)은 여러 리전에 걸쳐 있는 활성 리소스 간의 트래픽을 최적화할 때 사용합니다. 장애 감지나 백업 전환 기능이 없으므로 오류 페이지로 자동 전환되지 않습니다.

- C. 활성-활성(active-active) 구성은 두 엔드포인트 모두 트래픽을 수신하는 구조입니다. 이 경우 EC2 인스턴스가 불필요하게 상시 동작해야 하므로 인프라 오버헤드가 증가하며, 단순 오류 페이지 제공 목적에 맞지 않습니다.

- D. 다중 값 응답(multivalue answer) 라우팅은 여러 엔드포인트에 대한 상태 확인을 수행하지만, 장애 시 자동으로 다른 리소스로 전환하는 failover 동작을 제공하지 않습니다. 즉, 장애 발생 시 완전한 백업 전환이 불가능합니다.


## #546
최근 회사의 IT 비용 분석 결과, 백업 비용을 줄일 필요가 있음이 강조되었습니다. 회사의 최고정보책임자(CIO)는 물리적 백업 테이프 사용을 제거하여 온프레미스 백업 인프라를 단순화하고 비용을 절감하고자 합니다. 회사는 기존 온프레미스 백업 애플리케이션과 워크플로에 대한 투자를 보존해야 합니다.

솔루션스 아키텍트는 무엇을 권장해야 합니까?

A. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다.
B. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결되는 Amazon EFS 파일 시스템을 설정합니다.
C. iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결되는 Amazon EFS 파일 시스템을 설정합니다.
D. iSCSI-가상 테이프 라이브러리(VTL) 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다.

```
A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information officer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows.  
  
What should a solutions architect recommend?

- A. Set up AWS Storage Gateway to connect with the backup applications using the NFS interface.
- B. Set up an Amazon EFS file system that connects with the backup applications using the NFS interface.
- C. Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface.
- D. Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface.
```

정답 : `D`

- 기존 온프레미스 백업 소프트웨어･워크플로를 그대로 유지하면서 물리적 테이프를 제거하려면 AWS Storage Gateway의 Tape Gateway(VTL)를 iSCSI로 연결하는 구성이 정석
- 기존 백업 애플리케이션이 인식하는 가상 테이프 라이브러리(VTL)를 제공하고, 테이프 데이터를 S3/Glacier로 보관하여 저비용･관리 단순화를 동시에 달성

오답 이유

- A. File Gateway(NFS)는 파일 공유를 S3와 연계해 캐시/동기화하는 용도로 적합하지만, 테이프 기반 백업 워크플로(VTL, iSCSI)를 그대로 보존하지 못합니다.

- B. EFS는 VPC 내 POSIX 호환 NFS 파일 시스템으로, 온프레미스에서 직접 백업 애플리케이션을 붙이려면 네트워크(Transit/Direct Connect/VPN) 구성도 필요하고, 테이프 워크플로 대체(VTL) 목적에 부합하지 않습니다.

- C. EFS는 iSCSI를 지원하지 않습니다. 블록/테이프 인터페이스가 아니라서 기존 테이프 기반 백업 애플리케이션과의 호환을 제공하지 못합니다.


## #547
한 회사는 서로 다른 위치에 데이터 수집 센서를 보유하고 있습니다. 데이터 수집 센서는 회사로 대량의 데이터를 스트리밍합니다. 회사는 AWS에서 대용량 스트리밍 데이터를 수집하고 처리할 수 있는 플랫폼을 설계하려고 합니다. 솔루션은 확장 가능해야 하며 거의 실시간으로 데이터 수집을 지원해야 합니다. 회사는 향후 보고를 위해 데이터를 Amazon S3에 저장해야 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할 수 있습니까?

A. Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 Amazon S3로 전달합니다.
B. AWS Glue를 사용하여 스트리밍 데이터를 Amazon S3로 전달합니다.
C. AWS Lambda를 사용하여 스트리밍 데이터를 전달하고 데이터를 Amazon S3에 저장합니다.
D. AWS Database Migration Service (AWS DMS)를 사용하여 스트리밍 데이터를 Amazon S3로 전달합니다.

```
A company has data collection sensors at different locations. The data collection sensors stream a high volume of data to the company. The company wants to design a platform on AWS to ingest and process high-volume streaming data. The solution must be scalable and support data collection in near real time. The company must store the data in Amazon S3 for future reporting.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use Amazon Kinesis Data Firehose to deliver streaming data to Amazon S3.
- B. Use AWS Glue to deliver streaming data to Amazon S3.
- C. Use AWS Lambda to deliver streaming data and store the data to Amazon S3.
- D. Use AWS Database Migration Service (AWS DMS) to deliver streaming data to Amazon S3.
```

정답 : `A`

- Kinesis Data Firehose는 완전관리형 스트리밍 수집･적재 서비스로, 자동 확장, 버퍼링, 자동 재시도, S3 적재를 기본 제공
- 거의 실시간(초~분 단위) 수집을 지원하며 변환(Record format conversion, Lambda 변환) 옵션도 있어 S3로의 데이터 적재 최적

오답 이유

- B. AWS Glue는 ETL/데이터 처리 서비스이며 Glue Streaming을 쓰려면 Kinesis/Kafka 등의 소스 구성과 작업 클러스터 관리가 필요해 운영 오버헤드가 큽니다. 단순 수집·적재에 Firehose보다 적합하지 않습니다.

- C. Lambda로 직접 수집·저장 파이프라인을 구성하면 동시성/배치/재시도/순서 보장 등을 직접 설계해야 하고, 대량 스트리밍에서 호출 한도와 비용/운영 부담이 커집니다.

- D. AWS DMS는 데이터베이스 마이그레이션/CDC에 특화된 서비스로, 센서 텔레메트리 같은 일반 스트리밍 수집 용도에 적합하지 않습니다.


## #548
한 회사는 재무, 데이터 분석, 개발 부서별로 별도의 AWS 계정을 가지고 있습니다. 비용 및 보안 문제로 인해, 회사는 각 AWS 계정에서 사용할 수 있는 서비스를 제어하고자 합니다.

어떤 솔루션이 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족할 수 있습니까?

A. AWS Systems Manager 템플릿을 사용하여 각 부서가 사용할 수 있는 AWS 서비스를 제어합니다.
B. AWS Organizations에서 각 부서를 위한 조직 단위(OU)를 생성합니다. 서비스 제어 정책(SCP)을 OU에 연결합니다.
C. AWS CloudFormation을 사용하여 각 부서가 사용할 수 있는 AWS 서비스만 자동으로 프로비저닝합니다.
D. 각 AWS 계정에 AWS Service Catalog에서 제품 목록을 설정하여 특정 AWS 서비스 사용을 관리하고 제어합니다.

```
A company has separate AWS accounts for its finance, data analytics, and development departments. Because of costs and security concerns, the company wants to control which services each AWS account can use.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS Systems Manager templates to control which AWS services each department can use.
- B. Create organization units (OUs) for each department in AWS Organizations. Attach service control policies (SCPs) to the OUs.
- C. Use AWS CloudFormation to automatically provision only the AWS services that each department can use.
- D. Set up a list of products in AWS Service Catalog in the AWS accounts to manage and control the usage of specific AWS services.
```

정답 : `B`

- AWS Organizations의 서비스 제어 정책(SCP)은 계정/OU 수준에서 허용 또는 거부할 수 있는 서비스･API를 중아에서 강제 가능
- 다계정 환경에서 서비스 사용 범위를 통제하는 표준 해법. 한 번의 정책 관리로 여러 계정에 일괄 적용되므로 운영 오버헤드 최소

오답 이유

- A. Systems Manager 템플릿(예: 문서/오토메이션)은 구성/작업 자동화에 적합하지만, 계정 전반의 서비스/API 사용 자체를 강제로 제한하지 못합니다.

- C. CloudFormation은 리소스 프로비저닝 도구일 뿐, 사용자가 콘솔/CLI로 다른 서비스를 생성하는 것을 기술적으로 차단하지 못합니다. 서비스 사용 통제 수단이 아닙니다.

- D. Service Catalog는 승인된 제품 카탈로그를 통해 프로비저닝을 표준화하지만, 카탈로그 외부에서 서비스 사용을 직접 차단하지 못합니다. 또한 계정별 제품·승인 관리로 운영 복잡도가 증가합니다.


## #549
한 회사는 전자상거래 웹사이트를 위한 다중 계층 애플리케이션을 만들었습니다. 이 웹사이트는 퍼블릭 서브넷에 위치한 Application Load Balancer, 퍼블릭 서브넷의 웹 계층, 그리고 프라이빗 서브넷의 Amazon EC2 인스턴스에서 호스팅되는 MySQL 클러스터를 사용합니다. MySQL 데이터베이스는 타사 제공자가 인터넷에 호스팅하는 제품 카탈로그 및 가격 정보를 검색해야 합니다. 솔루션스 아키텍트는 운영 오버헤드를 증가시키지 않으면서 보안을 극대화하는 전략을 고안해야 합니다.  
  
이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. VPC에 NAT 인스턴스를 배포합니다. 모든 인터넷 기반 트래픽을 NAT 인스턴스를 통해 라우팅합니다.
B. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. 프라이빗 서브넷 라우팅 테이블을 수정하여 모든 인터넷 향 트래픽을 NAT 게이트웨이로 전달하도록 합니다.
C. 인터넷 게이트웨이를 구성하고 VPC에 연결합니다. 프라이빗 서브넷 라우팅 테이블을 수정하여 인터넷 향 트래픽을 인터넷 게이트웨이로 전달하도록 합니다.
D. 가상 프라이빗 게이트웨이를 구성하고 VPC에 연결합니다. 프라이빗 서브넷 라우팅 테이블을 수정하여 인터넷 향 트래픽을 가상 프라이빗 게이트웨이로 전달하도록 합니다.

```
A company has created a multi-tier application for its ecommerce website. The website uses an Application Load Balancer that resides in the public subnets, a web tier in the public subnets, and a MySQL cluster hosted on Amazon EC2 instances in the private subnets. The MySQL database needs to retrieve product catalog and pricing information that is hosted on the internet by a third-party provider. A solutions architect must devise a strategy that maximizes security without increasing operational overhead.  
  
What should the solutions architect do to meet these requirements?

- A. Deploy a NAT instance in the VPC. Route all the internet-based traffic through the NAT instance.
- B. Deploy a NAT gateway in the public subnets. Modify the private subnet route table to direct all internet-bound traffic to the NAT gateway.
- C. Configure an internet gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound traffic to the internet gateway.
- D. Configure a virtual private gateway and attach it to the VPC. Modify the private subnet route table to direct internet-bound traffic to the virtual private gateway.
```

정답 : `B`

- 프라이빗 서브넷의 DB 인스턴스가 인바운드 노출 없이 인터넷의 제 3자 API에 아웃바운드로만 접근하려면 NAT 필요
- NAT 게이트웨이는 관리형으로 가용성과 확장성이 높아 운영 오버헤드가 최소
- 인스턴스에 공인 IP를 부여하지 않고도 외부로 나갈 수 있어 보안도 극대화

오답 이유

- A. NAT 인스턴스는 패치, 용량/가용성 관리(ASG, 소스/대상 체크 등)를 직접 해야 하므로 운영 오버헤드가 큽니다. 문제는 오버헤드 최소화를 요구합니다.

- C. 인터넷 게이트웨이는 퍼블릭 서브넷에서 공인 IP를 가진 리소스에만 유효합니다. 프라이빗 서브넷의 인스턴스는 공인 IP가 없어 IGW로 직접 나갈 수 없으므로 NAT이 필요합니다.

- D. 가상 프라이빗 게이트웨이(VGW)는 온프레미스와의 VPN 연결 용도입니다. 퍼블릭 인터넷상의 제3자 서비스로의 일반 아웃바운드 경로에는 적합하지 않습니다.


## #550
한 회사는 AWS Key Management Service(AWS KMS) 키를 사용하여 AWS Lambda 환경 변수를 암호화하고 있습니다.  
솔루션스 아키텍트는 환경 변수를 복호화하고 사용할 수 있도록 필요한 권한이 설정되어 있는지 확인해야 합니다.

필요한 권한을 구현하기 위해 솔루션스 아키텍트가 수행해야 하는 단계는 무엇입니까? (2개를 선택하십시오.)

A. Lambda 리소스 정책에 AWS KMS 권한을 추가합니다.  
B. Lambda 실행 역할(Lambda execution role)에 AWS KMS 권한을 추가합니다.  
C. Lambda 함수 정책(Lambda function policy)에 AWS KMS 권한을 추가합니다.  
D. AWS KMS 키 정책에서 Lambda 실행 역할을 허용합니다.  
E. AWS KMS 키 정책에서 Lambda 리소스 정책을 허용합니다.

```
A company is using AWS Key Management Service (AWS KMS) keys to encrypt AWS Lambda environment variables. A solutions architect needs to ensure that the required permissions are in place to decrypt and use the environment variables.  
  
Which steps must the solutions architect take to implement the correct permissions? (Choose two.)

- A. Add AWS KMS permissions in the Lambda resource policy.
- B. Add AWS KMS permissions in the Lambda execution role.
- C. Add AWS KMS permissions in the Lambda function policy.
- D. Allow the Lambda execution role in the AWS KMS key policy.
- E. Allow the Lambda resource policy in the AWS KMS key policy.
```

정답 : `B, D`

- Lambda 함수가 KMS로 암호화된 환경 변수를 복호화하려면, Lambda 실행 역할이 KMS 키를 사용할 수 있는 권한을 가져야 함
	- B: Lambda 실행 역할 자체에 KMS 관련 관한(kms:Decrypt, kms:Encrypt, kms:GenerateDataKey)
	- D: KMS 키 정책에서 Lambda 실행 역할이 키를 사용할 수 있도록 허용

오답 이유

- A. Lambda 리소스 정책은 Lambda 함수 자체에 대한 접근을 제어할 때 사용되며, KMS 키 사용 권한과는 무관합니다.

- C. Lambda 함수 정책은 존재하지 않습니다. Lambda에는 함수 정책(Function policy)이라는 개념이 없으며, 이는 API Gateway 등과 혼동된 선택지입니다.

- E. KMS 키 정책에서 Lambda 리소스 정책을 허용하는 것은 올바른 방식이 아닙니다. Lambda 리소스 정책은 KMS 키를 사용할 수 있는 주체가 아니기 때문입니다.


## #551
한 회사에는 재무 애플리케이션이 있으며 이 애플리케이션은 보고서를 생성합니다. 보고서의 평균 크기는 50 KB이며 Amazon S3에 저장됩니다. 보고서는 생성 후 첫 주 동안 자주 액세스되며, 수년 동안 저장되어야 합니다. 보고서는 6시간 이내에 검색할 수 있어야 합니다.

다음 중 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

A. S3 Standard를 사용합니다. S3 수명 주기 규칙을 사용하여 7일 후 보고서를 S3 Glacier로 전환합니다.
B. S3 Standard를 사용합니다. S3 수명 주기 규칙을 사용하여 7일 후 보고서를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.
C. S3 Intelligent-Tiering을 사용합니다. S3 Intelligent-Tiering이 보고서를 S3 Standard-Infrequent Access(S3 Standard-IA)와 S3 Glacier로 전환하도록 구성합니다.
D. S3 Standard를 사용합니다. S3 수명 주기 규칙을 사용하여 7일 후 보고서를 S3 Glacier Deep Archive로 전환합니다.

```
A company has a financial application that produces reports. The reports average 50 KB in size and are stored in Amazon S3. The reports are frequently accessed during the first week after production and must be stored for several years. The reports must be retrievable within 6 hours.  
  
Which solution meets these requirements MOST cost-effectively?

- A. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier after 7 days.
- B. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) after 7 days.
- C. Use S3 Intelligent-Tiering. Configure S3 Intelligent-Tiering to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier.
- D. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier Deep Archive after 7 days.
```

정답 : `A`

- 보고서는 첫 주에 자주 액세스 되므로 초기에는 S3 Standard가 적합
- 이후에는 수년간 보관하면 6시간 이내 복구 요구가 있으므로, 표준 복구가 보통 3~5시간인 S3 Glacier(Flexible Retrieval)로 전환하는 것이 가장 저비용

오답 이유

- B. 첫 주 이후 드물게 접근하는 데이터이긴 하나, 수년 보관 관점에서는 Glacier가 Standard-IA보다 GB-월 비용이 낮습니다. 장기 보관 총비용과 6시간 이내 복구 요건을 동시에 고려하면 최적이 아닙니다.

- C. 접근 패턴이 명확(첫 주만 빈번)하므로 Intelligent-Tiering의 자동 계층화 이점이 작고, 객체 모니터링/자동화 비용까지 고려하면 Glacier로 직접 전환하는 것보다 비용 효율이 떨어질 수 있습니다.

- D. Glacier Deep Archive는 복구에 통상 12시간 이상이 필요하므로 “6시간 이내 검색” 요구를 충족하지 못합니다.


## #552
한 회사는 Amazon EC2 인스턴스의 비용을 최적화해야 합니다.  
또한 이 회사는 EC2 인스턴스의 유형(Type)과 패밀리(Family)를 2~3개월마다 변경해야 합니다.

이러한 요구 사항을 충족하려면 회사는 무엇을 해야 합니까?

A. 3년 기간의 Partial Upfront(부분 선결제형) 예약 인스턴스를 구매합니다.  
B. 1년 기간의 No Upfront(선결제 없음) Compute Savings Plan을 구매합니다.  
C. 1년 기간의 All Upfront(전체 선결제형) 예약 인스턴스를 구매합니다.  
D. 1년 기간의 All Upfront EC2 Instance Savings Plan을 구매합니다.

```
A company needs to optimize the cost of its Amazon EC2 instances. The company also needs to change the type and family of its EC2 instances every 2-3 months.  
  
What should the company do to meet these requirements?

- A. Purchase Partial Upfront Reserved Instances for a 3-year term.
- B. Purchase a No Upfront Compute Savings Plan for a 1-year term.
- C. Purchase All Upfront Reserved Instances for a 1-year term.
- D. Purchase an All Upfront EC2 Instance Savings Plan for a 1-year term.
```

정답 : `B`

- Compute Savings Plan은 인스턴스 유형(Type), 패밀리(Family), 리전(Region), OS와 상관없이 EC2 사용량 전체에 적용
	- 따라서 2~3개월마다 인스턴스 종류를 바꾸더라도 할인 혜택 유지
- "No Upfront, 1년 기간"은 단기적 유연성과 비용 최적화 균형을 제공
- RI나 EC2 Instance Savings Plan은 특정 인스턴스 패밀리 또는 리전에 종속되어 변경 시 혜택이 사라짐

오답 이유

- A. Partial Upfront Reserved Instance(3년)는 특정 인스턴스 패밀리/리전에 고정되므로 2~3개월마다 인스턴스를 바꾸면 혜택을 잃게 됩니다.

- C. All Upfront Reserved Instance(1년) 또한 인스턴스 패밀리나 유형 변경 시 적용되지 않으며, 선결제 부담이 커서 유연성이 떨어집니다.

- D. EC2 Instance Savings Plan은 동일한 인스턴스 패밀리 내에서만 변경이 가능하므로, 2~3개월마다 패밀리를 바꾸는 시나리오에는 맞지 않습니다.


## #553
솔루션스 아키텍트는 회사의 Amazon S3 버킷을 검토하여 개인 식별 정보(PII; Personally Identifiable Information)를 찾아야 합니다.  
회사는 PII 데이터를 us-east-1 리전과 us-west-2 리전에 저장하고 있습니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 각 리전에 Amazon Macie를 구성합니다. Amazon S3의 데이터를 분석할 작업(job)을 생성합니다.  
B. 모든 리전에 AWS Security Hub를 구성합니다. Amazon S3의 데이터를 분석할 AWS Config 규칙을 생성합니다.  
C. Amazon Inspector를 구성하여 Amazon S3의 데이터를 분석합니다.  
D. Amazon GuardDuty를 구성하여 Amazon S3의 데이터를 분석합니다.

```
A solutions architect needs to review a company's Amazon S3 buckets to discover personally identifiable information (PII). The company stores the PII data in the us-east-1 Region and us-west-2 Region.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Configure Amazon Macie in each Region. Create a job to analyze the data that is in Amazon S3.
- B. Configure AWS Security Hub for all Regions. Create an AWS Config rule to analyze the data that is in Amazon S3.
- C. Configure Amazon Inspector to analyze the data that is in Amazon S3.
- D. Configure Amazon GuardDuty to analyze the data that is in Amazon S3.
```

정답 : `A`

- Amazon Macie는 S3 버킷 내에 민감한 데이터를 자동으로 식별하고 분류하는 관리형 데이터 보안 및 프라이버시 서비스
- Macie는 리전별로 작동하므로, 데이터를 보관하는 각 리전에 설정해야 함
- S3 버킷을 대상으로 Macie discovery job을 생성하면 자동으로 데이터의 민감도(예: 이름, 이메일, 신용카드 번호 등)를 스캔하고 식별

오답 이유

- B. AWS Security Hub는 여러 보안 서비스(Macie, GuardDuty, Inspector 등)의 결과를 통합하는 관리형 서비스일 뿐, 자체적으로 S3 데이터를 분석하거나 PII를 탐지하지 않습니다.

- C. Amazon Inspector는 EC2, ECR, Lambda 등에서 취약점을 스캔하는 서비스로, S3 데이터 내용 분석이나 PII 탐지 기능은 없습니다.

- D. Amazon GuardDuty는 보안 위협 탐지 서비스이며, S3에 대한 접근 로그를 분석해 악의적 활동을 식별할 수는 있지만, S3 객체 내용(PII 포함)을 검사하지는 않습니다.

## #554
한 회사의 SAP 애플리케이션은 온프레미스 환경의 SQL Server 데이터베이스 백엔드를 사용하고 있습니다.  
회사는 온프레미스의 애플리케이션 서버와 데이터베이스 서버를 AWS로 마이그레이션하려고 합니다.  
이 회사는 SAP 데이터베이스의 높은 요구 사항을 충족할 수 있는 인스턴스 유형이 필요합니다.  
온프레미스 성능 데이터에 따르면 SAP 애플리케이션과 데이터베이스 모두 메모리 사용률이 높습니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 애플리케이션에는 Compute Optimized 인스턴스 패밀리를 사용합니다. 데이터베이스에는 Memory Optimized 인스턴스 패밀리를 사용합니다.  
B. 애플리케이션과 데이터베이스 모두에 Storage Optimized 인스턴스 패밀리를 사용합니다.  
C. 애플리케이션과 데이터베이스 모두에 Memory Optimized 인스턴스 패밀리를 사용합니다.  
D. 애플리케이션에는 High Performance Computing(HPC) Optimized 인스턴스 패밀리를 사용합니다. 데이터베이스에는 Memory Optimized 인스턴스 패밀리를 사용합니다.

```
A company's SAP application has a backend SQL Server database in an on-premises environment. The company wants to migrate its on-premises application and database server to AWS. The company needs an instance type that meets the high demands of its SAP database. On-premises performance data shows that both the SAP application and the database have high memory utilization.  
  
Which solution will meet these requirements?

- A. Use the compute optimized instance family for the application. Use the memory optimized instance family for the database.
- B. Use the storage optimized instance family for both the application and the database.
- C. Use the memory optimized instance family for both the application and the database.
- D. Use the high performance computing (HPC) optimized instance family for the application. Use the memory optimized instance family for the database.
```

정답 : `C`

- 온프레미스 성능 데이터에서 SAP 애플리케이션과 SQL Server 데이터베이스 모두 높은 메모리 사용률을 보였으므로
	- AWS에서는 Memory Optimized 인스턴스 패밀리가 적합
	- 이 인스턴스 패밀리는 대용량 인메모리 데이터셋을 처리하도록 설계되어 SAP와 같은 메모리 집약적 워크로드에 이상적

오답 이유

- A. Compute Optimized 인스턴스는 CPU 집약적인 워크로드(CFD, HPC 등)에 적합하며, 메모리 사용률이 높은 SAP 애플리케이션에는 부적절합니다.

- B. Storage Optimized 인스턴스는 I/O 및 디스크 처리량이 많은 워크로드(예: 로그 분석, Elasticsearch)에 적합하지만, 메모리 중심의 SAP 시스템에는 불필요한 디스크 성능만 제공합니다.

- D. HPC Optimized 인스턴스는 과학 연산, 병렬 연산에 특화되어 있으며, SAP 애플리케이션과 같은 트랜잭션 기반 워크로드에는 적합하지 않습니다.


## #555
한 회사는 퍼블릭 서브넷과 프라이빗 서브넷이 있는 VPC에서 애플리케이션을 운영합니다. VPC는 여러 가용 영역(AZ)에 걸쳐 있습니다. 애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon Simple Queue Service(Amazon SQS) 대기열을 사용합니다.

솔루션스 아키텍트는 EC2 인스턴스와 SQS 대기열 간의 연결을 설정하기 위한 보안 솔루션을 설계해야 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon SQS에 대한 인터페이스 VPC 엔드포인트를 구현합니다. 엔드포인트가 프라이빗 서브넷을 사용하도록 구성합니다. 엔드포인트에 프라이빗 서브넷의 EC2 인스턴스에서 오는 트래픽을 허용하는 인바운드 액세스 규칙을 가진 보안 그룹을 추가합니다.
B. Amazon SQS에 대한 인터페이스 VPC 엔드포인트를 구현합니다. 엔드포인트가 퍼블릭 서브넷을 사용하도록 구성합니다. 인터페이스 엔드포인트에 프라이빗 서브넷의 EC2 인스턴스에서의 액세스를 허용하는 VPC 엔드포인트 정책을 연결합니다.
C. Amazon SQS에 대한 인터페이스 VPC 엔드포인트를 구현합니다. 엔드포인트가 퍼블릭 서브넷을 사용하도록 구성합니다. 지정된 VPC 엔드포인트에서의 요청만 허용하는 Amazon SQS 액세스 정책을 인터페이스 VPC 엔드포인트에 연결합니다.
D. Amazon SQS에 대한 게이트웨이 엔드포인트를 구현합니다. 프라이빗 서브넷에 NAT 게이트웨이를 추가합니다. SQS 대기열에 대한 액세스를 허용하는 IAM 역할을 EC2 인스턴스에 연결합니다.

```
A company runs an application in a VPC with public and private subnets. The VPC extends across multiple Availability Zones. The application runs on Amazon EC2 instances in private subnets. The application uses an Amazon Simple Queue Service (Amazon SQS) queue.  
  
A solutions architect needs to design a secure solution to establish a connection between the EC2 instances and the SQS queue.  
  
Which solution will meet these requirements?

- A. Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the private subnets. Add to the endpoint a security group that has an inbound access rule that allows traffic from the EC2 instances that are in the private subnets.
- B. Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach to the interface endpoint a VPC endpoint policy that allows access from the EC2 instances that are in the private subnets.
- C. Implement an interface VPC endpoint for Amazon SQS. Configure the endpoint to use the public subnets. Attach an Amazon SQS access policy to the interface VPC endpoint that allows requests from only a specified VPC endpoint.
- D. Implement a gateway endpoint for Amazon SQS. Add a NAT gateway to the private subnets. Attach an IAM role to the EC2 instances that allows access to the SQS queue.
```

정답 : `A`

- SQS는 인터페이스 VPC 엔드포인트를 지원. 엔드포인트를 프라이빗 서브넷에 배치하고, 엔드포인트 ENI에 연결된 보안 그룹 인바운드 규칙으로 프라이빗 서브넷의 EC2에서의 접근만 허용
	- 트래픽이 인터넷/NAT을 거치지 않고 VPC 내부 사설 경로로 SQS에 안전하게 연결

오답 이유

- B. 인터페이스 엔드포인트를 퍼블릭 서브넷에 둘 필요가 없고, VPC 엔드포인트 정책은 '인스턴스'를 기준으로 허용/차단하지 않습니다(주로 IAM 주체/리소스/동작 조건). 보안상·운영상 모범사례는 프라이빗 서브넷 배치와 SG 제어입니다.

- C. SQS '대기열 정책'은 대기열 리소스에 붙이는 것이지 VPC 엔드포인트에 붙이지 않습니다. 특정 VPC 엔드포인트만 허용하려면 대기열 정책에 `aws:SourceVpce` 조건을 사용해야 하지만, 선택지의 기술은 부정확합니다.

- D. SQS는 게이트웨이 엔드포인트를 지원하지 않습니다(인터페이스 엔드포인트만 지원). 또한 NAT 게이트웨이는 퍼블릭 서브넷에 배치해야 하며, NAT를 경유하면 인터넷 경로가 포함되어 '프라이빗 전용' 연결 요건에 부합하지 않습니다.


## #556
솔루션스 아키텍트는 AWS CloudFormation 템플릿을 사용해 3계층 웹 애플리케이션을 배포하고 있습니다. 이 웹 애플리케이션은 웹 계층과 애플리케이션 계층으로 구성되며, 애플리케이션 계층은 Amazon DynamoDB 테이블에서 사용자 데이터를 저장하고 조회합니다. 웹 및 애플리케이션 계층은 Amazon EC2 인스턴스에서 호스팅되며, 데이터베이스 계층은 퍼블릭으로 접근할 수 없습니다. 애플리케이션 EC2 인스턴스는 템플릿에 API 자격 증명을 노출하지 않고 DynamoDB 테이블에 접근해야 합니다.

이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. DynamoDB 테이블을 읽기 위한 IAM 역할을 생성합니다. 인스턴스 프로파일을 참조하여 해당 역할을 애플리케이션 인스턴스에 연결합니다.
B. DynamoDB 테이블에서 읽기 및 쓰기에 필요한 권한을 가진 IAM 역할을 생성합니다. 역할을 EC2 인스턴스 프로파일에 추가하고, 인스턴스 프로파일을 애플리케이션 인스턴스에 연결합니다.
C. AWS CloudFormation 템플릿의 매개변수(Parameters) 섹션을 사용하여 사용자가 이미 생성된 IAM 사용자의 액세스 키와 비밀 키를 입력하도록 합니다. 해당 사용자는 DynamoDB 테이블에서 읽기 및 쓰기에 필요한 권한을 가집니다.
D. AWS CloudFormation 템플릿에서 DynamoDB 테이블에서 읽기 및 쓰기에 필요한 권한을 가진 IAM 사용자를 생성합니다. GetAtt 함수를 사용하여 액세스 키와 비밀 키를 검색하고, 사용자 데이터를 통해 애플리케이션 인스턴스에 전달합니다.

```
A solutions architect is using an AWS CloudFormation template to deploy a three-tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template.  
  
What should the solutions architect do to meet these requirements?

- A. Create an IAM role to read the DynamoDB tables. Associate the role with the application instances by referencing an instance profile.
- B. Create an IAM role that has the required permissions to read and write from the DynamoDB tables. Add the role to the EC2 instance profile, and associate the instance profile with the application instances.
- C. Use the parameter section in the AWS CloudFormation template to have the user input access and secret keys from an already-created IAM user that has the required permissions to read and write from the DynamoDB tables.
- D. Create an IAM user in the AWS CloudFormation template that has the required permissions to read and write from the DynamoDB tables. Use the GetAtt function to retrieve the access and secret keys, and pass them to the application instances through the user data.
```

정답 : `B`

- EC2에서 AWS 서비스에 안전하게 접근하는 모범 사례는 IAM 역할(Role) + 인스턴스 프로파일(Instance Profile)을 사용하는 것
- 이렇게 하면 임시 자격 증명(STS)이 자동으로 제공되어 템플릿이나 인스턴스 내 액세스 키를 하드코딩할 필요가 없고 순환도 자동 적용
- 애플리케이션이 저장과 조회를 모두 수행하므로 역할에 읽기/쓰기 최소 권한을 부여해야 함

오답 이유

- A. 읽기 전용 역할만 언급되어 있어 요구사항(저장/조회)에 필요한 쓰기 권한이 부족합니다. 역할+인스턴스 프로파일 접근 방식 자체는 맞지만 권한 범위가 불충분합니다.

- C. IAM 사용자 키를 파라미터로 입력받아 배포하면 키 노출/보관/회전 책임이 생기고, 템플릿·파이프라인에 비밀이 흘러들 수 있어 모범 사례가 아닙니다.

- D. CloudFormation으로 IAM 사용자를 생성하고 키를 유저데이터로 전달하는 것은 키 노출 위험이 높고, 장기 자격 증명 관리 오버헤드가 큽니다. 또한 유저데이터는 쉽게 조회될 수 있습니다.

## #557
솔루션스 아키텍트가 분석 애플리케이션을 관리하고 있습니다. 애플리케이션은 반정형(semistructured) 대용량 데이터를 Amazon S3 버킷에 저장합니다. 솔루션스 아키텍트는 데이터를 더 빠르게 처리하기 위해 병렬 데이터 처리를 사용하고자 합니다. 또한 Amazon Redshift 데이터베이스에 저장된 정보를 사용하여 데이터를 보강(enrich)하고자 합니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon Athena를 사용하여 S3 데이터를 처리합니다. AWS Glue를 Amazon Redshift 데이터와 함께 사용하여 S3 데이터를 보강합니다.
B. Amazon EMR을 사용하여 S3 데이터를 처리합니다. Amazon EMR을 Amazon Redshift 데이터와 함께 사용하여 S3 데이터를 보강합니다.
C. Amazon EMR을 사용하여 S3 데이터를 처리합니다. Amazon Kinesis Data Streams를 사용하여 S3 데이터를 Amazon Redshift로 이동하여 데이터를 보강할 수 있도록 합니다.
D. AWS Glue를 사용하여 S3 데이터를 처리합니다. AWS Lake Formation을 Amazon Redshift 데이터와 함께 사용하여 S3 데이터를 보강합니다.

```
A solutions architect manages an analytics application. The application stores large amounts of semistructured data in an Amazon S3 bucket. The solutions architect wants to use parallel data processing to process the data more quickly. The solutions architect also wants to use information that is stored in an Amazon Redshift database to enrich the data.  
  
Which solution will meet these requirements?

- A. Use Amazon Athena to process the S3 data. Use AWS Glue with the Amazon Redshift data to enrich the S3 data.
- B. Use Amazon EMR to process the S3 data. Use Amazon EMR with the Amazon Redshift data to enrich the S3 data.
- C. Use Amazon EMR to process the S3 data. Use Amazon Kinesis Data Streams to move the S3 data into Amazon Redshift so that the data can be enriched.
- D. Use AWS Glue to process the S3 data. Use AWS Lake Formation with the Amazon Redshift data to enrich the S3 data.
```

정답 : `B`

- Amazon EMR(Spark/Hadoop)은 대규모 S3 데이터를 병렬 처리하는데 최적
- JDBC 커넥터･Spark 커넥터 등을 통해 Redshift의 테이블을 소스/조인 대상으로 직접 읽거 S3 데이터와 동시에 조인/보강 작업 수행 가능
- 한 파이프라인(EMR Job)에서 S3+Redshift를 함께 처리하므로 성능과 단순성이 모두 충족

오답 이유

- A. Athena와 Glue를 분리해 각각 처리하면 조인/보강을 단일 실행 맥락에서 수행하기 어렵고, 병렬 대량 처리/파이프라인 단순성 면에서 EMR 직접 조인보다 비효율적입니다.

- C. Kinesis Data Streams는 실시간 스트리밍 수집용이며, 기존 S3의 대량 배치 데이터를 Redshift로 옮기는 경로로 적합하지 않습니다. 또한 목적은 S3 상의 병렬 처리+Redshift 데이터 보강이지 S3→Redshift 적재가 아닙니다.

- D. Lake Formation은 **데이터 액세스 제어/카탈로그/거버넌스** 서비스로서 보강 처리를 수행하지 않습니다. 보강 처리는 실행 엔진(EMR/Spark 등)이 담당해야 합니다.


## #558
한 회사는 동일한 AWS 계정의 us-west-2 리전에 두 개의 VPC를 보유하고 있습니다. 회사는 이 VPC들 간에 네트워크 트래픽을 허용해야 합니다. 매월 약 500 GB의 데이터 전송이 VPC 간에 발생할 예정입니다.

이 VPC들을 연결하는 가장 비용 효율적인 솔루션은 무엇입니까?

A. VPC들을 연결하기 위해 AWS Transit Gateway를 구현합니다. 각 VPC의 라우팅 테이블을 업데이트하여 VPC 간 통신에 트랜짓 게이트웨이를 사용하도록 합니다.
B. VPC들 사이에 AWS Site-to-Site VPN 터널을 구현합니다. 각 VPC의 라우팅 테이블을 업데이트하여 VPC 간 통신에 VPN 터널을 사용하도록 합니다.
C. VPC들 사이에 VPC 피어링 연결을 설정합니다. 각 VPC의 라우팅 테이블을 업데이트하여 VPC 간 통신에 VPC 피어링 연결을 사용하도록 합니다.
D. VPC들 사이에 1 GB AWS Direct Connect 연결을 설정합니다. 각 VPC의 라우팅 테이블을 업데이트하여 VPC 간 통신에 Direct Connect 연결을 사용하도록 합니다.

```
A company has two VPCs that are located in the us-west-2 Region within the same AWS account. The company needs to allow network traffic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month.  
  
What is the MOST cost-effective solution to connect these VPCs?

- A. Implement AWS Transit Gateway to connect the VPCs. Update the route tables of each VPC to use the transit gateway for inter-VPC communication.
- B. Implement an AWS Site-to-Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter-VPC communication.
- C. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication.
- D. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter-VPC communication.
```

정답 : `C`

- 동일 리전 내 두 VPC 간 통신은 VPC 피어링이 가장 단순하고 데이터 처리 요금이 낮아 월 500GB 규모에서 가장 비용 효율적
- 별도의 어태치먼트/시간당 요금이 없고, 라우트만 추가하면 사설 네트워크 경로로 안정적으로 통신 가능

오답 이유

- A. Transit Gateway는 다수 VPC/온프렘 허브-앤-스포크에 적합하지만, 데이터 처리당 요금(GB당) + 어태치먼트 시간당 비용이 추가되어 두 VPC만 연결할 때 VPC 피어링보다 비쌉니다.

- B. Site-to-Site VPN은 인터넷을 경유하는 IPSec 터널로 대역폭·지연 측면에서 불리하고, VPC↔VPC의 네이티브 구성도 표준적이지 않습니다(보통 TGW 또는 EC2 기반 어플라이언스 필요). 운영/비용 면에서 피어링보다 비효율적입니다.

- D. Direct Connect는 온프레미스↔AWS 전용선 용도로 설계되었습니다. VPC↔VPC 연결 용도가 아니며, 전용 포트 시간 요금 등으로 비용 측면에서도 과도합니다.


## #559
한 회사는 서로 다른 제품 라인을 위해 AWS에서 여러 애플리케이션을 호스팅하고 있습니다.  
이 애플리케이션들은 Amazon EC2 인스턴스와 Application Load Balancer를 포함한 다양한 컴퓨팅 리소스를 사용합니다.  
애플리케이션들은 여러 AWS 리전에 걸쳐 있으며, 동일한 AWS Organizations 내의 서로 다른 AWS 계정에서 운영됩니다.  
각 제품 라인의 팀은 각 계정에서 컴퓨팅 리소스에 태그를 지정했습니다.

회사는 Organizations의 통합 결제(Consolidated Billing) 기능을 통해 각 제품 라인별 비용 세부 정보를 보고자 합니다.

이 요구 사항을 충족하기 위해 수행해야 하는 단계의 조합은 무엇입니까? (2개를 선택하십시오.)

A. AWS Billing 콘솔에서 특정 AWS가 생성한 태그를 선택합니다.  
B. AWS Billing 콘솔에서 특정 사용자 정의(user-defined) 태그를 선택합니다.  
C. AWS Resource Groups 콘솔에서 특정 사용자 정의(user-defined) 태그를 선택합니다.  
D. 각 AWS 계정에서 선택된 태그를 활성화합니다.  
E. Organizations 관리(Management) 계정에서 선택된 태그를 활성화합니다.

```
A company hosts multiple applications on AWS for different product lines. The applications use different compute resources, including Amazon EC2 instances and Application Load Balancers. The applications run in different AWS accounts under the same organization in AWS Organizations across multiple AWS Regions. Teams for each product line have tagged each compute resource in the individual accounts.  
  
The company wants more details about the cost for each product line from the consolidated billing feature in Organizations.  
  
Which combination of steps will meet these requirements? (Choose two.)

- A. Select a specific AWS generated tag in the AWS Billing console.
- B. Select a specific user-defined tag in the AWS Billing console.
- C. Select a specific user-defined tag in the AWS Resource Groups console.
- D. Activate the selected tag from each AWS account.
- E. Activate the selected tag from the Organizations management account.
```

정답 : `B, E`

- 비용 할당 태그를 사용하려면 Billing and Cost Management 콘솔에서 사용자 정의 태그를 선택하고 활성화
- 태그는 Organizations 관리 계정에서만 활성화되어야 하며, 이렇게 하면 통합 결제 전체의 모든 계정의 리소스에 동일하게 적용
- AWS는 이후 해당 태그를 기반으로 비용 보고서(Cost Explorer, CUR 등)에서 제품 라인별 비용을 세분화해 확인 가능

오답 이유

- A. AWS가 자동 생성한 태그(예: aws:createdBy)는 비용 할당 태그로 활성화할 수는 있지만, 제품 라인 식별용 사용자 정의 태그가 아니므로 요구사항을 충족하지 않습니다.

- C. Resource Groups 콘솔은 리소스 필터링/관리 용도로 사용되며, Billing이나 Cost Allocation과는 직접적인 연관이 없습니다.

- D. 개별 계정에서 태그를 활성화하는 것은 통합 결제 전체에 적용되지 않습니다. Organizations의 관리 계정에서만 활성화해야 전체 계정의 비용 태그가 반영됩니다.


## #560
한 회사의 솔루션스 아키텍트가 AWS Organizations를 사용하는 AWS 멀티 계정 솔루션을 설계하고 있습니다. 솔루션스 아키텍트는 회사의 계정을 조직 단위(OU)로 구성했습니다.

솔루션스 아키텍트는 OU 계층 구조의 모든 변경을 식별할 수 있는 솔루션이 필요합니다. 또한 변경이 있을 때 회사 운영 팀에 알림을 보내야 합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Control Tower를 사용하여 AWS 계정을 프로비저닝합니다. OU 계층 구조의 변경을 식별하기 위해 계정 드리프트 알림을 사용합니다.
B. AWS Control Tower를 사용하여 AWS 계정을 프로비저닝합니다. OU 계층 구조의 변경을 식별하기 위해 AWS Config 집계 규칙을 사용합니다.
C. AWS Service Catalog를 사용하여 Organizations에서 계정을 생성합니다. OU 계층 구조의 변경을 식별하기 위해 AWS CloudTrail 조직 트레일(organization trail)을 사용합니다.
D. AWS CloudFormation 템플릿을 사용하여 Organizations에서 계정을 생성합니다. 스택의 드리프트 감지 작업을 사용하여 OU 계층 구조의 변경을 식별합니다.

```
A company's solutions architect is designing an AWS multi-account solution that uses AWS Organizations. The solutions architect has organized the company's accounts into organizational units (OUs).  
  
The solutions architect needs a solution that will identify any changes to the OU hierarchy. The solution also needs to notify the company's operations team of any changes.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Provision the AWS accounts by using AWS Control Tower. Use account drift notifications to identify the changes to the OU hierarchy.
- B. Provision the AWS accounts by using AWS Control Tower. Use AWS Config aggregated rules to identify the changes to the OU hierarchy.
- C. Use AWS Service Catalog to create accounts in Organizations. Use an AWS CloudTrail organization trail to identify the changes to the OU hierarchy.
- D. Use AWS CloudFormation templates to create accounts in Organizations. Use the drift detection operation on a stack to identify the changes to the OU hierarchy.
```

정답 : `C`

- OU 생성/이동/수정과 같은 Organizations 관리 작업은 CloudTrail 조직 트레일에 관리 이벤트로 기록
- 조직 트레일은 모든 계정과 모든 리전의 이벤트를 중앙에서 수집하므로 운영 오버헤드가 가장 낮음
- EventBridge 규칙 → SNS 알림을 연결하면 변경 발생 시 운영 팀에 자동 통지 가능

오답 이유

- A. Control Tower의 드리프트 알림은 주로 랜딩존/가드레일에서의 비관리 변경을 탐지하는 용도로 적합하며, OU 계층 변경 전반을 식별하는 기본 수단은 아닙니다. 조직 전반의 관리 이벤트 수집에는 CloudTrail 조직 트레일이 표준적이고 더 단순합니다.

- B. AWS Config는 계정 내 리소스 구성을 추적/평가하지만, Organizations의 OU 계층 변경을 직접 리소스로 취급하여 식별하는 데 적합하지 않습니다. 또한 다계정·다리전 집계 규칙 설정은 오버헤드를 증가시킵니다.

- D. CloudFormation 드리프트 감지는 스택 리소스와 실제 상태 간 차이를 탐지합니다. OU 계층 변경은 일반적으로 CloudFormation 스택 리소스 범주가 아니므로 해당 방법으로 포괄적 식별이 어렵습니다.