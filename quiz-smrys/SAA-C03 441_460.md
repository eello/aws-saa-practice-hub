---
created: 2025-10-13 14:48:13
last_modified: 2025-10-13 17:17:32
---
## #441
한 회사는 Application Load Balancer 뒤에 Amazon Linux 기반 Amazon EC2 인스턴스들로 다중 계층 웹 애플리케이션을 호스팅하고 있습니다. 인스턴스들은 여러 가용 영역에 걸친 Auto Scaling 그룹에서 실행됩니다. 회사는 애플리케이션의 최종 사용자가 대량의 정적 웹 콘텐츠에 접근할 때 Auto Scaling 그룹이 더 많은 온디맨드 인스턴스를 시작한다는 것을 관찰했습니다. 회사는 비용을 최적화하고 싶습니다.

가장 비용 효율적으로 애플리케이션을 재설계하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Auto Scaling 그룹이 온디맨드 인스턴스 대신 예약 인스턴스를 사용하도록 업데이트합니다.
B. Auto Scaling 그룹이 온디맨드 인스턴스 대신 스팟 인스턴스를 시작하여 확장하도록 업데이트합니다.
C. Amazon S3 버킷에서 정적 웹 콘텐츠를 호스팅하도록 Amazon CloudFront 배포를 생성합니다.
D. 정적 웹사이트 콘텐츠를 호스팅하기 위해 Amazon API Gateway API 뒤에 AWS Lambda 함수를 생성합니다.

```
A company hosts a multi-tier web application on Amazon Linux Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company observes that the Auto Scaling group launches more On-Demand Instances when the application's end users access high volumes of static web content. The company wants to optimize cost.  
  
What should a solutions architect do to redesign the application MOST cost-effectively?

- A. Update the Auto Scaling group to use Reserved Instances instead of On-Demand Instances.
- B. Update the Auto Scaling group to scale by launching Spot Instances instead of On-Demand Instances.
- C. Create an Amazon CloudFront distribution to host the static web contents from an Amazon S3 bucket.
- D. Create an AWS Lambda function behind an Amazon API Gateway API to host the static website contents.
```

정답 : `C`

- 정적 콘텐츠는 S3 정적 웹 호스팅과 CloudFront 엣지 캐싱으로 제공하면 EC2/ALB로 향하는 트래픽을 크게 줄일 수 있음
	- 이를 통해 Auto Scaling 확장을 유발하는 원인을 제거
- S3의 스토리지 비용과 CloudFront 캐시 적중으로 전송 비용을 절감하고, EC2 컴퓨팅 비용도 감소하므로 가장 비용 효율적

오답 이유

- **A. 예약 인스턴스 사용**: 컴퓨팅 단가만 낮출 뿐 정적 콘텐츠로 인한 확장 자체를 줄이지 못합니다. 근본 원인(정적 자산 제공 방식) 해결 아님.
    
- **B. 스팟 인스턴스로 확장**: 비용은 낮출 수 있으나 회수(interruption) 위험이 있고, 여전히 EC2로 정적 자산을 서빙해 확장 원인을 제거하지 못합니다.
    
- **D. API Gateway + Lambda**: 정적 콘텐츠 제공에 부적합하고 비용/구조가 과도하게 복잡합니다. 정적 파일은 S3+CloudFront 조합이 표준적이고 저비용입니다.


## #442
한 회사는 여러 AWS 계정에 걸쳐 페타바이트 규모의 데이터를 저장하고 있습니다. 회사는 AWS Lake Formation을 사용해 데이터 레이크를 관리합니다. 회사의 데이터 사이언스 팀은 분석 목적을 위해 자사 엔지니어링 팀과 각 계정의 선택적 데이터를 보안적으로 공유하고자 합니다.

가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 필요한 데이터를 공용 계정으로 복사합니다. 해당 계정에 IAM 액세스 역할을 생성합니다. 권한 정책에 엔지니어링 팀 계정의 사용자를 신뢰 주체로 지정하여 액세스를 부여합니다.
B. 데이터가 저장된 각 계정에서 Lake Formation permissions의 Grant 명령을 사용하여 필요한 엔지니어링 팀 사용자에게 데이터 액세스를 허용합니다.
C. AWS Data Exchange를 사용하여 필요한 데이터를 대상 엔지니어링 팀 계정에 비공개로 게시합니다.
D. Lake Formation 태그 기반 액세스 제어를 사용하여 엔지니어링 팀 계정에 필요한 데이터에 대한 교차 계정 권한을 부여하고 인가합니다.

```
A company stores several petabytes of data across multiple AWS accounts. The company uses AWS Lake Formation to manage its data lake. The company's data science team wants to securely share selective data from its accounts with the company's engineering team for analytical purposes.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Copy the required data to a common account. Create an IAM access role in that account. Grant access by specifying a permission policy that includes users from the engineering team accounts as trusted entities.
- B. Use the Lake Formation permissions Grant command in each account where the data is stored to allow the required engineering team users to access the data.
- C. Use AWS Data Exchange to privately publish the required data to the required engineering team accounts.
- D. Use Lake Formation tag-based access control to authorize and grant cross-account permissions for the required data to the engineering team accounts.
```

정답 : `D`

- Lake Formation의 LF-태그 기반 액세스 제어는 데이터와 주체를 태그로 묶어 정책 한 번으로 교차 계정 다수 리소스에 일괄 권한을 부여
	- 계정･리소스･열 단위로 그랜드 작업을 반복하는 수고를 줄일 수 있음
- Lake Formation이 제공하는 교차 계정 권한 위임 및 리소스 링크와 결합해 보안적으로 선택적 공유를 최소 운영 오버헤드로 구현 가능

오답 이유

- **A. 공용 계정 복사 + IAM 역할**    
    데이터 **복사·동기화 운영 부담**이 크고, **열 단위 등 세분 권한 제어**를 IAM만으로 관리하기 어려우며 Lake Formation 거버넌스를 우회합니다.

- **B. 각 계정에서 Grant 명령 반복**    
    계정/리소스/열별로 **세부 권한을 일일이 부여**해야 하므로 규모가 커질수록 관리 오버헤드가 큽니다. 정책 중앙화가 어렵습니다.

- **C. AWS Data Exchange**
    외부/서로 다른 조직 간 **데이터 상품 배포**에 적합합니다. 내부 팀 간 분석 공유에는 과도하며 Lake Formation 메타데이터/권한 모델과의 **운영 일관성**이 떨어집니다.


## #443
한 회사가 AWS에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다.  
이 애플리케이션은 전 세계 여러 지역의 사용자가 접근할 예정입니다.  
사용자들은 최대 기가바이트 단위의 고유 데이터를 다운로드 및 업로드할 수 있습니다.  
개발팀은 업로드 및 다운로드 지연(latency)을 최소화하고 성능을 극대화하면서도 비용 효율적인 솔루션을 원합니다.  

솔루션스 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. 애플리케이션을 호스팅하기 위해 Amazon S3와 Transfer Acceleration을 사용합니다.  
B. 애플리케이션을 호스팅하기 위해 Amazon S3와 CacheControl 헤더를 사용합니다.  
C. 애플리케이션을 호스팅하기 위해 Amazon EC2, Auto Scaling, Amazon CloudFront를 사용합니다.  
D. 애플리케이션을 호스팅하기 위해 Amazon EC2, Auto Scaling, Amazon ElastiCache를 사용합니다.

```
A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost-effective solution to minimize upload and download latency and maximize performance.  
  
What should a solutions architect do to accomplish this?

- A. Use Amazon S3 with Transfer Acceleration to host the application.
- B. Use Amazon S3 with CacheControl headers to host the application.
- C. Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.
- D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application.
```

정답 : `A`

- Amazon S3 Transfer Acceleration(S3TA)는 전 세계의 AWS 엣지 로케이션을 통해 S3 업로드/다운로드를 가속화
- 사용자는 가장 가까운 엣지 로케이션으로 데이터를 업로드하고, 그 데이터는 AWS 전용 네트워크를 통해 S3 버킷으로 전달
	- 인터넷 지연 최소화 및 전송 속도 극대화
- S3TA는 대규모 파일 업로드/다운로드에 매우 효율적이며 애플리케이션 서버를 직접 관리할 필요가 없어 서버리스 + 저비용 구조 제공

오답 이유

- **B. Amazon S3 + CacheControl 헤더**
    CacheControl 헤더는 브라우저 캐싱을 제어할 뿐이며, 업로드 성능 향상에는 전혀 도움이 되지 않습니다.    
    또한 다운로드 가속도 엣지 네트워크를 사용하지 않기 때문에 지연 감소 효과가 없습니다.

- **C. EC2 + Auto Scaling + CloudFront**
    CloudFront는 다운로드 캐싱은 가속화할 수 있으나, **업로드 트래픽(클라이언트 → 서버)** 은 가속하지 못합니다.
    또한 EC2를 운영하면 서버 유지·Auto Scaling·보안·가용성 관리 비용이 증가합니다.    
    “S3TA”는 업로드/다운로드 모두 전송을 가속화하기 때문에 더 적합합니다.

- **D. EC2 + Auto Scaling + ElastiCache**
    ElastiCache는 데이터베이스 쿼리 결과나 세션 데이터를 캐싱하는 용도로 사용됩니다.
    파일 업로드/다운로드와는 무관하며, 전송 지연을 줄이는 효과도 없습니다.

## #444
한 회사는 애플리케이션을 위한 신뢰성 높은 아키텍처를 설계하기 위해 솔루션스 아키텍트를 고용했습니다. 애플리케이션은 하나의 Amazon RDS DB 인스턴스와 웹 서버를 실행하는 두 대의 수동 프로비저닝된 Amazon EC2 인스턴스로 구성되어 있습니다. EC2 인스턴스들은 단일 가용 영역(Availability Zone)에 위치해 있습니다.

최근 한 직원이 DB 인스턴스를 삭제하여 애플리케이션이 그 결과로 24시간 동안 사용 불가능해졌습니다. 회사는 전체 환경의 신뢰성에 대해 우려하고 있습니다.

애플리케이션 인프라의 신뢰성을 극대화하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 한 대의 EC2 인스턴스를 삭제하고 다른 EC2 인스턴스에서 종료 보호를 활성화합니다. DB 인스턴스를 Multi-AZ로 업데이트하고 삭제 보호를 활성화합니다.
B. DB 인스턴스를 Multi-AZ로 업데이트하고 삭제 보호를 활성화합니다. EC2 인스턴스를 Application Load Balancer 뒤에 배치하고, 여러 가용 영역에 걸친 EC2 Auto Scaling 그룹에서 실행합니다.
C. 추가 DB 인스턴스를 하나 더 생성하고 Amazon API Gateway 및 AWS Lambda 함수를 함께 생성합니다. 애플리케이션이 API Gateway를 통해 Lambda 함수를 호출하도록 구성합니다. Lambda 함수가 두 개의 DB 인스턴스에 데이터를 쓰도록 합니다.
D. EC2 인스턴스를 여러 가용 영역에 위치한 여러 서브넷을 가진 EC2 Auto Scaling 그룹에 배치합니다. 온디맨드 인스턴스 대신 스팟 인스턴스를 사용합니다. 인스턴스의 상태를 모니터링하기 위해 Amazon CloudWatch 알람을 설정합니다. DB 인스턴스를 Multi-AZ로 업데이트하고 삭제 보호를 활성화합니다.

```
A company has hired a solutions architect to design a reliable architecture for its application. The application consists of one Amazon RDS DB instance and two manually provisioned Amazon EC2 instances that run web servers. The EC2 instances are located in a single Availability Zone.  
  
An employee recently deleted the DB instance, and the application was unavailable for 24 hours as a result. The company is concerned with the overall reliability of its environment.  
  
What should the solutions architect do to maximize reliability of the application's infrastructure?

- A. Delete one EC2 instance and enable termination protection on the other EC2 instance. Update the DB instance to be Multi-AZ, and enable deletion protection.
- B. Update the DB instance to be Multi-AZ, and enable deletion protection. Place the EC2 instances behind an Application Load Balancer, and run them in an EC2 Auto Scaling group across multiple Availability Zones.
- C. Create an additional DB instance along with an Amazon API Gateway and an AWS Lambda function. Configure the application to invoke the Lambda function through API Gateway. Have the Lambda function write the data to the two DB instances.
- D. Place the EC2 instances in an EC2 Auto Scaling group that has multiple subnets located in multiple Availability Zones. Use Spot Instances instead of On-Demand Instances. Set up Amazon CloudWatch alarms to monitor the health of the instances Update the DB instance to be Multi-AZ, and enable deletion protection.
```

정답 : `B`

- RDS Multi-AZ + 삭제보호 : 동기식 스탠바이로 장애 시 자동 페일오버 제공, 실수성 삭제를 방지해 DB 단일 장애점 제거
- ALB + Auto Scaling(다중 AZ) : 웹 계층을 최소 2개 AZ로 분산하고 자동 복구/확장으로 인스턴스 장애･AZ 장애에도 가용성 유지
	- 데이터베이스와 웹 계층 모두에 대해 단일 장애점 제거 + 자동 복구/확장을 구현하므로 신뢰성 향상

오답 이유

- **A**: 웹 계층을 한 대로 축소하면 가용성이 오히려 악화됩니다(단일 인스턴스/단일 AZ). 부분적으로만 맞습니다.
    
- **C**: Lambda/API Gateway를 추가하는 것은 패턴에 부합하지 않으며, 애플리케이션 레이어를 불필요하게 복잡하게 만듭니다. 또한 RDS 다중 AZ 고가용성 문제의 정공법이 아닙니다.
    
- **D**: 다중 AZ Auto Scaling은 좋지만 **스팟 인스턴스는 회수(interruption) 가능**하여 신뢰성 극대화 목적에 부적합합니다. 비용 최적화 선택이지 가용성 강화 기본 해법은 아님.


## #445
한 회사는 기업 데이터 센터의 대형 NAS 시스템에 700TB의 데이터를 저장하고 있습니다. 이 회사는 10Gbps AWS Direct Connect 연결이 있는 하이브리드 환경을 보유하고 있습니다.

규제 기관의 감사를 받은 후, 회사는 90일 이내에 데이터를 클라우드로 이동해야 합니다. 회사는 중단 없이 효율적으로 데이터를 이동해야 합니다. 전송 기간 동안에도 데이터에 계속 액세스하고 업데이트할 수 있어야 합니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 회사 데이터 센터에 AWS DataSync 에이전트를 생성합니다. 데이터 전송 작업을 생성합니다. Amazon S3 버킷으로 전송을 시작합니다.
B. 데이터를 AWS Snowball Edge Storage Optimized 디바이스에 백업합니다. 디바이스를 AWS 데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 마운트합니다.
C. Direct Connect 연결을 통해 로컬 스토리지에서 지정한 Amazon S3 버킷으로 rsync를 사용해 직접 복사합니다.
D. 데이터를 테이프에 백업합니다. 테이프를 AWS 데이터 센터로 배송합니다. 온프레미스 파일 시스템에 대상 Amazon S3 버킷을 마운트합니다.

```
A company is storing 700 terabytes of data on a large network-attached storage (NAS) system in its corporate data center. The company has a hybrid environment with a 10 Gbps AWS Direct Connect connection.  
  
After an audit from a regulator, the company has 90 days to move the data to the cloud. The company needs to move the data efficiently and without disruption. The company still needs to be able to access and update the data during the transfer window.  
  
Which solution will meet these requirements?

- A. Create an AWS DataSync agent in the corporate data center. Create a data transfer task Start the transfer to an Amazon S3 bucket.
- B. Back up the data to AWS Snowball Edge Storage Optimized devices. Ship the devices to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.
- C. Use rsync to copy the data directly from local storage to a designated Amazon S3 bucket over the Direct Connect connection.
- D. Back up the data on tapes. Ship the tapes to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.
```

정답 : `A`

- AWS DataSync는 NFS/SMB 기반 NAS에서 S3로 증분･병렬 전송을 수행해 대용량 데이터를 효율적으로 이동
- Direct Connect(10Gbps)를 활용해 전송 효율을 극대화하고 지속 동기화(주기적/스케줄링)로 전송 기간동안 발생하는 변경 사항을 계속 반영
- 최종 컷오버 시점에 짧은 중단으로 마이그레이션 완료할 수 있어 중단 최소화

오답 이유

- **B. Snowball Edge + S3 버킷 마운트**
    Snowball Edge는 오프라인 대량 이관에 적합하지만, 디바이스 수거/반입 전까지 **S3에 반영되지 않으며 실시간 업데이트 동기화가 불가**합니다. 또한 **S3 버킷은 온프레미스에 마운트할 수 없습니다**.

- **C. rsync + Direct Connect**    
    rsync는 **스루풋 활용, 병렬화, 재시도/검증, 메타데이터 보존** 측면에서 운영 부담이 크고 비효율적입니다. 대량/장기 동기화 및 **지속 증분 동기화 자동화**에 DataSync가 더 적합합니다.

- **D. 테이프 백업 배송 + S3 마운트**
    테이프 기반 이관은 **오프라인 일괄 전송**으로 전송 기간 동안 변경 사항 동기화가 어렵고, 역시 **S3 버킷 마운트는 불가**합니다. 중단 없이 지속 접근/업데이트 요구에 부적합합니다.


## #446
한 회사는 Amazon S3 버킷에 PDF 형식의 데이터를 저장합니다. 회사는 Amazon S3에 있는 모든 신규 및 기존 데이터를 7년 동안 보관해야 하는 법적 요구사항을 따라야 합니다.

가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷에 대해 S3 버전 관리(Versioning) 기능을 켭니다. 7년 후 데이터를 삭제하도록 S3 수명주기(Lifecycle)를 구성합니다. 모든 S3 객체에 대해 다중 요소 인증(MFA) 삭제를 구성합니다.
B. S3 버킷에 대해 거버넌스 보존 모드(Governance retention mode)로 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. 기존 데이터를 규정 준수 상태로 만들기 위해 기존 객체를 모두 다시 복사합니다.
C. S3 버킷에 대해 컴플라이언스 보존 모드(Compliance retention mode)로 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. 기존 데이터를 규정 준수 상태로 만들기 위해 기존 객체를 모두 다시 복사합니다.
D. S3 버킷에 대해 컴플라이언스 보존 모드(Compliance retention mode)로 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. S3 Batch Operations를 사용하여 기존 데이터를 규정 준수 상태로 만듭니다.

```
A company stores data in PDF format in an Amazon S3 bucket. The company must follow a legal requirement to retain all new and existing data in Amazon S3 for 7 years.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Turn on the S3 Versioning feature for the S3 bucket. Configure S3 Lifecycle to delete the data after 7 years. Configure multi-factor authentication (MFA) delete for all S3 objects.
- B. Turn on S3 Object Lock with governance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Recopy all existing objects to bring the existing data into compliance.
- C. Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Recopy all existing objects to bring the existing data into compliance.
- D. Turn on S3 Object Lock with compliance retention mode for the S3 bucket. Set the retention period to expire after 7 years. Use S3 Batch Operations to bring the existing data into compliance.
```

정답 : `D`

- 법적 보존 요건에는 WORM(Write Once Read Many) 보장이 필요한데, 이를 위해서는 관리자도 임의로 삭제/수정할 수 없는 Object Lock "Compliance" 모드가 적합
- 기존 객체에 보존 설정을 적용하려면 대량 객체에 태그/보존을 일괄 적용할 수 있는 S3 Batch Operations가 운영 오버헤드가 낮음

오답 이유

- **A. Versioning + Lifecycle + MFA Delete**    
    버전 관리와 수명주기는 **삭제 일정**일 뿐 **법적 보존(WORM) 강제**가 아닙니다. MFA Delete도 관리자가 해제 가능하여 **법적 요구 충족 불가**입니다.

- **B. Object Lock “Governance” + 재복사**
    Governance 모드는 **특정 권한이 있으면 우회**가 가능해 법적 요건에 미흡합니다. 게다가 **전량 재복사**는 운영 오버헤드가 큽니다.

- **C. Object Lock “Compliance” + 재복사**
    보존 강도는 적절하나, **모든 객체 재복사**는 시간·비용·운영 부담이 큽니다. Batch Operations로 **재복사 없이** 적용하는 D가 더 효율적입니다.


## #447
한 회사에는 Amazon API Gateway가 호출하는 AWS Lambda 함수로 실행되는 상태 비저장(stateless) 웹 애플리케이션이 있습니다. 회사는 리전(Region) 장애 시 페일오버가 가능하도록 애플리케이션을 여러 AWS 리전에 배포하고자 합니다.

여러 리전으로 트래픽을 라우팅하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 각 리전에 대해 Amazon Route 53 상태 확인(Health Check)을 생성합니다. 활성-활성(Active-Active) 페일오버 구성을 사용합니다.
B. 각 리전에 대한 오리진을 갖는 Amazon CloudFront 배포를 생성합니다. 트래픽 라우팅에 CloudFront 상태 확인을 사용합니다.
C. 트랜짓 게이트웨이를 생성합니다. 각 리전의 API Gateway 엔드포인트에 트랜짓 게이트웨이를 연결합니다. 트랜짓 게이트웨이로 요청을 라우팅하도록 구성합니다.
D. 기본 리전에 Application Load Balancer를 생성합니다. 대상 그룹이 각 리전의 API Gateway 엔드포인트 호스트 이름을 가리키도록 설정합니다.

```
A company has a stateless web application that runs on AWS Lambda functions that are invoked by Amazon API Gateway. The company wants to deploy the application across multiple AWS Regions to provide Regional failover capabilities.  
  
What should a solutions architect do to route traffic to multiple Regions?

- A. Create Amazon Route 53 health checks for each Region. Use an active-active failover configuration.
- B. Create an Amazon CloudFront distribution with an origin for each Region. Use CloudFront health checks to route traffic.
- C. Create a transit gateway. Attach the transit gateway to the API Gateway endpoint in each Region. Configure the transit gateway to route requests.
- D. Create an Application Load Balancer in the primary Region. Set the target group to point to the API Gateway endpoint hostnames in each Region.
```

정답 : `A`

- 여러 리전에 배포된 API Gateway 엔드포인트에 대해 Route 53 레코드를 다중 리전으로 구성하고
	- 각 엔드포인트에 Health Check를 붙여 가용한 리전으로만 트래픽을 라우팅하는 방식이 표준
- 라우팅 정책은 지연 시간 기반 또는 가중치 기반에 Health Check를 결합해 활성-활성 분산 + 비정상 리전 자동 배제(페일오버)를 구현
- 이 방식이 가장 간단하고 오버헤드가 낮으며 서버리스 다중 리전 아키텍처에 적합

오답 이유

- **B. CloudFront로 오리진 다중 구성 + CloudFront 상태 확인**    
    CloudFront는 **오리진 페일오버(주/보조)** 는 가능하나, **리전별 다중 엔드포인트에 대한 정교한 라우팅/헬스체크 기반 활성-활성 분산**은 제한적입니다. 또한 API 엔드포인트 라우팅에는 **Route 53이 정석**입니다.

- **C. Transit Gateway로 API Gateway에 연결**    
    Transit Gateway는 **VPC 간/온프레미스 연결용 L3 라우팅 서비스**로, **퍼블릭 API Gateway 엔드포인트 트래픽 라우팅**에 사용하는 서비스가 아닙니다. API Gateway와 직접 연결해 요청 라우팅을 할 수 없습니다.

- **D. ALB가 각 리전의 API Gateway 엔드포인트를 대상(Target)으로**
    ALB 대상 그룹은 **IP/인스턴스/람다 등 특정 타입**만 지원하며, **다른 리전의 퍼블릭 API Gateway 호스트명을 직접 타깃으로 구성**하는 패턴이 아닙니다. 또한 단일 리전의 ALB로 다중 리전 경로 제어를 하는 것은 **가용성 측면에서 부적절**합니다.


## #448
한 회사에는 Management와 Production이라는 두 개의 VPC가 있습니다. Management VPC는 고객 게이트웨이(customer gateway)를 통해 VPN을 사용하여 데이터 센터의 단일 장치에 연결합니다. Production VPC는 가상 프라이빗 게이트웨이(virtual private gateway)를 사용하며 두 개의 AWS Direct Connect 연결이 연결되어 있습니다. Management VPC와 Production VPC는 애플리케이션 간 통신을 허용하기 위해 단일 VPC 피어링 연결을 모두 사용합니다.

이 아키텍처에서 단일 장애 지점을 완화하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Management VPC와 Production VPC 사이에 VPN 세트를 추가합니다.
B. 두 번째 가상 프라이빗 게이트웨이를 추가하고 이를 Management VPC에 연결합니다.
C. 두 번째 고객 게이트웨이 장치에서 Management VPC로 두 번째 VPN 세트를 추가합니다.
D. Management VPC와 Production VPC 간에 두 번째 VPC 피어링 연결을 추가합니다.

```
A company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center. The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications.  
  
What should a solutions architect do to mitigate any single point of failure in this architecture?

- A. Add a set of VPNs between the Management and Production VPCs.
- B. Add a second virtual private gateway and attach it to the Management VPC.
- C. Add a second set of VPNs to the Management VPC from a second customer gateway device.
- D. Add a second VPC peering connection between the Management VPC and the Production VPC.
```

정답 : `C`

- 현재 Management VPC는 온프레미스의 단일 고객 게이트웨이 장치에 의존하고 있어 해당 장치가 단일 장애 지점(SPOF)
- 고객 게이트웨이 장치를 이중화해 서로 다른 온프리메스 장치에서 각각 VPN 연결(일반적으로 터널 2개씩)구성하면
	- 온프레미스 장치 장애나 회선 이슈 시에도 경로가 유지되어 가용성이 향상
- Production 쪽은 이미 이중 DX로 회선 중복이 있으므로, 부족한 구간은 온프레미스 측 장치의 이중화

오답 이유

- **A. Management-Production 간 VPN 추가**
    VPC 간 경로를 하나 더 만드는 것은 **온프레미스 장치의 SPOF를 해결하지 못함**. 문제의 핵심은 Management↔온프레미스 구간의 단일 장치 의존입니다.

- **B. Management VPC에 두 번째 VGW 추가**
    VPC는 **동시에 하나의 VGW만 연결 가능**합니다. 또한 SPOF는 **온프레미스 고객 게이트웨이 장치**이므로 VGW 추가로 해결되지 않습니다.

- **D. 두 번째 VPC 피어링 연결 추가**
    동일 VPC 쌍 간 **중복 피어링으로 가용성이 개선되지 않으며**(동일 경로), 문제의 SPOF(온프레미스 단일 장치)에도 영향이 없습니다. 게다가 일반적으로 동일 쌍에 **중복 피어링은 지원/의미가 없습니다**.


## #449
한 회사는 애플리케이션을 Oracle 데이터베이스에서 실행하고 있습니다. 회사는 데이터베이스 및 백업 관리, 데이터 센터 유지보수에 사용할 수 있는 리소스가 제한적이므로 AWS로 빠르게 마이그레이션할 계획입니다. 애플리케이션은 특권 액세스가 필요한 서드파티 데이터베이스 기능을 사용합니다.

가장 비용 효율적으로 데이터베이스를 AWS로 마이그레이션하는 데 도움이 되는 솔루션은 무엇입니까?

A. 데이터베이스를 Amazon RDS for Oracle로 마이그레이션합니다. 서드파티 기능을 클라우드 서비스로 대체합니다.
B. 데이터베이스를 Amazon RDS Custom for Oracle로 마이그레이션합니다. 서드파티 기능을 지원하도록 데이터베이스 설정을 사용자 지정합니다.
C. 데이터베이스를 Oracle용 Amazon EC2 Amazon Machine Image(AMI)로 마이그레이션합니다. 서드파티 기능을 지원하도록 데이터베이스 설정을 사용자 지정합니다.
D. 애플리케이션 코드를 다시 작성하여 Oracle APEX에 대한 종속성을 제거하고, 데이터베이스를 Amazon RDS for PostgreSQL로 마이그레이션합니다.

```
A company runs its application on an Oracle database. The company plans to quickly migrate to AWS because of limited resources for the database, backup administration, and data center maintenance. The application uses third-party database features that require privileged access.  
  
Which solution will help the company migrate the database to AWS MOST cost-effectively?

- A. Migrate the database to Amazon RDS for Oracle. Replace third-party features with cloud services.
- B. Migrate the database to Amazon RDS Custom for Oracle. Customize the database settings to support third-party features.
- C. Migrate the database to an Amazon EC2 Amazon Machine Image (AMI) for Oracle. Customize the database settings to support third-party features.
- D. Migrate the database to Amazon RDS for PostgreSQL by rewriting the application code to remove dependency on Oracle APEX.
```

정답 : `B`

- 요구사항: 특권 액세스가 필요한 서드파티 DB 기능을 유지하면서도, 운영(백업/패치/가용성) 부담을 줄이고 빠른 마이그레이션
- RDS Custom for Oracle은 표준 RDS가 제한하는 OS/DB 레벨의 특권 접근(SYSDBA, OS 수준, 에이전트 설치 등)을 허용하여, 서드파티 백업/모니터링/확장 기능을 그대로 사용 가능
- 동시에 스토리지 관리, 백업 스케줄링, 모니터링 등 RDS의 관리형 이점을 활용할 수 있어 
	- EC2 자가 운영 대비 운영 오버헤드와 비용을 절감하면서도, 재개발 없이 신속한 마이그레이션 가능

오답이유

- **A. RDS for Oracle + 서드파티 기능 대체**    
    표준 RDS for Oracle은 OS/DB 특권 접근이 제한되어 서드파티 에이전트/기능 사용이 어려울 수 있습니다. 또한 기능 대체를 위해 **재설계/재구성 비용**이 커져 “빠르고 비용 효율적인” 요구와 상충합니다.

- **C. EC2 AMI 위 자가 운영 Oracle**    
    특권 접근은 가능하지만 **백업·패치·HA 구성 등 모든 운영을 직접 관리**해야 합니다. 본문의 “리소스 제한”과 “빠른 마이그레이션/운영 부담 축소” 요구에 부적합합니다.

- **D. RDS for PostgreSQL로 전환(재개발)**
    **이기종 마이그레이션(Oracle → PostgreSQL)** 은 스키마/코드 변환, 기능 호환성 검토 등 **대규모 재작성**이 필요합니다. 빠르고 비용 효율적인 마이그레이션 요구에 맞지 않습니다.

## #450
한 회사에는 단일 서버에서 동작하는 3계층 웹 애플리케이션이 있습니다. 회사는 애플리케이션을 AWS 클라우드로 마이그레이션하고자 합니다. 또한 애플리케이션이 AWS Well-Architected Framework에 부합하고, 보안·확장성·복원성에 대한 AWS 권장 모범 사례와 일치하길 원합니다.

이 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (세 가지 선택)

A. 두 개의 가용 영역에 걸쳐 VPC를 생성하고 애플리케이션의 기존 아키텍처를 사용합니다. 각 가용 영역의 프라이빗 서브넷의 Amazon EC2 인스턴스에서 기존 아키텍처로 애플리케이션을 호스팅하고, EC2 Auto Scaling 그룹을 사용합니다. 보안 그룹과 네트워크 액세스 제어 목록(network ACL)으로 EC2 인스턴스를 보호합니다.
B. 데이터베이스 계층에 대한 액세스를 제어하기 위해 보안 그룹과 네트워크 액세스 제어 목록(network ACL)을 설정합니다. 프라이빗 서브넷에 단일 Amazon RDS 데이터베이스를 설정합니다.
C. 두 개의 가용 영역에 걸쳐 VPC를 생성합니다. 웹 계층, 애플리케이션 계층, 데이터베이스 계층으로 애플리케이션을 리팩터링합니다. 각 계층을 자체 프라이빗 서브넷에 호스팅하고, 웹 계층과 애플리케이션 계층에는 Auto Scaling 그룹을 사용합니다.
D. 단일 Amazon RDS 데이터베이스를 사용합니다. 데이터베이스 액세스는 애플리케이션 계층 보안 그룹에서만 허용합니다.
E. 웹 계층 앞에 Elastic Load Balancers를 사용합니다. 각 계층의 보안 그룹을 서로 참조하는 보안 그룹을 사용하여 액세스를 제어합니다.
F. 프라이빗 서브넷에 Amazon RDS 데이터베이스 Multi-AZ 클러스터 배포를 사용합니다. 데이터베이스 액세스는 애플리케이션 계층 보안 그룹에서만 허용합니다.

```
A company has a three-tier web application that is in a single server. The company wants to migrate the application to the AWS Cloud. The company also wants the application to align with the AWS Well-Architected Framework and to be consistent with AWS recommended best practices for security, scalability, and resiliency.  
  
Which combination of solutions will meet these requirements? (Choose three.)

- A. Create a VPC across two Availability Zones with the application's existing architecture. Host the application with existing architecture on an Amazon EC2 instance in a private subnet in each Availability Zone with EC2 Auto Scaling groups. Secure the EC2 instance with security groups and network access control lists (network ACLs).
- B. Set up security groups and network access control lists (network ACLs) to control access to the database layer. Set up a single Amazon RDS database in a private subnet.
- C. Create a VPC across two Availability Zones. Refactor the application to host the web tier, application tier, and database tier. Host each tier on its own private subnet with Auto Scaling groups for the web tier and application tier.
- D. Use a single Amazon RDS database. Allow database access only from the application tier security group.
- E. Use Elastic Load Balancers in front of the web tier. Control access by using security groups containing references to each layer's security groups.
- F. Use an Amazon RDS database Multi-AZ cluster deployment in private subnets. Allow database access only from application tier security groups.
```

정답 : `C, E, F`

- C: 단일 서버를 3계층(웹/앱/DB)으로 분리하고, 다중 AZ VPC에 배치하며, 웹･앱 계층에 오토스케일링을 적용해 탄력성과 복원성 확보
- E: ALB/NLB를 웹 계층 앞에 두어 가용성･확장성을 높이고, 보안 그룹 간 SG 참조로 계층 간 최소 권한 네트워킹 구현
- F: RDS Multi-AZ(클러스터형/고가용성 배포)를 프라이빗 서브넷에 두고, 접근을 앱 계층 SG로만 제한해 데이터 계층으 내구성･가용성･최소 권한 접근 달성

오답 이유

- **A**: “기존 아키텍처”를 그대로 유지하고 웹 앞단 공개 경로/로드밸런서 언급이 없으며, 웹·앱·DB **계층 분리**가 없음. 또한 웹을 프라이빗 서브넷에 두고 외부 접근 경로를 제시하지 않아 **모범 사례에 부합하지 않음**.
    
- **B**: DB를 **단일 RDS 인스턴스**로 두면 AZ 장애 시 가용성 저하. **Multi-AZ** 요구를 충족하지 못함.
    
- **D**: DB 접근 제어는 좋지만 **단일 RDS**로 가용성/복원성 미흡. 다중 AZ가 필요.


## #451
한 회사가 애플리케이션과 데이터베이스를 AWS 클라우드로 마이그레이션하고 있습니다.  
회사는 Amazon Elastic Container Service(Amazon ECS), AWS Direct Connect, Amazon RDS를 사용할 예정입니다.

회사의 운영팀이 관리해야 하는 활동은 무엇입니까? (세 가지 선택)

A. Amazon RDS 인프라 계층, 운영 체제 및 플랫폼 관리  
B. Amazon RDS DB 인스턴스를 생성하고 예약된 유지 관리 창을 구성  
C. 모니터링, 패치 관리, 로그 관리 및 호스트 침입 탐지를 위한 추가 소프트웨어 구성 요소를 Amazon ECS에 구성  
D. Amazon RDS의 모든 마이너 및 메이저 데이터베이스 버전에 대한 패치 설치  
E. 데이터 센터 내 Amazon RDS 인프라의 물리적 보안 보장  
F. Direct Connect를 통해 이동하는 데이터의 전송 중 암호화 수행

```
A company is migrating its applications and databases to the AWS Cloud. The company will use Amazon Elastic Container Service (Amazon ECS), AWS Direct Connect, and Amazon RDS.  
  
Which activities will be managed by the company's operational team? (Choose three.)

- A. Management of the Amazon RDS infrastructure layer, operating system, and platforms
- B. Creation of an Amazon RDS DB instance and configuring the scheduled maintenance window
- C. Configuration of additional software components on Amazon ECS for monitoring, patch management, log management, and host intrusion detection
- D. Installation of patches for all minor and major database versions for Amazon RDS
- E. Ensure the physical security of the Amazon RDS infrastructure in the data center
- F. Encryption of the data that moves in transit through Direct Connect
```

정답 : `B, C, F`

- AWS의 공유 책임 모델(Shared Responsibility Model)에 따르면
	- AWS는 인프라, 하이퍼바이저, 하드웨어, 물리적 보안, 기본 관리형 서비스의 플랫폼 계층을 관리
	- 고객(운영팀)은 데이터, 애플리케이션 구성, 접근 제어, 네트워크 트래픽 암호화, 컨테이너 구성, DB 인스턴스 생성 및 설정 등을 관리
- B: RDS는 관리형 서비스지만, 인스턴스 생성/삭제, 파라미터 그룹 설정, 유지관리 창 선택, 백업 정책 설정은 고객의 책임
- C: ECS에서 애플리케이션 컨테이너 및 OS 상의 추가 보안･모니터링 구성은 고객이 관리
- F: AWS Direct Connect는 암호화가 자동으로 제공되지 않으며, 고객이 VPN 또는 TLS 계층 암호화를 구성해야 함

오답 이유

- **A. RDS 인프라/OS/플랫폼 관리**
    → RDS는 완전관리형 서비스이므로 AWS가 이 계층(하드웨어, OS, RDS 플랫폼)을 관리합니다. 고객은 DB 엔진/데이터만 관리합니다.

- **D. RDS 버전 패치 설치**    
    → RDS는 **자동 패치 적용 옵션**을 제공하며, 마이너/메이저 패치의 설치와 유지보수는 AWS가 수행합니다(고객은 일정만 지정).

- **E. 물리적 보안 보장**
    → 물리적 데이터센터, 서버 하드웨어, 전원, 냉각 등은 **AWS 책임**입니다. 고객은 접근 제어(IAM 등)만 관리합니다.


## #452
한 회사는 Amazon EC2 인스턴스에서 Java 기반 잡을 실행합니다. 이 잡은 매시간 실행되며 실행에는 10초가 걸립니다. 잡은 예약된 간격으로 실행되며 1GB 메모리를 사용합니다. 인스턴스의 CPU 사용률은 잡이 사용 가능한 최대 CPU를 사용하는 짧은 급증 기간을 제외하고 낮습니다. 회사는 이 잡을 실행하는 비용을 최적화하고자 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. AWS App2Container(A2C)를 사용하여 잡을 컨테이너화합니다. AWS Fargate에서 0.5 vCPU와 1GB 메모리로 Amazon Elastic Container Service(Amazon ECS) 작업으로 잡을 실행합니다.
B. 코드를 1GB 메모리를 가진 AWS Lambda 함수로 복사합니다. Amazon EventBridge 예약 규칙을 생성하여 매시간 코드를 실행합니다.
C. AWS App2Container(A2C)를 사용하여 잡을 컨테이너화합니다. 기존 Amazon Machine Image(AMI)에 컨테이너를 설치합니다. 스케줄이 작업 완료 시 컨테이너를 중지하도록 합니다.
D. 기존 스케줄을 구성하여 잡 완료 시 EC2 인스턴스를 중지하고 다음 잡이 시작될 때 EC2 인스턴스를 다시 시작합니다.

```
A company runs a Java-based job on an Amazon EC2 instance. The job runs every hour and takes 10 seconds to run. The job runs on a scheduled interval and consumes 1 GB of memory. The CPU utilization of the instance is low except for short surges during which the job uses the maximum CPU available. The company wants to optimize the costs to run the job.  
  
Which solution will meet these requirements?

- A. Use AWS App2Container (A2C) to containerize the job. Run the job as an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate with 0.5 virtual CPU (vCPU) and 1 GB of memory.
- B. Copy the code into an AWS Lambda function that has 1 GB of memory. Create an Amazon EventBridge scheduled rule to run the code each hour.
- C. Use AWS App2Container (A2C) to containerize the job. Install the container in the existing Amazon Machine Image (AMI). Ensure that the schedule stops the container when the task finishes.
- D. Configure the existing schedule to stop the EC2 instance at the completion of the job and restart the EC2 instance when the next job starts.
```

정답 : `B`

- 실행 시간이 10초/시간당 1회로 매우 짧아 서버리스 이벤트 구동이 최적
- 람다는 호출 횟수 + 실행 시간(GB-초) 기준 과금으로, 유휴 시간 비용이 없음. EC2 또는 Fargate처럼 항상 런타임 자원을 유지할 필요가 없어 가장 저렴
- 람다는 메모리 크기에 비례해 CPU가 할당되어 짧은 시간 최대 CPU 사용에도 대응 가능하며, 1GB 메모리 요구사항 충족 가능
- 인프라 관리(패치/오토스케일/시작･중지) 제거, EventBridge 스케줄로 간단히 자동 실행

오답 이유

- **A. ECS on Fargate (0.5 vCPU/1GB)**
    짧은 주기성 배치에 동작은 가능하나 **태스크 시작/초기화 비용 및 런타임 비용**이 Lambda 대비 불리하고, 굳이 컨테이너화(A2C)까지 필요 없음.

- **C. 컨테이너를 AMI에 설치 후 스케줄 종료**
    여전히 **EC2 인스턴스 관리/유지 비용 및 운영 복잡도**가 존재. 서버 유지 자체가 비용 최적화에 불리.

- **D. EC2를 매시간 중지/시작**
    시작/중지 오버헤드와 실패 가능성이 있으며 **EBS 비용은 계속 발생**. 운영 복잡도도 증가. Lambda에 비해 비용·관리 모두 열세.


## #453
한 회사는 Amazon EC2 데이터와 여러 Amazon S3 버킷에 대한 백업 전략을 구현하려고 합니다. 규제 요건으로 인해 회사는 지정된 기간 동안 백업 파일을 보존해야 합니다. 보존 기간 동안 파일을 변경해서는 안 됩니다.

이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Backup을 사용하여 거버넌스 모드의 볼트 잠금(vault lock)이 있는 백업 볼트를 생성합니다. 필요한 백업 계획을 생성합니다.
B. Amazon Data Lifecycle Manager를 사용하여 필요한 자동 스냅샷 정책을 생성합니다.
C. Amazon S3 File Gateway를 사용하여 백업을 생성합니다. 적절한 S3 수명 주기 관리(S3 Lifecycle)를 구성합니다.
D. AWS Backup을 사용하여 컴플라이언스 모드의 볼트 잠금(vault lock)이 있는 백업 볼트를 생성합니다. 필요한 백업 계획을 생성합니다.

```
A company wants to implement a backup strategy for Amazon EC2 data and multiple Amazon S3 buckets. Because of regulatory requirements, the company must retain backup files for a specific time period. The company must not alter the files for the duration of the retention period.  
  
Which solution will meet these requirements?

- A. Use AWS Backup to create a backup vault that has a vault lock in governance mode. Create the required backup plan.
- B. Use Amazon Data Lifecycle Manager to create the required automated snapshot policy.
- C. Use Amazon S3 File Gateway to create the backup. Configure the appropriate S3 Lifecycle management.
- D. Use AWS Backup to create a backup vault that has a vault lock in compliance mode. Create the required backup plan.
```

정답 : `D`

- 회사는 EC2와 S3 버킷을 모두 대상으로 규제 수준의 보존과 불변성(보존 기간 동안 변경/삭제 불가) 요구
- AWS Backup Vault Lock의 컴플라이언스 모드는 보존 기간 동안 루트 관리자조차도 백업 복구 지점을 변경･삭제 불가능해 WORM(Write Once Read Many) 충족
- AWS Backup은 EC2, EBS, S3 등 여러 워크로드를 하나의 백업 계획/정책으로 관리할 수 있어 운영 오버헤드가 낮음

오답 이유

- **A. 거버넌스 모드**
    거버넌스 모드는 특정 권한(BypassGovernanceRetention)으로 **보존을 우회**할 수 있습니다. 강한 규제 요건의 **불변성 보장**에 미흡합니다.

- **B. Amazon DLM**
    주로 **EBS 스냅샷/AMI 수명 주기** 자동화용이며 **S3 백업을 포함하지 못하고**, WORM 수준의 불변성 강제 기능이 없습니다.

- **C. S3 File Gateway + Lifecycle**
    File Gateway는 파일 워크로드를 S3로 보관하는 용도이고, Lifecycle은 **만료/이전** 정책일 뿐 **변경/삭제 불가 보장(WORM)** 을 제공하지 않습니다. 또한 EC2 전체 백업 전략과 직결되지 않습니다.


## #454
한 회사는 여러 AWS 리전과 계정에 걸쳐 리소스를 보유하고 있습니다. 새로 입사한 솔루션스 아키텍트는 이전 직원이 리소스 인벤토리에 대한 상세 정보를 제공하지 않았다는 사실을 발견했습니다. 솔루션스 아키텍트는 모든 계정의 다양한 워크로드의 관계 상세 정보를 구축하고 매핑해야 합니다.

가장 운영 효율적인 방법으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Systems Manager Inventory를 사용하여 상세 보기 보고서에서 맵 뷰를 생성합니다.
B. AWS Step Functions를 사용하여 워크로드 세부 정보를 수집합니다. 워크로드의 아키텍처 다이어그램을 수동으로 작성합니다.
C. Workload Discovery on AWS를 사용하여 워크로드의 아키텍처 다이어그램을 생성합니다.
D. AWS X-Ray를 사용하여 워크로드 세부 정보를 확인합니다. 관계를 포함한 아키텍처 다이어그램을 작성합니다.

```
A company has resources across multiple AWS Regions and accounts. A newly hired solutions architect discovers a previous employee did not provide details about the resources inventory. The solutions architect needs to build and map the relationship details of the various workloads across all accounts.  
  
Which solution will meet these requirements in the MOST operationally efficient way?

- A. Use AWS Systems Manager Inventory to generate a map view from the detailed view report.
- B. Use AWS Step Functions to collect workload details. Build architecture diagrams of the workloads manually.
- C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.
- D. Use AWS X-Ray to view the workload details. Build architecture diagrams with relationships.
```

정답 : `C`

- Workload Discovery on AWS
	- 여러 계정/리전 전반의 리소스를 자동으로 수집하고 서비스 간 관계를 시각화한 아키텍처 다이어그램을 생성하는 관리형 솔루션
	- 클릭 몇 번으로 최신 상태의 토폴로지(리소스, 연결, 종속성)를 자동 갱신
	- 초기 인벤토리 파악과 지속적인 아키텍처 맵 유지에 운영 오버헤드가 최소

오답 이유

- **A. Systems Manager Inventory**
    주로 **관리형 인스턴스(EC2/온프레미스)** 의 소프트웨어/패치/구성 인벤토리를 수집하는 용도이며, **계정/리전 전체의 리소스 관계 맵/아키텍처 다이어그램을 자동 생성하지 않습니다.**

- **B. Step Functions + 수동 다이어그램**
    워크로드 세부 정보를 수집하는 **커스텀 파이프라인을 직접 구축**해야 하고, 다이어그램을 **수동 작성**해야 하므로 **운영 효율성 최저**입니다.

- **D. AWS X-Ray**
    애플리케이션 **분산 트레이싱** 및 요청 경로 분석 도구로, **인프라 인벤토리/관계 맵**을 전사 계정/리전 수준에서 제공하지 않습니다. 실행 트래픽이 없으면 정보도 제한적입니다.


## #455
한 회사는 AWS Organizations를 사용하고 있습니다. 회사는 일부 AWS 계정을 서로 다른 예산으로 운영하려고 합니다. 회사는 특정 기간 동안 할당된 예산 한도에 도달하면 경고를 받고, AWS 계정에서 추가 리소스 프로비저닝을 자동으로 방지하고자 합니다.

이 요구 사항을 충족하는 솔루션 조합은 무엇입니까? (세 가지 선택)

A. AWS Budgets를 사용하여 예산을 생성합니다. 필요한 AWS 계정의 비용 및 사용 보고서(Cost and Usage Reports) 섹션에서 예산 금액을 설정합니다.  
B. AWS Budgets를 사용하여 예산을 생성합니다. 필요한 AWS 계정의 결제 대시보드(Billing dashboards)에서 예산 금액을 설정합니다.  
C. 필요한 권한으로 예산 작업을 실행할 수 있는 IAM 사용자를 생성합니다.  
D. 필요한 권한으로 예산 작업을 실행할 수 있는 IAM 역할을 생성합니다.  
E. 각 계정이 예산 한도에 도달하면 회사를 알리는 알림을 추가합니다. 추가 리소스 프로비저닝을 방지하기 위해 적절한 config rule이 있는 IAM ID를 선택하여 예산 작업을 추가합니다.  
F. 각 계정이 예산 한도에 도달하면 회사를 알리는 알림을 추가합니다. 추가 리소스 프로비저닝을 방지하기 위해 적절한 서비스 제어 정책(SCP)이 있는 IAM ID를 선택하여 예산 작업을 추가합니다.

```
A company uses AWS Organizations. The company wants to operate some of its AWS accounts with different budgets. The company wants to receive alerts and automatically prevent provisioning of additional resources on AWS accounts when the allocated budget threshold is met during a specific period.  
  
Which combination of solutions will meet these requirements? (Choose three.)

- A. Use AWS Budgets to create a budget. Set the budget amount under the Cost and Usage Reports section of the required AWS accounts.
- B. Use AWS Budgets to create a budget. Set the budget amount under the Billing dashboards of the required AWS accounts.
- C. Create an IAM user for AWS Budgets to run budget actions with the required permissions.
- D. Create an IAM role for AWS Budgets to run budget actions with the required permissions.
- E. Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources.
- F. Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources.
```

정답 : `B, D, F`

- 요구사항: 예산 한도 도달 시 알림 + 자동 조치로 리소스 프로비저닝 차단(예산 초과 방지)
- B - AWS Budgets에서 예산 생성 (Billing Dashboard 사용)
	- 각 계정의 Billing 콘솔 내 AWS Budgets를 통해 예산 금액을 설정하고, 사용량 및 비용을 모니터링 가능
	- 예산은 Billing 대시보드에서 관리되며, 조직 멤버 계정 단위로도 설정 가능
- D - IAM 역할 생성(Budgets Action 실행용)
	- AWS Budgets에서 자동 조치를 실행하기 위해서는 Budgets Action을 수행할 IAM 역할을 지정해야 함
- F - 알림 + SCP 기반 예산 액션 설정
	- 예산이 한도에 도달하면 AWS Budgets Action을 트리거하여 SCP를 수정하거나 적용함으로써 새로운 계정에서 새로운 리소스 생성을 차단
	- SCP는 AWS Organizations 수준에서 리소스 생성 권한을 제한할 수 있는 가장 강력한 제어 수단

오답 이유

- **A. Cost and Usage Reports(CUR) 섹션에서 예산 설정**
    → CUR은 원시 사용량 데이터를 S3로 내보내는 기능이며, **예산 생성 위치가 아닙니다.**

- **C. IAM 사용자(User) 생성**
    → Budgets Action은 **IAM 사용자 자격 증명으로 실행되지 않으며**, 자동화 트리거용으로 **IAM 역할(Role)** 이 필요합니다.

- **E. Config rule 기반 조치**
    → AWS Config는 **리소스 구성 규정 준수(Compliance)** 평가용이며, **예산 초과 시 리소스 프로비저닝 차단과는 무관**합니다.


## #456
한 회사는 하나의 AWS 리전에서 Amazon EC2 인스턴스 위에 애플리케이션을 운영하고 있습니다. 회사는 EC2 인스턴스를 두 번째 리전에 백업하고자 합니다. 또한 두 번째 리전에서 EC2 리소스를 프로비저닝하고, 하나의 AWS 계정에서 EC2 인스턴스를 중앙에서 관리하고자 합니다.

가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 두 번째 리전에 유사한 수의 EC2 인스턴스를 갖는 재해 복구(DR) 계획을 생성합니다. 데이터 복제를 구성합니다.
B. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 시점(Point-in-time)으로 생성합니다. 스냅샷을 주기적으로 두 번째 리전으로 복사합니다.
C. AWS Backup을 사용하여 백업 계획을 생성합니다. EC2 인스턴스에 대해 두 번째 리전으로 교차 리전 백업을 구성합니다.
D. 두 번째 리전에 유사한 수의 EC2 인스턴스를 배포합니다. 소스 리전에서 두 번째 리전으로 데이터를 전송하기 위해 AWS DataSync를 사용합니다.

```
A company runs applications on Amazon EC2 instances in one AWS Region. The company wants to back up the EC2 instances to a second Region. The company also wants to provision EC2 resources in the second Region and manage the EC2 instances centrally from one AWS account.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region. Configure data replication.
- B. Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.
- C. Create a backup plan by using AWS Backup. Configure cross-Region backup to the second Region for the EC2 instances.
- D. Deploy a similar number of EC2 instances in the second Region. Use AWS DataSync to transfer the data from the source Region to the second Region.
```

정답 : `C`

- AWS Backup은 EC2(AMI/스냅샷 기반) 백업을 정책 중심으로 중앙 관리하고, 교차 리전 복사를 자동화
- 스케줄･수명주기･보존정책･태그 기반 선택을 한 곳에서 운영할 수 있어 다수 계정/리전의 리소스도 운영 오버헤드 없이 관리 가능
- 필요 시 두 번째 리전에 복구하여 EC2 리소스를 프로비저닝할 수 있으므로 비용 효율성과 요구사항 충족

오답 이유

- **A. 동일 규모의 DR 인스턴스 상시 운영**
    두 번째 리전에 유사 수량의 EC2를 상시 기동하면 **지속 인프라 비용이 매우 큼**. “백업” 목적 대비 과도한 비용(웜/핫 스탠바이).

- **B. 수동 EBS 스냅샷 생성 및 복사**
    가능한 접근이지만 **인스턴스/다중 볼륨/일정/보존/교차 리전 복사**를 스크립트로 직접 운영해야 하므로 **운영 오버헤드가 큼**. 또한 인스턴스 구성 복구(AMI 관리 등)도 수동 처리 필요.

- **D. 두 번째 리전에 동일 수량 배포 + DataSync 전송**
    DataSync는 파일/객체 마이그레이션에 적합하나 **EC2 백업/복구 체계가 아님**. 또한 두 번째 리전에 인스턴스를 미리 띄우는 것은 **비용 비효율적**.


## #457
AWS를 사용하는 한 회사가 제품 제조업체로 데이터를 전송하는 애플리케이션을 구축하고 있습니다. 회사는 자체 IdP(Identity Provider)를 보유하고 있습니다. 회사는 사용자가 애플리케이션을 사용해 데이터를 전송하는 동안 IdP가 애플리케이션 사용자를 인증하길 원합니다. 회사는 반드시 AS2(Applicability Statement 2) 프로토콜을 사용해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. AWS DataSync을 사용하여 데이터를 전송합니다. IdP 인증을 위해 AWS Lambda 함수를 생성합니다.
B. Amazon AppFlow 플로우를 사용하여 데이터를 전송합니다. IdP 인증을 위해 Amazon Elastic Container Service(Amazon ECS) 태스크를 생성합니다.
C. AWS Transfer Family를 사용하여 데이터를 전송합니다. IdP 인증을 위해 AWS Lambda 함수를 생성합니다.
D. AWS Storage Gateway를 사용하여 데이터를 전송합니다. IdP 인증을 위해 Amazon Cognito ID 풀을 생성합니다.

```
A company that uses AWS is building an application to transfer data to a product manufacturer. The company has its own identity provider (IdP). The company wants the IdP to authenticate application users while the users use the application to transfer data. The company must use Applicability Statement 2 (AS2) protocol.  
  
Which solution will meet these requirements?

- A. Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication.
- B. Use Amazon AppFlow flows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.
- C. Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.
- D. Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication.
```

정답 : `C`

- AS2 필수 요건을 충족하는 AWS 관리형 서비스는 AWS Transfer Family(AS2 지원)
- Transfer Family는 서버리스로 고가용성 및 운영 부담 최소화를 제공하며, 트레이딩 파트너/프로필, 인증서(서명/암호화), MDN 등 AS2에 필요한 요소를 네이티브로 지원
- Transfer Family는 사용자 인증/권한 부여를 위한 맞춤형 ID 제공자 연동(Authorizer Lambda)을 지원하므로, 회사의 자체 IdP와 Lambda를 통해 연동해 애플리케이션 사용자를 인증･인가 가능

오답 이유

- **A. DataSync**: 파일/오브젝트 전송·마이그레이션을 위한 서비스로 **AS2 프로토콜을 지원하지 않습니다**.
    
- **B. AppFlow**: SaaS 애플리케이션 간 데이터 통합 서비스로 **AS2 및 제조사로의 파일 교환** 요구에 부적합합니다.
    
- **D. Storage Gateway**: 온프레미스와 AWS 간 파일/볼륨/테이프 워크로드 연계 용도로, **AS2를 지원하지 않으며** Cognito ID 풀과의 조합도 요구사항(AS2+IdP 인증)과 맞지 않습니다.


## #458
한 솔루션스 아키텍트가 현금 캐시백 서비스를 위한 REST API를 Amazon API Gateway로 설계하고 있습니다. 애플리케이션의 계산 리소스에는 1GB 메모리와 2GB 스토리지가 필요합니다. 애플리케이션은 데이터가 관계형 형식이어야 합니다.

가장 적은 관리 노력으로 이러한 요구 사항을 충족하는 추가 AWS 서비스 조합은 무엇입니까? (두 가지 선택)

A. Amazon EC2
B. AWS Lambda
C. Amazon RDS
D. Amazon DynamoDB
E. Amazon Elastic Kubernetes Services (Amazon EKS)

```
A solutions architect is designing a RESTAPI in Amazon API Gateway for a cash payback service. The application requires 1 GB of memory and 2 GB of storage for its computation resources. The application will require that the data is in a relational format.  
  
Which additional combination ofAWS services will meet these requirements with the LEAST administrative effort? (Choose two.)

- A. Amazon EC2
- B. AWS Lambda
- C. Amazon RDS
- D. Amazon DynamoDB
- E. Amazon Elastic Kubernetes Services (Amazon EKS)
```

정답 : `B, C`

- Lambda는 API Gateway와 네이티브 통합되며, 함수 메모리를 1GB 이상으로 설정할 수 있고 임시 스토리지(/tmp)를 최대 10GB까지 확장할 수 있음
- RDS는 완전 관리형 관계형 데이터베이스로 백업･패치･복구･모니터링을 관리형으로 제공해 운영 부담 최소

오답 이유

- **A. Amazon EC2**: 유연하지만 OS 패치·확장·가용성 구성 등 **운영 부담이 큼**. “최소 관리 노력”과 상충.
    
- **D. Amazon DynamoDB**: **NoSQL 키-값/문서형**이므로 **관계형 데이터 요건**을 충족하지 못함.
    
- **E. Amazon EKS**: 강력하지만 **클러스터/노드/업그레이드** 등 관리 복잡도가 높아 본 요구의 **최소 운영** 기준에 부적합.


## #459
한 회사는 AWS Organizations를 사용하여 여러 AWS 계정에서 워크로드를 운영합니다. 태깅 정책은 회사가 태그를 생성할 때 AWS 리소스에 부서(department) 태그를 추가합니다.

회계 팀은 Amazon EC2 사용 비용 지출을 파악해야 합니다. 회계 팀은 AWS 계정과 관계없이 어떤 부서가 비용에 책임이 있는지 결정해야 합니다. 회계 팀은 조직 내 모든 AWS 계정에 대해 AWS Cost Explorer에 접근할 수 있으며, Cost Explorer의 모든 보고서에 접근해야 합니다.

가장 운영 효율적인 방식으로 이러한 요구를 충족하는 솔루션은 무엇입니까?

A. Organizations 관리 계정의 결제 콘솔에서 department라는 사용자 정의 비용 할당 태그를 활성화합니다. Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링한 하나의 비용 보고서를 생성합니다.
B. Organizations 관리 계정의 결제 콘솔에서 department라는 AWS 정의 비용 할당 태그를 활성화합니다. Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링한 하나의 비용 보고서를 생성합니다.
C. Organizations 멤버 계정의 결제 콘솔에서 department라는 사용자 정의 비용 할당 태그를 활성화합니다. Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링한 하나의 비용 보고서를 생성합니다.
D. Organizations 멤버 계정의 결제 콘솔에서 department라는 AWS 정의 비용 할당 태그를 활성화합니다. Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링한 하나의 비용 보고서를 생성합니다.

```
A company uses AWS Organizations to run workloads within multiple AWS accounts. A tagging policy adds department tags to AWS resources when the company creates tags.  
  
An accounting team needs to determine spending on Amazon EC2 consumption. The accounting team must determine which departments are responsible for the costs regardless ofAWS account. The accounting team has access to AWS Cost Explorer for all AWS accounts within the organization and needs to access all reports from Cost Explorer.  
  
Which solution meets these requirements in the MOST operationally efficient way?

- A. From the Organizations management account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.
- B. From the Organizations management account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.
- C. From the Organizations member account billing console, activate a user-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by the tag name, and filter by EC2.
- D. From the Organizations member account billing console, activate an AWS-defined cost allocation tag named department. Create one cost report in Cost Explorer grouping by tag name, and filter by EC2.
```

정답 : `A`

- department는 회사가 정의･적용한 사용자 정의 태그로 비용 집계에 쓰려면 비용 할당 태그로 관리 계정에서 활성화해야 전체 통합 청구 범위에 반영
- 그 후 Cost Explorer에서 Service=EC2로 필터링하고 Tag=department로 그룹화하면 모든 계정/리전에 대해 부서별 EC2 비용을 한 보고서로 확인 가능해 운영 오버헤드 최소화

오답 이유

- **B. AWS 정의 태그 활성화**: department는 AWS가 자동 생성하는 태그가 아니라 **사용자 정의 태그**이므로 해당 없음.
    
- **C/D. 멤버 계정에서 활성화**: 비용 할당 태그는 **관리(결제) 계정**에서 활성화해야 **조직 전체 비용**에 반영됩니다. 멤버 계정에서 해도 통합 보고에 충분치 않음.


## #460
한 회사가 자사 소프트웨어형 서비스(SaaS) 애플리케이션인 Salesforce 계정과 Amazon S3 간에 데이터를 안전하게 교환하려고 합니다. 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 키(CMK)를 사용하여 데이터를 저장 시 암호화해야 합니다. 또한 전송 중에도 데이터를 암호화해야 합니다. 회사는 Salesforce 계정에서 API 접근을 활성화했습니다.

A. AWS Lambda 함수를 생성하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.  
B. AWS Step Functions 워크플로를 생성합니다. 작업(Task)을 정의하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.  
C. Amazon AppFlow 플로우를 생성하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.  
D. Salesforce용 사용자 지정 커넥터를 생성하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.

```
A company wants to securely exchange data between its software as a service (SaaS) application Salesforce account and Amazon S3. The company must encrypt the data at rest by using AWS Key Management Service (AWS KMS) customer managed keys (CMKs). The company must also encrypt the data in transit. The company has enabled API access for the Salesforce account.

- A. Create AWS Lambda functions to transfer the data securely from Salesforce to Amazon S3.
- B. Create an AWS Step Functions workflow. Define the task to transfer the data securely from Salesforce to Amazon S3.
- C. Create Amazon AppFlow flows to transfer the data securely from Salesforce to Amazon S3.
- D. Create a custom connector for Salesforce to transfer the data securely from Salesforce to Amazon S3.
```

정답 : `C`

- Amazon AppFlow는 SaaS 애플리케이션과 AWS 간의 데이터 교환을 안전하게 자동화하는 완전관리형 서비스
- Salesforce API 통합을 기본 제공하며, 데이터를 전송 중 암호화(TLS 1.2) 와 저장 시 암호화(KMS CMK)로 보호
- 사용자는 Salesforce → S3 흐름을 생성하고 S3 암호화 키(KMS CMK)를 지정

오답 이유

- **A. AWS Lambda**
    직접 API 호출·데이터 이동 로직을 작성해야 하며, **KMS 암호화/인증 로직 관리**를 수동으로 처리해야 함. 관리 오버헤드와 코드 유지 부담이 큼.

- **B. AWS Step Functions**
    자체적으로 데이터 이동을 수행하지 않으며, Lambda 등 다른 서비스를 호출해야 함. **데이터 전송 및 암호화 처리의 본질적 기능 없음.**

- **D. Salesforce 사용자 지정 커넥터**
    Salesforce 자체 개발 및 관리 필요. AppFlow가 이미 Salesforce용 **표준 커넥터를 네이티브로 지원**하므로, 커스텀 커넥터는 불필요하고 **운영 비용과 복잡도 증가**.