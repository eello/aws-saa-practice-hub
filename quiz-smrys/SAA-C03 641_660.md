---
created: 2025-10-18 12:14:15
last_modified: 2025-10-18 17:26:00
---
## #641
한 회사가 재무 검토를 위해 AWS 비용을 모니터링하려고 합니다. 클라우드 운영 팀은 AWS Organizations 관리 계정에서 모든 멤버 계정에 대한 AWS Cost and Usage Reports(CUR)를 쿼리하기 위한 아키텍처를 설계하고 있습니다. 팀은 이 쿼리를 한 달에 한 번 실행하고 청구서에 대한 상세 분석을 제공해야 합니다.

다음 중 이러한 요구 사항을 충족하는 가장 확장 가능하고 비용 효율적인 방법은 무엇입니까?

A. 관리 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon Kinesis로 전달합니다. 분석을 위해 Amazon EMR을 사용합니다.
B. 관리 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon S3로 전달합니다. 분석을 위해 Amazon Athena를 사용합니다.
C. 멤버 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon S3로 전달합니다. 분석을 위해 Amazon Redshift를 사용합니다.
D. 멤버 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon Kinesis로 전달합니다. 분석을 위해 Amazon QuickSight를 사용합니다.

```
A company wants to monitor its AWS costs for financial review. The cloud operations team is designing an architecture in the AWS Organizations management account to query AWS Cost and Usage Reports for all member accounts. The team must run this query once a month and provide a detailed analysis of the bill.  
  
Which solution is the MOST scalable and cost-effective way to meet these requirements?

- A. Enable Cost and Usage Reports in the management account. Deliver reports to Amazon Kinesis. Use Amazon EMR for analysis.
- B. Enable Cost and Usage Reports in the management account. Deliver the reports to Amazon S3 Use Amazon Athena for analysis.
- C. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon S3 Use Amazon Redshift for analysis.
- D. Enable Cost and Usage Reports for member accounts. Deliver the reports to Amazon Kinesis. Use Amazon QuickSight tor analysis.
```

정답 : `B`

- 관리(결제) 계정에서 CUR을 S3로 전달하고 Athena로 서버리스 SQL 조회를 하면, 조직 전체 비용 데이터를 중앙에서 확장 가능하게 분석 가능
- 월 1회 실행에도 사용한 만큼만 과금되어 비용 효율적
- Athena는 CUR 스키마(파티셔닝/압축)와도 잘 맞아 설정이 간단

오답 이유

- A. CUR는 Kinesis로 전달되지 않습니다. 또한 EMR은 운영/비용 오버헤드가 커 월 1회 분석 용도에 과도합니다.

- C. 조직 환경에서는 관리(결제) 계정에서 중앙 CUR를 수집하는 것이 일반적입니다. 각 멤버 계정별로 CUR를 만들면 중복/운영 부담이 증가하고 Redshift는 상시 클러스터 비용이 발생합니다.

- D. CUR를 Kinesis로 전달할 수 없습니다. QuickSight는 시각화 도구이지 CUR 원천 처리를 대체하지 않으며, 데이터 준비/쿼리는 여전히 다른 계층이 필요합니다.


## #642
한 회사가 AWS 클라우드에서 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스에서 게임 애플리케이션을 실행하려고 합니다.  
이 애플리케이션은 UDP 패킷을 사용하여 데이터를 전송합니다.  
회사는 트래픽이 증가하거나 감소함에 따라 애플리케이션이 자동으로 확장(Scale out) 및 축소(Scale in)되도록 보장하고 싶습니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Network Load Balancer를 Auto Scaling 그룹에 연결합니다.  
B. Application Load Balancer를 Auto Scaling 그룹에 연결합니다.  
C. Amazon Route 53의 가중치(Weighted) 라우팅 정책이 있는 레코드 세트를 배포하여 트래픽을 적절히 라우팅합니다.  
D. Auto Scaling 그룹의 EC2 인스턴스에 포트 포워딩이 구성된 NAT 인스턴스를 배포합니다.

```
A company wants to run a gaming application on Amazon EC2 instances that are part of an Auto Scaling group in the AWS Cloud. The application will transmit data by using UDP packets. The company wants to ensure that the application can scale out and in as traffic increases and decreases.  
  
What should a solutions architect do to meet these requirements?

- A. Attach a Network Load Balancer to the Auto Scaling group.
- B. Attach an Application Load Balancer to the Auto Scaling group.
- C. Deploy an Amazon Route 53 record set with a weighted policy to route traffic appropriately.
- D. Deploy a NAT instance that is configured with port forwarding to the EC2 instances in the Auto Scaling group.
```

정답 : `A`

- 게임 애플리케이션은 UDP 트래픽을 사용하므로 L4 로드 밸런서인 NLB가 필요
- NLB는 TCP 및 UDP 프로토콜을 모두 지원하며, 오토 스케일링 그룹과 통합되어 인스턴스의 추가/제거 시 자동으로 트래픽을 조정

오답 이유

- B. Application Load Balancer(ALB)는 7계층(HTTP/HTTPS) 트래픽만 지원하며, UDP 프로토콜은 지원하지 않습니다.

- C. Route 53의 가중치 라우팅은 단순 DNS 수준의 트래픽 분산으로, 인스턴스 상태 모니터링이나 동적 확장(Auto Scaling)과 연동되지 않습니다.

- D. NAT 인스턴스는 사설 서브넷의 아웃바운드 인터넷 트래픽을 위한 것이며, 인바운드 UDP 요청 분산에는 적합하지 않습니다.


## #643
한 회사가 각기 다른 브랜드용 웹사이트를 AWS에서 운영하고 있습니다. 각 웹사이트는 매일 수십 GB의 웹 트래픽 로그를 생성합니다. 솔루션스 아키텍트는 회사의 개발자들이 모든 웹사이트의 트래픽 패턴을 분석할 수 있도록 확장 가능한 솔루션을 설계해야 합니다. 이 분석은 수개월에 걸쳐 주 1회 필요 시(on demand) 수행될 예정입니다. 솔루션은 표준 SQL을 사용한 쿼리를 지원해야 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 로그를 Amazon S3에 저장합니다. 분석에는 Amazon Athena를 사용합니다.
B. 로그를 Amazon RDS에 저장합니다. 분석에는 데이터베이스 클라이언트를 사용합니다.
C. 로그를 Amazon OpenSearch Service에 저장합니다. 분석에는 OpenSearch Service를 사용합니다.
D. 로그를 Amazon EMR 클러스터에 저장합니다. SQL 기반 분석을 위해 지원되는 오픈 소스 프레임워크를 사용합니다.

```
A company runs several websites on AWS for its different brands. Each website generates tens of gigabytes of web traffic logs each day. A solutions architect needs to design a scalable solution to give the company's developers the ability to analyze traffic patterns across all the company's websites. This analysis by the developers will occur on demand once a week over the course of several months. The solution must support queries with standard SQL.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Store the logs in Amazon S3. Use Amazon Athena tor analysis.
- B. Store the logs in Amazon RDS. Use a database client for analysis.
- C. Store the logs in Amazon OpenSearch Service. Use OpenSearch Service for analysis.
- D. Store the logs in an Amazon EMR cluster Use a supported open-source framework for SQL-based analysis.
```

정답 : `A`

- 로그를 Amazon S3에 적재하고 Amazon Athena로 쿼리하면 서버리스 표준 SQL 분석이 가능
- 주 1회 온디맨드 실행 시 쿼리한 데이터 스캔량만큼 과금되어 가장 비용 효율적

오답 이유

- B. RDS는 대용량 로그 적재/스케일에 비경제적이며 스토리지·IO·컴퓨트 비용과 운영 부담이 큽니다.

- C. OpenSearch는 검색/분석엔 강점이나 표준 SQL 기반 일반형 쿼리에 최적은 아니며(전용 SQL 플러그인은 한계), 지속 프로비저닝 비용이 발생합니다.

- D. EMR은 강력하지만 클러스터 관리·튜닝이 필요하고 상시 혹은 주기적 클러스터 비용이 들어 주 1회 분석에는 과합니다.


## #644
한 국제 기업은 회사가 운영하는 각 국가마다 서브도메인을 보유하고 있습니다. 서브도메인 형식은 example.com, country1.example.com, country2.example.com 입니다. 회사의 워크로드는 Application Load Balancer 뒤에 있습니다. 회사는 전송 중인 웹사이트 데이터를 암호화하고자 합니다.

다음 중 이러한 요구 사항을 충족하는 단계의 조합은 무엇입니까? (두 가지 선택)

A. AWS Certificate Manager(ACM) 콘솔을 사용하여 최상위 도메인(example.com)에 대한 공개 인증서와 \*.example.com에 대한 와일드카드 인증서를 요청합니다.
B. AWS Certificate Manager(ACM) 콘솔을 사용하여 최상위 도메인(example.com)에 대한 사설 인증서와 \*.example.com에 대한 와일드카드 인증서를 요청합니다.
C. AWS Certificate Manager(ACM) 콘솔을 사용하여 최상위 도메인(example.com)에 대한 공개 인증서와 사설 인증서를 요청합니다.
D. 이메일 주소로 도메인 소유권을 검증합니다. DNS 제공자에 필요한 DNS 레코드를 추가하여 DNS 검증으로 전환합니다.
E. DNS 제공자에 필요한 DNS 레코드를 추가하여 도메인 소유권을 검증합니다.

```
An international company has a subdomain for each country that the company operates in. The subdomains are formatted as example.com, country1.example.com, and country2.example.com. The company's workloads are behind an Application Load Balancer. The company wants to encrypt the website data that is in transit.  
  
Which combination of steps will meet these requirements? (Choose two.)

- A. Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example com and a wildcard certificate for \*.example.com.
- B. Use the AWS Certificate Manager (ACM) console to request a private certificate for the apex top domain example.com and a wildcard certificate for \*.example.com.
- C. Use the AWS Certificate Manager (ACM) console to request a public and private certificate for the apex top domain example.com.
- D. Validate domain ownership by email address. Switch to DNS validation by adding the required DNS records to the DNS provider.
- E. Validate domain ownership for the domain by adding the required DNS records to the DNS provider.
```

정답 : `A, E`

- 공용 웹사이트를 HTTPS로 보호하려면 공개(퍼블릭) ACM 인증서 필요
- apex 도메인(example.com) + 와일드카드(\*.example.com) 조합으로 루트와 모든 국가별 서브도메인을 한 번에 커버 가능
- 도메인 검증은 자동 갱신에 유리한 DNS 검증(선택지 E)이 가장 실무적

오답 이유

- B. 사설 인증서(Private CA)는 내부 전용(사내 PKI) 시나리오에 사용합니다. 인터넷 공개 사이트의 ALB/TLS에는 퍼블릭 인증서가 필요합니다.

- C. apex에 대한 퍼블릭+프라이빗 인증서를 둘 다 받을 이유가 없고, 서브도메인들(\*.example.com)을 커버하지 못합니다.

- D. 이메일 검증 후 DNS로 전환하는 절차는 불필요하게 복잡합니다. 처음부터 DNS 검증(E)으로 진행하는 것이 자동 갱신과 운영에 유리합니다.


## #645
회사는 온프레미스 키 매니저에서 암호화 키를 사용해야 합니다. 규정 및 컴플라이언스 요구사항 때문에 키 매니저는 AWS 클라우드 외부에 있습니다. 회사는 AWS 클라우드 외부에 보관되는 암호화 키를 사용하여 암호화 및 복호화를 관리하고, 서로 다른 벤더의 다양한 외부 키 매니저를 지원하길 원합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. CloudHSM 클러스터를 기반으로 하는 AWS CloudHSM 키 스토어를 사용합니다.
B. 외부 키 매니저를 기반으로 하는 AWS Key Management Service(AWS KMS) External Key Store를 사용합니다.
C. 기본 AWS Key Management Service(AWS KMS) 관리형 키 스토어를 사용합니다.
D. AWS CloudHSM 클러스터를 기반으로 하는 커스텀 키 스토어를 사용합니다.

```
A company is required to use cryptographic keys in its on-premises key manager. The key manager is outside of the AWS Cloud because of regulatory and compliance requirements. The company wants to manage encryption and decryption by using cryptographic keys that are retained outside of the AWS Cloud and that support a variety of external key managers from different vendors.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS CloudHSM key store backed by a CloudHSM cluster.
- B. Use an AWS Key Management Service (AWS KMS) external key store backed by an external key manager.
- C. Use the default AWS Key Management Service (AWS KMS) managed key store.
- D. Use a custom key store backed by an AWS CloudHSM cluster.
```

정답 : `B`

- AWS KMS External Key Store(XKS)는 키를 AWS 외부(온프레미스 또는 서드파티)에 보관하면서 KMS API를 통해 암･복호화를 수행
- 여러 벤더의 외부 키 매니저를 지원하도록 설계되어 규제 준수와 운영 단순성을 동시에 충족

오답 이유

- A. CloudHSM 키 스토어는 키가 AWS CloudHSM 클러스터(클라우드 내부)에 상주합니다. "클라우드 외부 보관" 요구에 부합하지 않습니다.

- C. KMS 기본 관리형 키 스토어는 키가 AWS에서 관리·보관됩니다. 외부 보관 및 타사 키 매니저 연계 요구를 충족하지 못합니다.

- D. KMS 커스텀 키 스토어(CloudHSM 기반) 역시 키가 AWS CloudHSM(클라우드 내부)에 존재하므로 규정상 외부 보관 요구를 충족하지 못합니다.


## #646
솔루션스 아키텍트는 AWS 클라우드에서 고성능 컴퓨팅(HPC) 워크로드를 호스팅해야 합니다. 이 워크로드는 수백 개의 Amazon EC2 인스턴스에서 실행되며, 대용량 데이터세트의 분산 처리를 가능하게 하기 위해 공유 파일 시스템에 대한 병렬 액세스가 필요합니다. 데이터세트는 여러 인스턴스에서 동시에 액세스됩니다. 워크로드는 1ms 이내의 액세스 지연 시간을 요구합니다. 처리가 완료된 후 엔지니어는 수동 후처리를 위해 데이터세트에 대한 액세스가 필요합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 공유 파일 시스템으로 Amazon Elastic File System(Amazon EFS)을 사용합니다. Amazon EFS에서 데이터세트에 액세스합니다.
B. 공유 파일 시스템으로 사용하기 위해 Amazon S3 버킷을 마운트합니다. S3 버킷에서 직접 후처리를 수행합니다.
C. 공유 파일 시스템으로 Amazon FSx for Lustre를 사용합니다. 후처리를 위해 파일 시스템을 Amazon S3 버킷과 연결합니다.
D. AWS Resource Access Manager를 구성하여 Amazon S3 버킷을 공유하도록 하여 모든 인스턴스에 마운트해 처리와 후처리를 수행할 수 있게 합니다.

```
A solutions architect needs to host a high performance computing (HPC) workload in the AWS Cloud. The workload will run on hundreds of Amazon EC2 instances and will require parallel access to a shared file system to enable distributed processing of large datasets. Datasets will be accessed across multiple instances simultaneously. The workload requires access latency within 1 ms. After processing has completed, engineers will need access to the dataset for manual postprocessing.  
  
Which solution will meet these requirements?

- A. Use Amazon Elastic File System (Amazon EFS) as a shared file system. Access the dataset from Amazon EFS.
- B. Mount an Amazon S3 bucket to serve as the shared file system. Perform postprocessing directly from the S3 bucket.
- C. Use Amazon FSx for Lustre as a shared file system. Link the file system to an Amazon S3 bucket for postprocessing.
- D. Configure AWS Resource Access Manager to share an Amazon S3 bucket so that it can be mounted to all instances for processing and postprocessing.
```

정답 : `C`

- HPC 워크로드에서 수백 노드의 병렬 I/O와 서브밀리초(~1ms) 지연을 요구할 때는 FSx for Lustre가 최적
- Lustre는 대규모 병렬 파일 시스템으로 높은 처리량과 낮은 지연을 제공
- S3와의 네이티브 연동(import/export)으로 입력 데이터 세트를 S3에서 손쉽게 가져오고 처리 결과를 S3로 내보내 후처리에 활용 가능

오답 이유

- A. EFS는 표준 NFS 기반의 범용 공유 파일 시스템으로 관리성은 좋지만, HPC에서 요구하는 초저지연/고처리량(대규모 병렬 I/O)에는 Lustre 대비 성능이 부족합니다.

- B. S3는 객체 스토리지이며 인스턴스에 '마운트'하는 정식 파일 시스템이 아닙니다. FUSE 기반 도구로 유사 마운트는 가능하나 성능/일관성/지원 측면에서 HPC 요구(1ms 지연, 병렬 POSIX I/O)를 충족하지 못합니다.

- D. AWS RAM은 리소스 공유 서비스일 뿐, S3를 파일 시스템처럼 '마운트'하게 해주지 않습니다. 또한 S3는 POSIX 파일 시스템이 아니므로 HPC 병렬 I/O에 부적합합니다.


## #647
한 게임 회사가 VoIP(Voice over IP) 기능이 있는 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 전 세계 사용자에게 트래픽을 제공할 것입니다. 애플리케이션은 높은 가용성과 AWS 리전 간 자동 장애 조치가 필요합니다. 회사는 사용자 단말의 IP 주소 캐싱에 의존하지 않으면서 지연 시간을 최소화하고자 합니다.

이 요구사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 상태 검사가 포함된 AWS Global Accelerator를 사용합니다.
B. 지리적 위치 라우팅 정책이 있는 Amazon Route 53을 사용합니다.
C. 여러 오리진을 포함하는 Amazon CloudFront 배포를 생성합니다.
D. 경로 기반 라우팅을 사용하는 Application Load Balancer를 생성합니다.

```
A gaming company is building an application with Voice over IP capabilities. The application will serve traffic to users across the world. The application needs to be highly available with an automated failover across AWS Regions. The company wants to minimize the latency of users without relying on IP address caching on user devices.  
  
What should a solutions architect do to meet these requirements?

- A. Use AWS Global Accelerator with health checks.
- B. Use Amazon Route 53 with a geolocation routing policy.
- C. Create an Amazon CloudFront distribution that includes multiple origins.
- D. Create an Application Load Balancer that uses path-based routing.
```

정답 : `A`

- Global Accelerator는 전 세계 엣지 로케이션의 Anycast 정적 IP를 통해 가장 가까운 엔드포인트(리전)로 트래픽을 라우팅
	- 헬스 체크 기반으로 리전 간 자동 장애 조치를 제공
- DNS 캐싱에 의존하지 않으므로 IP 캐싱 문제 없이 저지연 접속이 가능하며, TCP/UDP(VoIP 포함) 트래픽에 적합)

오답 이유

- B. Route 53 지리 라우팅은 DNS 기반으로 동작하여 클라이언트/리졸버의 캐싱(TTL)에 영향을 받습니다. 장애 시 빠른 전환 보장이 어렵고 “IP 캐싱에 의존하지 않음” 요구와 불일치합니다.

- C. CloudFront는 주로 HTTP/HTTPS 콘텐츠 전송/캐싱에 적합하며, VoIP와 같은 실시간 UDP 워크로드에는 적합하지 않습니다. 리전 간 액티브-액티브/장애 조치도 목적에 부합하지 않습니다.

- D. ALB는 리전 내 L7 HTTP/HTTPS 로드 밸런싱에 초점이 있으며, 글로벌 라우팅이나 리전 간 자동 장애 조치를 제공하지 않습니다. 또한 UDP를 지원하지 않습니다.


## #648
한 기상 예측 회사가 서브밀리초(sub-millisecond) 지연으로 수백 기가바이트의 데이터를 처리해야 합니다. 이 회사는 데이터 센터에 고성능 컴퓨팅(HPC) 환경을 보유하고 있으며, 예측 역량을 확장하고자 합니다.

솔루션스 아키텍트는 대량의 지속적인 처리량을 감당할 수 있고 고가용성을 제공하는 클라우드 스토리지 솔루션을 식별해야 합니다. 솔루션에 저장된 파일은 전체 데이터 세트를 동시에 액세스하고 처리할 수 있는 수천 개의 컴퓨팅 인스턴스에서 접근 가능해야 합니다.

이 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Amazon FSx for Lustre 스크래치(scratch) 파일 시스템을 사용합니다.
B. Amazon FSx for Lustre 퍼시스턴트(persistent) 파일 시스템을 사용합니다.
C. Bursting Throughput 모드의 Amazon Elastic File System(Amazon EFS)을 사용합니다.
D. Provisioned Throughput 모드의 Amazon Elastic File System(Amazon EFS)을 사용합니다.

```
A weather forecasting company needs to process hundreds of gigabytes of data with sub-millisecond latency. The company has a high performance computing (HPC) environment in its data center and wants to expand its forecasting capabilities.  
  
A solutions architect must identify a highly available cloud storage solution that can handle large amounts of sustained throughput. Files that are stored in the solution should be accessible to thousands of compute instances that will simultaneously access and process the entire dataset.  
  
What should the solutions architect do to meet these requirements?

- A. Use Amazon FSx for Lustre scratch file systems.
- B. Use Amazon FSx for Lustre persistent file systems.
- C. Use Amazon Elastic File System (Amazon EFS) with Bursting Throughput mode.
- D. Use Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode.
```

정답 : `B`

- FSx for Lustre는 HPC 워크로드에 맞춘 서브밀리초 지연과 대규모 병렬 처리량을 제공
- 퍼시스턴트 유형은 데이터 복제 및 장애 조치가 포함되어 고가용성 요구를 충족
- 수천 노드가 동시에 전체 데이터셋을 읽고/쓰는 패턴에 적합

오답 이유

- A. 스크래치(scratch) 유형은 일시적·실험적 워크로드에 적합하며, 장치 장애 시 데이터가 보존되지 않습니다. “고가용성” 요구에 부합하지 않습니다.

- C. EFS는 관리 편의성은 높지만 NFS 기반으로 지연이 밀리초 단위이며, HPC 수준의 대규모 병렬 I/O·초저지연 요구에 부족합니다.

- D. EFS Provisioned Throughput으로 처리량을 올릴 수는 있으나 지연 특성(밀리초)과 HPC 병렬 파일 시스템 최적화 측면에서 Lustre에 미치지 못합니다.


## #649
한 전자상거래 회사가 온프레미스에서 PostgreSQL 데이터베이스를 운영하고 있습니다. 이 데이터베이스는 고 IOPS Amazon Elastic Block Store(Amazon EBS) 블록 스토리지를 사용하여 데이터를 저장합니다. 일일 피크 I/O 초당 트랜잭션(IOPS)은 15,000 IOPS를 넘지 않습니다. 회사는 데이터베이스를 Amazon RDS for PostgreSQL로 마이그레이션하고, 디스크 스토리지 용량과 독립적으로 디스크 IOPS 성능을 프로비저닝하길 원합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 범용 SSD(gp2) EBS 볼륨 스토리지 타입을 구성하고 15,000 IOPS를 프로비저닝합니다.
B. 프로비저닝된 IOPS SSD(io1) EBS 볼륨 스토리지 타입을 구성하고 15,000 IOPS를 프로비저닝합니다.
C. 범용 SSD(gp3) EBS 볼륨 스토리지 타입을 구성하고 15,000 IOPS를 프로비저닝합니다.
D. 최대 IOPS 달성을 위해 EBS 마그네틱 볼륨 타입을 구성합니다.

```
An ecommerce company runs a PostgreSQL database on premises. The database stores data by using high IOPS Amazon Elastic Block Store (Amazon EBS) block storage. The daily peak I/O transactions per second do not exceed 15,000 IOPS. The company wants to migrate the database to Amazon RDS for PostgreSQL and provision disk IOPS performance independent of disk storage capacity.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Configure the General Purpose SSD (gp2) EBS volume storage type and provision 15,000 IOPS.
- B. Configure the Provisioned IOPS SSD (io1) EBS volume storage type and provision 15,000 IOPS.
- C. Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS.
- D. Configure the EBS magnetic volume type to achieve maximum IOPS.
```

정답 : `C`

- gp3는 용량과 독립적으로 IOPS/처리량을 프로비저닝할 수 있으며(최대 16,000 IOPS, 최대 1,000MB/s), 가격도 io1 대비 현저히 저렴
- 피크 15,000 IOPS 요구를 충족하면서 가장 비용 효율적

오답 이유

- A. gp2는 IOPS가 용량에 비례(기본 3 IOPS/GB)하므로 “용량과 독립적인 IOPS 프로비저닝” 요구를 충족하지 못합니다.

- B. io1은 IOPS를 독립적으로 프로비저닝할 수 있으나 gp3보다 비용이 높습니다. 동일 요구(15K IOPS)에 대해 비용 효율성이 떨어집니다.
  
- D. 마그네틱은 레거시/저성능 스토리지로 고 IOPS 워크로드에 적합하지 않습니다.


## #650
한 회사가 온프레미스 Microsoft SQL Server Enterprise 에디션 데이터베이스를 AWS로 마이그레이션하려고 합니다. 회사의 온라인 애플리케이션은 이 데이터베이스를 사용해 트랜잭션을 처리합니다. 데이터 분석 팀은 동일한 프로덕션 데이터베이스를 사용해 분석 처리용 보고서를 실행합니다. 회사는 가능한 한 관리형 서비스를 사용해 운영 오버헤드를 줄이고자 합니다.

다음 중 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon RDS for Microsoft SQL Server로 마이그레이션합니다. 보고 목적을 위해 읽기 전용 복제본을 사용합니다.
B. Amazon EC2에서 Microsoft SQL Server를 사용하도록 마이그레이션합니다. 보고 목적을 위해 Always On 읽기 복제본을 사용합니다.
C. Amazon DynamoDB로 마이그레이션합니다. 보고 목적을 위해 DynamoDB 온디맨드 복제본을 사용합니다.
D. Amazon Aurora MySQL로 마이그레이션합니다. 보고 목적을 위해 Aurora 읽기 복제본을 사용합니다.

```
A company wants to migrate its on-premises Microsoft SQL Server Enterprise edition database to AWS. The company's online application uses the database to process transactions. The data analysis team uses the same production database to run reports for analytical processing. The company wants to reduce operational overhead by moving to managed services wherever possible.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Migrate to Amazon RDS for Microsoft SOL Server. Use read replicas for reporting purposes
- B. Migrate to Microsoft SQL Server on Amazon EC2. Use Always On read replicas for reporting purposes
- C. Migrate to Amazon DynamoDB. Use DynamoDB on-demand replicas for reporting purposes
- D. Migrate to Amazon Aurora MySQL. Use Aurora read replicas for reporting purposes
```

정답 : `A`

- RDS for SQL Server(Enterprise 에디션)는 관리형 패치/백업/모니터링을 제공하면서 읽기 전용 복제본(Always On 기반)으로 리포팅 워크로드를 오프로드할 수 있음
- 애플리케이션 변경을 최소화한 "리프트 앤드 시프트" 경로이므로 운영 오버헤드가 가장 낮고 OLTP와 리포팅(OLAP) 분리를 동시에 달성

오답 이유

- B. EC2에서 직접 SQL Server와 Always On을 운영하면 클러스터 구성, 패치, 장애 조치 관리 등 운영 부담이 큽니다. “관리형 서비스 선호”에 부합하지 않습니다.

- C. DynamoDB는 NoSQL 키-값/문서형으로 스키마/쿼리 모델이 달라 대규모 재설계가 필요합니다. 트랜잭션성 SQL 워크로드와 T-SQL 리포팅을 바로 대체하기 어렵습니다.

- D. Aurora MySQL로의 이관은 DB 엔진 변경(스키마/코드 호환성 문제)과 이관 작업이 커 운영 부담이 큽니다. 목표는 SQL Server 워크로드의 관리형 전환이지 엔진 전환이 아닙니다.


## #651
한 회사가 Amazon S3 버킷에 대량의 이미지 파일을 저장합니다. 이미지는 처음 180일 동안 즉시 사용 가능해야 합니다. 다음 180일 동안은 접근 빈도가 낮습니다. 360일 이후에는 이미지를 아카이브해야 하지만, 요청 시 즉시 사용 가능해야 합니다. 5년이 지난 후에는 감사 담당자만 이미지를 액세스할 수 있습니다. 감사 담당자는 12시간 이내에 이미지를 검색할 수 있어야 합니다. 이 과정에서 이미지를 잃어서는 안 됩니다.

개발자는 처음 180일 동안 S3 Standard 스토리지를 사용할 것입니다. 개발자는 S3 수명 주기(Lifecycle) 규칙을 구성해야 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 180일 후 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 360일 후 S3 Glacier Instant Retrieval로, 5년 후 S3 Glacier Deep Archive로 전환합니다.
B. 180일 후 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환합니다. 360일 후 S3 Glacier Flexible Retrieval로, 5년 후 S3 Glacier Deep Archive로 전환합니다.
C. 180일 후 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 360일 후 S3 Glacier Instant Retrieval로, 5년 후 S3 Glacier Deep Archive로 전환합니다.
D. 180일 후 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다. 360일 후 S3 Glacier Flexible Retrieval로, 5년 후 S3 Glacier Deep Archive로 전환합니다.

```
A company stores a large volume of image files in an Amazon S3 bucket. The images need to be readily available for the first 180 days. The images are infrequently accessed for the next 180 days. After 360 days, the images need to be archived but must be available instantly upon request. After 5 years, only auditors can access the images. The auditors must be able to retrieve the images within 12 hours. The images cannot be lost during this process.  
  
A developer will use S3 Standard storage for the first 180 days. The developer needs to configure an S3 Lifecycle rule.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 180 days. S3 Glacier Instant Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.
- B. Transition the objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 180 days. S3 Glacier Flexible Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.
- C. Transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 180 days, S3 Glacier Instant Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.
- D. Transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 180 days, S3 Glacier Flexible Retrieval after 360 days, and S3 Glacier Deep Archive after 5 years.
```

정답 : `C`

- 180~360일 구간: 내구성과 가용성을 유지해야 하므로 단일 AZ에 저장되는 One Zone-IA 대신 S3 Standard-IA(다중 AZ)가 적합
- 360일 이후: "아카이브지만 즉시 접근" 요구는 S3 Glacier Instant Retrieval만 충족(밀리초 단위 조회)
- 5년 이후: 감사용이고 12시간 내 검색이면 S3 Glacier Deep Archive(표준 검색 <= 12시간)가 가장 저렴

오답 이유

- A. 180일 후 One Zone-IA는 단일 AZ 저장으로 AZ 장애 시 데이터 손실 위험이 커집니다(“이미지를 잃어서는 안 됨” 위배).
- B. 360일 후 Flexible Retrieval은 분~시간 지연으로 “즉시 사용 가능” 요건을 만족하지 못합니다.
- D. 360일 후 Flexible Retrieval 역시 즉시 접근 요구를 충족하지 못합니다(Instant Retrieval 필요).


## #652
한 회사에 매일 6시간 동안 실행되는 대규모 데이터 워크로드가 있습니다. 프로세스가 실행되는 동안 데이터가 손실되어서는 안 됩니다. 솔루션스 아키텍트는 이 중요한 데이터 워크로드를 지원하기 위해 Amazon EMR 클러스터 구성을 설계하고 있습니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 기본(primary) 노드와 코어(core) 노드는 온디맨드 인스턴스로, 태스크(task) 노드는 스팟 인스턴스로 실행하는 장기 실행(롱런닝) 클러스터를 구성합니다.
B. 기본 노드와 코어 노드는 온디맨드 인스턴스로, 태스크 노드는 스팟 인스턴스로 실행하는 일시적(트랜지언트) 클러스터를 구성합니다.
C. 기본 노드는 온디맨드 인스턴스로, 코어 노드와 태스크 노드는 스팟 인스턴스로 실행하는 일시적(트랜지언트) 클러스터를 구성합니다.
D. 기본 노드는 온디맨드 인스턴스로, 코어 노드와 태스크 노드는 스팟 인스턴스로 실행하는 장기 실행(롱런닝) 클러스터를 구성합니다.

```
A company has a large data workload that runs for 6 hours each day. The company cannot lose any data while the process is running. A solutions architect is designing an Amazon EMR cluster configuration to support this critical data workload.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Configure a long-running cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.
- B. Configure a transient cluster that runs the primary node and core nodes on On-Demand Instances and the task nodes on Spot Instances.
- C. Configure a transient cluster that runs the primary node on an On-Demand Instance and the core nodes and task nodes on Spot Instances.
- D. Configure a long-running cluster that runs the primary node on an On-Demand Instance, the core nodes on Spot Instances, and the task nodes on Spot Instances.
```

정답 : `B`

- 매일 6시간만 필요한 워크로드이므로 트래지언트(작업 종료 시 자동 종료) 클러스터가 가장 비용 효율적
- 데이터 손실 금지 요구 때문에 HDFS를 보유한 코어 노드와 마스터 노드는 온디맨드로 유지해야 함
- 반면 연산 확장용 태스크 노드는 스팟으로 비용을 절감 가능(중단돼도 HDFS에 데이터가 없음)

오답 이유

- A. 롱런닝 클러스터는 24/7 비용이 들어 트랜지언트 대비 비효율적입니다.
- C. 코어 노드를 스팟으로 구성하면 스팟 회수 시 HDFS 데이터 손실 위험이 있어 “데이터 손실 없음” 요구에 어긋납니다.
- D. 롱런닝 + 코어 스팟은 비용·내구성 두 측면 모두 부적합합니다.


## #653
한 회사는 사용자와 코스트 센터를 매핑하는 Amazon RDS 데이터베이스를 유지하고 있습니다. 이 회사는 AWS Organizations의 조직 내에 여러 계정을 보유하고 있습니다. 회사는 조직 내 특정 AWS 계정에서 생성되는 모든 리소스에 태그를 적용하는 솔루션이 필요합니다. 솔루션은 리소스를 생성한 사용자의 코스트 센터 ID로 각 리소스를 태그해야 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 관리 계정에서 해당 특정 AWS 계정을 Organizations의 새로운 조직 단위(OU)로 이동합니다. 리소스가 생성되기 전에 모든 기존 리소스가 올바른 코스트 센터 태그를 갖도록 요구하는 서비스 제어 정책(SCP)을 생성합니다. 이 SCP를 새 OU에 적용합니다.
B. 적절한 코스트 센터를 RDS 데이터베이스에서 조회한 후 리소스에 태그를 적용하는 AWS Lambda 함수를 생성합니다. AWS CloudTrail 이벤트에 반응하여 Lambda 함수를 호출하는 Amazon EventBridge 규칙을 구성합니다.
C. AWS Lambda 함수를 배포하는 AWS CloudFormation 스택을 생성합니다. Lambda 함수가 RDS 데이터베이스에서 적절한 코스트 센터를 조회하고 리소스에 태그하도록 구성합니다. CloudFormation 스택을 호출하는 Amazon EventBridge 예약 규칙을 생성합니다.
D. 기본값으로 리소스에 태그를 적용하는 AWS Lambda 함수를 생성합니다. 코스트 센터 태그가 없는 리소스가 있을 때 Lambda 함수를 호출하도록 AWS CloudTrail 이벤트에 반응하는 Amazon EventBridge 규칙을 구성합니다.

```
A company maintains an Amazon RDS database that maps users to cost centers. The company has accounts in an organization in AWS Organizations. The company needs a solution that will tag all resources that are created in a specific AWS account in the organization. The solution must tag each resource with the cost center ID of the user who created the resource.  
  
Which solution will meet these requirements?

- A. Move the specific AWS account to a new organizational unit (OU) in Organizations from the management account. Create a service control policy (SCP) that requires all existing resources to have the correct cost center tag before the resources are created. Apply the SCP to the new OU.
- B. Create an AWS Lambda function to tag the resources after the Lambda function looks up the appropriate cost center from the RDS database. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function.
- C. Create an AWS CloudFormation stack to deploy an AWS Lambda function. Configure the Lambda function to look up the appropriate cost center from the RDS database and to tag resources. Create an Amazon EventBridge scheduled rule to invoke the CloudFormation stack.
- D. Create an AWS Lambda function to tag the resources with a default value. Configure an Amazon EventBridge rule that reacts to AWS CloudTrail events to invoke the Lambda function when a resource is missing the cost center tag.
```

정답 : `B`

- CloudTrail → EventBridge → Lambda(태깅) 패턴을 사용하면 리소스 생성 이벤트 시점에 EventBrdige가 Lambda랄 호출
- Labmda가 이벤트의 userIdentity(생성자)를 읽어 RDS 매핑 테이블에서 코스트 센터를 조회한 뒤 해당 리쇄스에 Tag API를 호출해 즉시 적용 가능

오답 이유

- A. SCP는 권한의 상한선을 제한/거부할 수 있을 뿐, 태그를 "자동 부여"하지 못합니다. 또한 사용자별 코스트 센터 조회/적용을 수행할 수 없습니다.
- C. CloudFormation 스택을 주기(예약) 실행해도 생성 즉시 태깅을 보장하지 못합니다(지연·누락 가능). 이벤트 구동이 적합합니다.
- D. 기본값으로 태깅하면 사용자별 정확한 코스트 센터 반영이 되지 않습니다. 이후 수정 로직도 요구 조건(정확한 사용자 매핑)에 부합하지 않습니다.


## #654
한 회사가 최근 웹 애플리케이션을 AWS 클라우드로 마이그레이션했습니다. 회사는 하나의 Amazon EC2 인스턴스를 사용해 애플리케이션을 호스팅하는 여러 프로세스를 실행합니다. 이 프로세스에는 정적 콘텐츠를 제공하는 Apache 웹 서버가 포함됩니다. Apache 웹 서버는 로컬 Redis 서버를 사용자 세션으로 사용하는 PHP 애플리케이션에 요청을 보냅니다.

회사는 아키텍처를 고가용성으로 재설계하고, AWS 관리형 솔루션을 사용하고자 합니다.

다음 중 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. AWS Elastic Beanstalk를 사용하여 정적 콘텐츠와 PHP 애플리케이션을 호스팅합니다. Elastic Beanstalk가 퍼블릭 서브넷에 EC2 인스턴스를 배포하도록 구성합니다. 공인 IP 주소를 할당합니다.
B. AWS Lambda를 사용하여 정적 콘텐츠와 PHP 애플리케이션을 호스팅합니다. Amazon API Gateway REST API를 사용하여 요청을 Lambda 함수로 프록시합니다. API Gateway CORS 구성을 도메인 이름에 응답하도록 설정합니다. Amazon ElastiCache for Redis를 구성하여 세션 정보를 처리합니다.
C. 백엔드 코드는 EC2 인스턴스에 유지합니다. Multi-AZ가 활성화된 Amazon ElastiCache for Redis 클러스터를 생성합니다. ElastiCache for Redis 클러스터를 클러스터 모드로 구성합니다. 프런트엔드 리소스를 Amazon S3로 복사합니다. 백엔드 코드가 EC2 인스턴스를 참조하도록 구성합니다.
D. Amazon S3 버킷(정적 웹 호스팅 구성)을 오리진으로 사용하는 Amazon CloudFront 배포를 구성합니다. AWS Fargate 태스크로 PHP 애플리케이션을 실행하는 Amazon Elastic Container Service(Amazon ECS) 서비스를 대상으로 하는 Application Load Balancer를 구성합니다. PHP 애플리케이션이 여러 가용 영역에서 실행되는 Amazon ElastiCache for Redis 클러스터를 사용하도록 구성합니다.

```
A company recently migrated its web application to the AWS Cloud. The company uses an Amazon EC2 instance to run multiple processes to host the application. The processes include an Apache web server that serves static content. The Apache web server makes requests to a PHP application that uses a local Redis server for user sessions.  
  
The company wants to redesign the architecture to be highly available and to use AWS managed solutions.  
  
Which solution will meet these requirements?

- A. Use AWS Elastic Beanstalk to host the static content and the PHP application. Configure Elastic Beanstalk to deploy its EC2 instance into a public subnet. Assign a public IP address.
- B. Use AWS Lambda to host the static content and the PHP application. Use an Amazon API Gateway REST API to proxy requests to the Lambda function. Set the API Gateway CORS configuration to respond to the domain name. Configure Amazon ElastiCache for Redis to handle session information.
- C. Keep the backend code on the EC2 instance. Create an Amazon ElastiCache for Redis cluster that has Multi-AZ enabled. Configure the ElastiCache for Redis cluster in cluster mode. Copy the frontend resources to Amazon S3. Configure the backend code to reference the EC2 instance.
- D. Configure an Amazon CloudFront distribution with an Amazon S3 endpoint to an S3 bucket that is configured to host the static content. Configure an Application Load Balancer that targets an Amazon Elastic Container Service (Amazon ECS) service that runs AWS Fargate tasks for the PHP application. Configure the PHP application to use an Amazon ElastiCache for Redis cluster that runs in multiple Availability Zones.
```

정답 : `D`

- 정적 콘텐츠는 S3 + CloudFront로 전 세계에 고가용성/저지연 제공이 가능
- PHP 백엔드는 ECS on Fargate + ALB로 서버 관리 없이 자동 확장/고가용성을 확보
- 세션은 ElastiCache for Reds(Multi-AZ)로 외부화하여 상태를 분리하고, 인스턴스 교체/스케일 아웃 시에도 무중단을 보장

오답 이유

- A. Elastic Beanstalk 단일 환경을 퍼블릭 서브넷 한 곳에 배치하고 공인 IP를 직접 할당하는 구성은 고가용성 요건을 충족하지 못합니다. 정적 콘텐츠를 EB로 제공하는 것도 비효율적입니다.

- B. Lambda는 PHP를 기본 지원하지 않아 커스텀 런타임/레이어가 필요하며, “정적 콘텐츠를 Lambda로 호스팅”하는 것은 적합하지 않습니다. 또한 장기 실행/상태 관리가 필요한 웹앱에는 ECS/Fargate가 더 적합합니다.

- C. 백엔드를 계속 EC2에 유지하면 관리형 요구와 상충하며, 단일 인스턴스 의존 구성이 될 수 있습니다. 고가용성 측면과 운영 오버헤드 감소 목표에 부합하지 않습니다.


## #655
한 회사가 Amazon EC2 인스턴스에서 웹 애플리케이션을 실행하고 있으며, 이 인스턴스들은 대상 그룹을 사용하는 Auto Scaling 그룹에 속해 있습니다. 회사는 더 나은 사용자 경험을 위해 애플리케이션을 세션 어피니티(스티키 세션)로 동작하도록 설계했습니다.

애플리케이션은 인터넷을 통해 공개 엔드포인트로 제공되어야 합니다. 추가 보안을 위해 해당 엔드포인트에 WAF가 적용되어야 합니다. 또한 엔드포인트에서 세션 어피니티(스티키 세션)가 구성되어야 합니다.

다음 중 이러한 요구 사항을 충족하는 단계의 조합은 무엇입니까? (두 가지 선택)

A. 퍼블릭 Network Load Balancer를 생성합니다. 애플리케이션 대상 그룹을 지정합니다.
B. Gateway Load Balancer를 생성합니다. 애플리케이션 대상 그룹을 지정합니다.
C. 퍼블릭 Application Load Balancer를 생성합니다. 애플리케이션 대상 그룹을 지정합니다.
D. 두 번째 대상 그룹을 생성합니다. EC2 인스턴스에 Elastic IP 주소를 추가합니다.
E. AWS WAF에서 웹 ACL을 생성합니다. 웹 ACL을 엔드포인트에 연결합니다.

```
A company runs a web application on Amazon EC2 instances in an Auto Scaling group that has a target group. The company designed the application to work with session affinity (sticky sessions) for a better user experience.  
  
The application must be available publicly over the internet as an endpoint. A WAF must be applied to the endpoint for additional security. Session affinity (sticky sessions) must be configured on the endpoint.  
  
Which combination of steps will meet these requirements? (Choose two.)

- A. Create a public Network Load Balancer. Specify the application target group.
- B. Create a Gateway Load Balancer. Specify the application target group.
- C. Create a public Application Load Balancer. Specify the application target group.
- D. Create a second target group. Add Elastic IP addresses to the EC2 instances.
- E. Create a web ACL in AWS WAF. Associate the web ACL with the endpoint
```

정답 : `C, E`

- C: ALB는 HTTP(S)용 공개 엔드포인트를 제공하며 대상 그룹 수준의 스티키 세션(ALB 쿠키 기반)을 지원
- E: AWS WAF는 ALB와 직접 통합되므로, 생성한 웹 ACL을 ALB 엔드포인트에 연결해 추가 보안을 적용 가능

오답 이유

- A. NLB는 4계층 로드 밸런서로 일부 소스 IP 기반 스틱니스는 가능하지만, AWS WAF를 NLB에 직접 연결할 수 없습니다. 또한 애플리케이션(L7) 쿠키 기반 스티키 세션 요구에 부적합합니다.

- B. Gateway Load Balancer는 네트워크 보안 어플라이언스를 배치하기 위한 용도로, 웹 애플리케이션의 공개 엔드포인트/스티키 세션 요건을 충족하지 않습니다.

- D. Elastic IP를 인스턴스에 붙이고 두 번째 대상 그룹을 만드는 것은 공개 엔드포인트·WAF 적용·스티키 세션 요건을 체계적으로 해결하지 못하고, 확장성/가용성도 저해합니다.


## #656
한 회사가 역사적 사건의 이미지를 저장하는 웹사이트를 운영합니다. 웹사이트 사용자는 이미지에 담긴 사건이 발생한 연도를 기준으로 이미지를 검색하고 볼 수 있어야 합니다. 평균적으로 사용자는 각 이미지를 1년에 한두 번만 요청합니다. 회사는 이미지를 저장하고 사용자에게 제공하기 위한 고가용성 솔루션을 원합니다.

다음 중 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. Amazon Elastic Block Store(Amazon EBS)에 이미지를 저장합니다. Amazon EC2에서 실행되는 웹 서버를 사용합니다.
B. Amazon Elastic File System(Amazon EFS)에 이미지를 저장합니다. Amazon EC2에서 실행되는 웹 서버를 사용합니다.
C. Amazon S3 Standard에 이미지를 저장합니다. 정적 웹사이트를 사용하여 S3 Standard로 이미지를 직접 제공합니다.
D. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 이미지를 저장합니다. 정적 웹사이트를 사용하여 S3 Standard-IA로 이미지를 직접 제공합니다.

```
A company runs a website that stores images of historical events. Website users need the ability to search and view images based on the year that the event in the image occurred. On average, users request each image only once or twice a year. The company wants a highly available solution to store and deliver the images to users.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Store images in Amazon Elastic Block Store (Amazon EBS). Use a web server that runs on Amazon EC2.
- B. Store images in Amazon Elastic File System (Amazon EFS). Use a web server that runs on Amazon EC2.
- C. Store images in Amazon S3 Standard. Use S3 Standard to directly deliver images by using a static website.
- D. Store images in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Use S3 Standard-IA to directly deliver images by using a static website.
```

정답 : `D`

- 객체가 연 1~2회 수준으로 드물게 조회되므로, 다중 AZ 내구성과 높은 가용성을 유지하면서도 저비용인 S3 Standard-IA가 가장 적합
- S3는 정적 웹사이트 호스팅/직접 제공이 가능하므로 별도 서버 없이 이미지 전달을 처리할 수 있어 운영 오버헤드 최소

오답 이유

- A. EBS는 단일 인스턴스/단일 AZ에 종속적이며, 웹 서버 운영 비용과 관리 오버헤드가 큽니다. 객체 제공용 대규모 정적 콘텐츠에는 부적합합니다.
- B. EFS는 공유 파일 시스템으로 운영 편의성은 있으나, 정적 객체 제공에는 S3 대비 비용이 높고 굳이 EC2 웹 서버가 필요해 오버헤드가 증가합니다.
- C. S3 Standard도 가능하지만, 접근 빈도가 매우 낮아 Standard-IA가 더 비용 효율적입니다(조회 수수료 감안해도 유리).


## #657
회사는 AWS Organizations의 조직 내에 여러 AWS 계정을 보유하고 있으며, 서로 다른 비즈니스 부서가 사용합니다. 회사는 전 세계에 여러 사무실이 있습니다. 회사는 조직 전체에서 새로운 사무실 CIDR 대역을 허용하거나 오래된 CIDR 대역을 제거하기 위해 보안 그룹 규칙을 업데이트해야 합니다. 회사는 CIDR 대역 업데이트에 필요한 관리 오버헤드를 최소화하기 위해 보안 그룹 규칙 관리를 중앙집중화하려고 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 조직의 관리 계정에 VPC 보안 그룹을 생성합니다. CIDR 대역 업데이트가 필요할 때 보안 그룹을 업데이트합니다.
B. CIDR 목록을 포함하는 VPC 고객 관리 프리픽스 리스트를 생성합니다. AWS Resource Access Manager(AWS RAM)를 사용하여 조직 전체에 프리픽스 리스트를 공유합니다. 조직 전체의 보안 그룹에서 이 프리픽스 리스트를 사용합니다.
C. AWS 관리형 프리픽스 리스트를 생성합니다. AWS Security Hub 정책을 사용하여 조직 전반의 보안 그룹 업데이트를 강제합니다. CIDR 대역이 변경될 때 프리픽스 리스트를 자동으로 업데이트하도록 AWS Lambda 함수를 사용합니다.
D. 중앙 관리용 AWS 계정에 보안 그룹을 생성합니다. 조직 전체에 대해 AWS Firewall Manager 공용 보안 그룹 정책을 생성합니다. 정책에서 앞서 생성한 보안 그룹을 기본 그룹으로 선택합니다.

```
A company has multiple AWS accounts in an organization in AWS Organizations that different business units use. The company has multiple offices around the world. The company needs to update security group rules to allow new office CIDR ranges or to remove old CIDR ranges across the organization. The company wants to centralize the management of security group rules to minimize the administrative overhead that updating CIDR ranges requires.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Create VPC security groups in the organization's management account. Update the security groups when a CIDR range update is necessary.
- B. Create a VPC customer managed prefix list that contains the list of CIDRs. Use AWS Resource Access Manager (AWS RAM) to share the prefix list across the organization. Use the prefix list in the security groups across the organization.
- C. Create an AWS managed prefix list. Use an AWS Security Hub policy to enforce the security group update across the organization. Use an AWS Lambda function to update the prefix list automatically when the CIDR ranges change.
- D. Create security groups in a central administrative AWS account. Create an AWS Firewall Manager common security group policy for the whole organization. Select the previously created security groups as primary groups in the policy.
```

정답 : `B`

- VPC 고객 관리 프리픽스 리스트를 만들어 사무실 CIDR 목록을 한 곳에서 관리하고, 이를 AWS RAM으로 조직 전체에 공유하면 각 계정/리전의 보안 그룹 규칙에서 해당 프리픽스 리스트만 참조하면 됨.
- 이후 CIDR 추가/삭제는 프리픽스 리스트 한 번 수정으로 모든 보안 그룹에 자동 반영되어 운영 오버헤드와 비용을 최소화

오답 이유

- A. 관리 계정의 보안 그룹만 업데이트해도 다른 계정의 보안 그룹에는 자동 반영되지 않습니다. 중앙집중·조직 전파 기능이 없습니다.

- C. AWS 관리형 프리픽스 리스트는 주로 AWS 서비스(예: CloudFront, S3)용이며, 회사의 사무실 CIDR 같은 임의의 사용자 정의 CIDR을 담을 수 없습니다. Security Hub는 규정 준수/탐지 서비스로서 보안 그룹 규칙을 강제 적용하지 않습니다. 불필요한 Lambda 자동화도 과도합니다.

- D. Firewall Manager 공용 보안 그룹 정책으로 중앙 배포는 가능하지만, 서비스 사용 비용이 추가되고(계정/리소스 단위 과금) 단순 CIDR 변경을 위해 정책을 매번 수정·배포해야 합니다. 프리픽스 리스트 참조 대비 운영·비용 효율이 떨어집니다.


## #658
한 회사는 온프레미스 NAS 시스템을 사용해 HPC(고성능 컴퓨팅) 워크로드에 파일 공유를 제공합니다. 회사는 지연 시간에 민감한 HPC 워크로드와 스토리지를 AWS 클라우드로 마이그레이션하고자 합니다. 파일 시스템에서 NFS와 SMB의 멀티 프로토콜 접근을 제공할 수 있어야 합니다.

다음 중 지연 시간을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지 선택)

A. 컴퓨팅 최적화 EC2 인스턴스를 클러스터 배치 그룹(cluster placement group)에 배포합니다.
B. 컴퓨팅 최적화 EC2 인스턴스를 파티션 배치 그룹(partition placement group)에 배포합니다.
C. EC2 인스턴스를 Amazon FSx for Lustre 파일 시스템에 연결합니다.
D. EC2 인스턴스를 Amazon FSx for OpenZFS 파일 시스템에 연결합니다.
E. EC2 인스턴스를 Amazon FSx for NetApp ONTAP 파일 시스템에 연결합니다.

```
A company uses an on-premises network-attached storage (NAS) system to provide file shares to its high performance computing (HPC) workloads. The company wants to migrate its latency-sensitive HPC workloads and its storage to the AWS Cloud. The company must be able to provide NFS and SMB multi-protocol access from the file system.  
  
Which solution will meet these requirements with the LEAST latency? (Choose two.)

- A. Deploy compute optimized EC2 instances into a cluster placement group.
- B. Deploy compute optimized EC2 instances into a partition placement group.
- C. Attach the EC2 instances to an Amazon FSx for Lustre file system.
- D. Attach the EC2 instances to an Amazon FSx for OpenZFS file system.
- E. Attach the EC2 instances to an Amazon FSx for NetApp ONTAP file system.
```

정답 : `A, E`

- A. 클러스터 배치 그룹: 인스턴스들을 물리적으로 가까이 배치하여 초저지연･고대역폭 통신을 확보해 HPC에 최적
- E. FSx for NetApp ONTAP: NFS와 SMB 멀티프로토콜을 모두 지원하는 관리형 파일 시스템으로, 지연을 최소화하면서 요구사항을 충족

오답 이유

- B. 파티션 배치 그룹은 대규모 분산 워크로드의 장애 도메인 분리를 위한 용도로, 최저 지연 확보 목적에는 클러스터 배치 그룹보다 부적합합니다.

- C. FSx for Lustre는 HPC 성능은 뛰어나지만 Lustre 고유 프로토콜을 사용하며 SMB를 지원하지 않습니다. 문제의 “NFS와 SMB 멀티프로토콜” 요구에 맞지 않습니다.

- D. FSx for OpenZFS는 NFS는 지원하지만 SMB는 지원하지 않습니다. 멀티프로토콜 요건을 만족하지 못합니다.


## #659
한 회사가 데이터 센터를 이전하려고 하며, 2주 이내에 50TB의 데이터를 AWS로 안전하게 전송하려고 합니다. 기존 데이터 센터는 AWS와 Site-to-Site VPN 연결을 사용 중이며, 현재 이 연결은 90%가 이미 사용되고 있습니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 AWS 서비스를 사용해야 합니까?

A. VPC 엔드포인트를 사용하는 AWS DataSync  
B. AWS Direct Connect  
C. AWS Snowball Edge Storage Optimized  
D. AWS Storage Gateway

```
A company is relocating its data center and wants to securely transfer 50 TB of data to AWS within 2 weeks. The existing data center has a Site-to-Site VPN connection to AWS that is 90% utilized.  
  
Which AWS service should a solutions architect use to meet these requirements?

- A. AWS DataSync with a VPC endpoint
- B. AWS Direct Connect
- C. AWS Snowball Edge Storage Optimized
- D. AWS Storage Gateway
```

정답 : `C`

- Site-to-Site VPN은 이미 90% 사용 중이므로 추가로 50TB를 전송하기엔 대역폭과 시간 제약이 큼
- AWS Snowball Edge Storage Optimized는 대용량(50TB 이상) 데이터를 물리적으로 안전하게 AWS로 전송하는 오프라인 전송 서비스
- 2주 이내 마이그레이션 목표를 안전하고 네트워크 부담 없이 달성할 수 있는 가장 현실적이고 비용 효율적인 방법
- Snowball은 암호화된 스토리지 디바이스를 배송받아 데이터를 복사하고 AWS로 반송하면, 데이터는 S3로 자동 업로드

오답 이유

- A. DataSync는 네트워크 기반 온라인 전송 서비스이므로, 현재 VPN(90% 사용) 환경에서는 충분한 전송 대역폭이 없어 2주 내 50TB 전송이 불가능합니다.

- B. Direct Connect는 전용선 연결로 고속 전송이 가능하나, 설치와 프로비저닝에 **수 주~수 개월 소요**될 수 있어 "2주 이내" 요건을 충족하지 못합니다.

- D. Storage Gateway는 온프레미스와 AWS 간 하이브리드 스토리지 연결(캐시/볼륨/파일 게이트웨이)용이며, 대규모 초기 데이터 마이그레이션에는 비효율적입니다.


## #660
한 회사가 Amazon EC2 온디맨드 인스턴스로 구성된 Auto Scaling 그룹에서 애플리케이션을 호스팅하고 있습니다.  
애플리케이션의 피크 시간대(트래픽이 가장 많은 시간)는 매일 동일한 시간에 발생합니다.  
사용자들은 피크 시간대가 시작될 때 애플리케이션 성능이 느려진다고 보고하지만, 피크 시간대가 시작된 후 2~3시간이 지나면 정상적으로 작동합니다.  
회사는 애플리케이션이 피크 시간대가 시작되는 시점부터 정상적으로 작동하도록 보장하길 원합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Application Load Balancer를 구성하여 인스턴스로 트래픽을 적절히 분산시킵니다.  
B. Auto Scaling 그룹에 메모리 사용률을 기준으로 새로운 인스턴스를 시작하는 동적 스케일링 정책을 구성합니다.  
C. Auto Scaling 그룹에 CPU 사용률을 기준으로 새로운 인스턴스를 시작하는 동적 스케일링 정책을 구성합니다.  
D. Auto Scaling 그룹에 예약 스케일링 정책을 구성하여 피크 시간 이전에 새로운 인스턴스를 시작하도록 합니다.

```
A company hosts an application on Amazon EC2 On-Demand Instances in an Auto Scaling group. Application peak hours occur at the same time each day. Application users report slow application performance at the start of peak hours. The application performs normally 2-3 hours after peak hours begin. The company wants to ensure that the application works properly at the start of peak hours.  
  
Which solution will meet these requirements?

- A. Configure an Application Load Balancer to distribute traffic properly to the instances.
- B. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on memory utilization.
- C. Configure a dynamic scaling policy for the Auto Scaling group to launch new instances based on CPU utilization.
- D. Configure a scheduled scaling policy for the Auto Scaling group to launch new instances before peak hours.
```

정답 : `D`

- 문제의 핵심은 피크 시간이 매일 동일한 시간대에 예측 가능하게 발생한다는 것
- 예약 스케일링(Scheduled Scaling)을 사용해 피크 시작 전에 미리 인스턴스를 추가로 실행하면, 인스턴스가 부하를 받기 전에 워밍업되어 초기 성능 저하를 방지

오답 이유

- A. ALB는 트래픽 분산을 담당하지만, 피크 시간 이전의 용량 부족 문제(인스턴스 수 부족)를 해결하지는 못합니다.

- B. 메모리 사용률 기반 스케일링은 CloudWatch에서 직접 지원되지 않으며, 지표 수집/구성의 복잡도가 높습니다. 또한 문제의 핵심은 예측 가능한 시간대의 부하이므로 동적 스케일링은 불필요하게 지연됩니다.

- C. CPU 사용률 기반 동적 스케일링은 부하가 발생한 뒤에 인스턴스를 늘리기 때문에, 인스턴스가 준비되기 전까지 성능 저하가 발생할 수 있습니다(지연된 반응).