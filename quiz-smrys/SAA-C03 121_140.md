---
created: 2025-09-28 12:02:21
last_modified: 2025-09-30 12:39:49
---
## #121
한 회사가 AWS에서 온라인 트랜잭션 처리(OLTP) 워크로드를 실행하고 있습니다.  
이 워크로드는 Multi-AZ 배포로 구성된 **암호화되지 않은 Amazon RDS DB 인스턴스**를 사용합니다.  
이 인스턴스에서 매일 데이터베이스 스냅샷이 생성됩니다.  

앞으로 데이터베이스와 스냅샷이 항상 암호화되도록 하려면 솔루션 설계자는 무엇을 해야 합니까?

A. 최신 DB 스냅샷을 암호화된 사본으로 생성합니다. 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다.  
B. 새 암호화된 Amazon Elastic Block Store(EBS) 볼륨을 생성하고 스냅샷을 여기에 복사합니다. DB 인스턴스에서 암호화를 활성화합니다.  
C. 스냅샷을 복사하고 AWS Key Management Service(AWS KMS)를 사용하여 암호화를 활성화합니다. 암호화된 스냅샷을 사용하여 기존 DB 인스턴스를 복원합니다.  
D. 스냅샷을 Amazon S3 버킷으로 복사하고 AWS Key Management Service(AWS KMS) 관리 키(SSE-KMS)를 사용하여 서버 측 암호화를 적용합니다.

```
A company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi-AZ deployment. Daily database snapshots are taken from this instance.  
What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward?

- A. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.
- B. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots to it. Enable encryption on the DB instance.
- C. Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS) Restore encrypted snapshot to an existing DB instance.
- D. Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS).
```


정답 : `A`

- RDS 인스턴스 자체는 기존에 암호화되지 않은 상태에서는 직접 암호화 설정이 불가
- 기존 스냅샷을 암호화된 스냅샷으로 복사하고, 그 스냅샷에서 새 DB 인스턴스를 복원하면 DB 인스턴스와 스냅샷이 모두 암호화됨
- 이후 생성되는 모든 스냅샷도 자동으로 암호화

오답 이유

- **B. EBS 볼륨 생성 후 복사**
    - RDS는 **EBS 직접 접근을 지원하지 않음**. EBS 볼륨을 만들고 스냅샷을 복사해도 RDS DB 인스턴스 암호화는 적용되지 않음
    
- **C. 스냅샷 복사 후 기존 인스턴스 복원**
    - **기존 DB 인스턴스는 직접 암호화 불가**. 스냅샷에서 새 DB 인스턴스를 만들어야 함. 기존 인스턴스를 그대로 복원하면 암호화되지 않음
    
- **D. S3로 스냅샷 복사 후 SSE-KMS 암호화**
    - RDS 스냅샷을 S3로 직접 옮겨도 **RDS에서 복원 가능한 암호화된 DB 인스턴스**를 만드는 방법이 아님. 운영 DB 암호화 요구 사항을 충족하지 않음


## #122
한 회사가 개발자들이 애플리케이션에서 데이터를 암호화하는 데 사용할 수 있는 **확장 가능한 키 관리 인프라**를 구축하고자 합니다.  
운영 부담을 줄이려면 솔루션 설계자는 무엇을 해야 합니까?

A. 다단계 인증(MFA)을 사용하여 암호화 키를 보호합니다.  
B. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키를 보호합니다.  
C. AWS Certificate Manager(ACM)를 사용하여 암호화 키를 생성, 저장, 할당합니다.  
D. IAM 정책을 사용하여 암호화 키에 대한 액세스 권한을 가진 사용자의 범위를 제한합니다.

```
A company wants to build a scalable key management infrastructure to support developers who need to encrypt data in their applications.  
What should a solutions architect do to reduce the operational burden?

- A. Use multi-factor authentication (MFA) to protect the encryption keys.
- B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys.
- C. Use AWS Certificate Manager (ACM) to create, store, and assign the encryption keys.
- D. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys.
```

정답 : `B`

- AWS KMS는 완전관리형 키 관리 서비스로 개발자가 애플리케이션에서 쉽게 데이터를 암호화/복호화할 수 있는 확장 가능한 인프라를 제공
- 키 생성, 저장, 회전, 액세스 제어 등 운영 부담을 최소화
- IAM과 통합되어 세부적인 권한 관리도 가능

오답 이유

- **A. MFA 사용**
    - MFA는 키 보호의 일부 보안 조치일 뿐, **확장 가능한 키 관리 인프라 제공에는 부족**
    
- **C. ACM 사용**
    - ACM은 SSL/TLS 인증서 관리용으로 설계됨. **데이터 암호화 키 관리는 지원하지 않음**
    
- **D. IAM 정책만 사용**
    - 권한 제한은 키 접근을 제어할 수 있지만, **키 생성, 회전, 보관 같은 관리 기능은 제공하지 않음**


## #123
한 회사가 두 개의 Amazon EC2 인스턴스에서 동적 웹 애플리케이션을 호스팅하고 있습니다.  
회사는 자체 SSL 인증서를 가지고 있으며, 각 인스턴스에서 SSL 종료(SSL termination)를 수행합니다.  

최근 트래픽이 증가하면서 운영팀은 **SSL 암호화 및 복호화로 인해 웹 서버의 컴퓨팅 용량이 최대 한계에 도달**했다고 판단했습니다.  

솔루션 설계자가 애플리케이션 성능을 향상시키기 위해 수행해야 하는 작업은 무엇입니까?

A. AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. ACM 인증서를 각 인스턴스에 설치합니다.  
B. Amazon S3 버킷을 생성합니다. SSL 인증서를 S3 버킷으로 마이그레이션합니다. EC2 인스턴스가 SSL 종료를 위해 버킷을 참조하도록 구성합니다.  
C. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스로 연결을 전달하도록 구성합니다.  
D. SSL 인증서를 AWS Certificate Manager(ACM)에 가져옵니다. ACM 인증서를 사용하도록 HTTPS 리스너가 있는 Application Load Balancer를 생성합니다.

```
A company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination.  
There has been an increase in traffic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit.  
What should a solutions architect do to increase the application's performance?

- A. Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.
- B. Create an Amazon S3 bucket Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.
- C. Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.
- D. Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM.
```

정답 : `D`

- 문제 : SSL 종료로 인해 각 EC2 인스턴스의 CPU가 포화 -> 성능 저하
- 해결방법
	- SSL 종료를 Application Load balancer(ALB)로 오프로드
	- ALB는 HTTPS 트래픽을 처리하며 EC2 인스턴스는 암호화/복호화 부담 없이 애플리케이션 로직만 수행
	- ACM과 통합하여 인증서 관리, 자동 갱신 가능

오답 이유

- **A. ACM 인증서를 각 인스턴스에 설치**
    - EC2가 여전히 SSL 종료를 수행 → CPU 부담 여전히 존재
    
- **B. S3로 인증서를 이동**
    - S3는 SSL 종료를 수행하지 않음 → 해결책 아님
    
- **C. 추가 EC2를 프록시 서버로 구성**
    - SSL 종료 부담이 다른 EC2로 이동될 뿐, **근본적인 문제(로드밸런서 없는 구조)는 해결되지 않음**


## #124
한 회사가 많은 Amazon EC2 인스턴스를 사용하여 완료하는 **동적인 배치 처리 작업**을 가지고 있습니다.  
이 작업은 상태가 없으며, 언제든지 시작 및 중단할 수 있으며 부정적인 영향이 없습니다.  
총 완료 시간은 일반적으로 **60분 이상**입니다.  

회사는 솔루션 설계자에게 **확장 가능하고 비용 효율적인 솔루션**을 설계하도록 요청했습니다.  

솔루션 설계자가 권장해야 하는 방법은 무엇입니까?

A. EC2 스팟 인스턴스를 구현합니다.  
B. EC2 예약 인스턴스를 구매합니다.  
C. EC2 온디맨드 인스턴스를 구현합니다.  
D. AWS Lambda에서 처리를 구현합니다.

```
A company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete. The company has asked a solutions architect to design a scalable and cost-effective solution that meets the requirements of the job.  
What should the solutions architect recommend?

- A. Implement EC2 Spot Instances.
- B. Purchase EC2 Reserved Instances.
- C. Implement EC2 On-Demand Instances.
- D. Implement the processing on AWS Lambda.
```


정답 : `A`

- 작업의 특성
	- 상태가 없고 언제든지 시작 및 중단 가능 -> Spot 인스턴스 중단 가능성 허용
	- 총 실행 시간 >= 60분 -> 람다 제한(최대 15분)을 초과 -> 람다 사용 불가
- 비용 효율성
	- EC2 Spot 인스턴스는 온디맨드 대비 최대 90% 저렴
- 확장성
	- 오토 스케일링 그룹이나 EC2 Fleet과 Spot을 함께 사용하여 수백~수천 인스턴스로 자동 확장 가능

오답 이유

- **B. EC2 예약 인스턴스**
    - 장기 사용에 적합, 배치 작업의 동적 요구에 맞지 않음
    
- **C. EC2 온디맨드 인스턴스**
    - 유연하지만 비용이 높음 → 비용 효율적 요구 불만족
    
- **D. AWS Lambda**
    - Lambda 최대 실행 시간 15분 → 60분 이상 작업 불가


## #125
한 회사가 AWS에서 2계층 전자상거래 웹사이트를 운영하고 있습니다.  

- 웹 계층: 트래픽을 Amazon EC2 인스턴스로 보내는 로드 밸런서  
- 데이터베이스 계층: Amazon RDS DB 인스턴스  

요구 사항:  
- EC2 인스턴스와 RDS DB 인스턴스는 **공용 인터넷에 노출되지 않아야 함**  
- EC2 인스턴스는 제3자 웹 서비스를 통한 결제 처리를 위해 **인터넷 액세스 필요**  
- 애플리케이션은 **고가용성 필요**

이 요구 사항을 충족하는 구성 옵션 조합은 무엇입니까? (두 개 선택)

A. Auto Scaling 그룹을 사용하여 **EC2 인스턴스를 프라이빗 서브넷**에 시작합니다. RDS Multi-AZ DB 인스턴스를 프라이빗 서브넷에 배포합니다.  

B. 두 개의 프라이빗 서브넷과 두 개의 NAT 게이트웨이를 두 개의 AZ에 걸쳐 구성합니다. 프라이빗 서브넷에 **Application Load Balancer**를 배포합니다.  

C. Auto Scaling 그룹을 사용하여 **EC2 인스턴스를 퍼블릭 서브넷**에 시작합니다. RDS Multi-AZ DB 인스턴스를 프라이빗 서브넷에 배포합니다.  

D. 하나의 퍼블릭 서브넷, 하나의 프라이빗 서브넷, 두 개의 NAT 게이트웨이를 두 개의 AZ에 걸쳐 구성합니다. 퍼블릭 서브넷에 **Application Load Balancer**를 배포합니다.  

E. 두 개의 퍼블릭 서브넷, 두 개의 프라이빗 서브넷, 두 개의 NAT 게이트웨이를 두 개의 AZ에 걸쳐 구성합니다. 퍼블릭 서브넷에 **Application Load Balancer**를 배포합니다.

```
A company runs its two-tier ecommerce website on AWS. The web tier consists of a load balancer that sends traffic to Amazon EC2 instances. The database tier uses an Amazon RDS DB instance. The EC2 instances and the RDS DB instance should not be exposed to the public internet. The EC2 instances require internet access to complete payment processing of orders through a third-party web service. The application must be highly available.  
Which combination of configuration options will meet these requirements? (Choose two.)

- A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets.
- B. Configure a VPC with two private subnets and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the private subnets.
- C. Use an Auto Scaling group to launch the EC2 instances in public subnets across two Availability Zones. Deploy an RDS Multi-AZ DB instance in private subnets.
- D. Configure a VPC with one public subnet, one private subnet, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnet.  
    D. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.
```

정답 : `A, E`

- A: EC2 인스턴스 프라이빗 서브넷, RDS Multi-AZ DB 프라이빗 서브넷
	- EC2와 RDS 모두 공용 인터넷에 노출되지 않음
	- RDS Multi-AZ -> 고가용성 확보
- E: 퍼블릭 서브넷에 ALB, 프라이빗 서브넷에 EC2 + NAT 게이트웨이
	- ALB는 퍼블릭에서 접근 가능 -> 웹 트래픽 수신
	- EC2는 프라이빗 서브넷 -> 인터넷에서 직접 접근 불가
	- NAT 게이트웨이를 통해 EC2가 인터넷으로 결제 요청 전송 가능
	- 두 개의 AZ -> 고가용성 확보

오답 이유

- **B. ALB를 프라이빗 서브넷에 배포**
    - 퍼블릭 인터넷에서 접근 불가 → 사용자가 웹사이트에 접속 불가능
    
- **C. EC2를 퍼블릭 서브넷에 배포**
    - 요구 사항: EC2는 **공용 인터넷에 노출되지 않아야 함** → 불만족
    
- **D. 하나의 퍼블릭/프라이빗 서브넷만 사용**
    - 두 개의 AZ 필요 → 고가용성 요구 불만족


## #126
솔루션 아키텍트는 회사의 스토리지 비용을 줄이기 위한 솔루션을 구현해야 합니다.  
회사의 모든 데이터는 Amazon S3 Standard 스토리지 클래스에 있습니다.  
회사는 모든 데이터를 최소 25년 동안 보관해야 합니다.  
최근 2년의 데이터는 고가용성(Highly Available)이며 즉시 검색 가능해야 합니다.  

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. S3 수명 주기(Lifecycle) 정책을 설정하여 객체를 즉시 S3 Glacier Deep Archive로 전환합니다.  
B. S3 수명 주기 정책을 설정하여 객체를 2년 후 S3 Glacier Deep Archive로 전환합니다.  
C. S3 Intelligent-Tiering을 사용합니다. 아카이빙 옵션을 활성화하여 데이터가 S3 Glacier Deep Archive로 아카이브되도록 합니다.  
D. S3 수명 주기 정책을 설정하여 객체를 즉시 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하고 2년 후 S3 Glacier Deep Archive로 전환합니다.

```
A solutions architect needs to implement a solution to reduce a company's storage costs. All the company's data is in the Amazon S3 Standard storage class. The company must keep all data for at least 25 years. Data from the most recent 2 years must be highly available and immediately retrievable.  
Which solution will meet these requirements?

- A. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive immediately.
- B. Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 2 years.
- C. Use S3 Intelligent-Tiering. Activate the archiving option to ensure that data is archived in S3 Glacier Deep Archive.
- D. Set up an S3 Lifecycle policy to transition objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately and to S3 Glacier Deep Archive after 2 years.
```

정답 : `B`

- 최근 2년간의 데이터는 즉시 접근 가능 -> Glacier Deep Archive로 이동시키면 안됨
- 2년 후의 데이터는 장기 보관 비용을 절감하기 위해 Glacier Deep Archive로 전환

오답 이유
- **A, D**
	- 객체를 즉시 Glacier Deep Archive 또는 One Zone-IA로 이동 → 최근 2년 데이터 즉시 접근 불가 → 요구사항 위반
        
- **C**
	- Intelligent-Tiering은 액세스 패턴 기반으로 아카이브 → 최근 2년 데이터의 즉시 접근 요구사항 보장 불가


## #127
한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리를 위해 가능한 최대 I/O 성능을 제공하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위해 300TB의 매우 내구성이 높은 스토리지, 더 이상 사용하지 않는 아카이브 미디어 요구사항을 충족하기 위해 900TB의 스토리지가 필요합니다.  
이 요구사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 서비스 조합은 무엇입니까?

A. 최대 성능을 위해 Amazon EBS, 내구성 있는 데이터 저장을 위해 Amazon S3, 아카이브 스토리지를 위해 Amazon S3 Glacier  
B. 최대 성능을 위해 Amazon EBS, 내구성 있는 데이터 저장을 위해 Amazon EFS, 아카이브 스토리지를 위해 Amazon S3 Glacier  
C. 최대 성능을 위해 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 저장을 위해 Amazon EFS, 아카이브 스토리지를 위해 Amazon S3  
D. 최대 성능을 위해 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 저장을 위해 Amazon S3, 아카이브 스토리지를 위해 Amazon S3 Glacier

```
A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing, 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore.  
Which set of services should a solutions architect recommend to meet these requirements?

- A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage
- B. Amazon EBS for maximum performance, Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage
- C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage
- D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage
```


정답 : `A`

- 비디오 처리를 위해 최대 I/O 성능이 필요하므로 블록 스토리지인 Amazon EBS (특히 io2 or gp3 볼륨)를 사용하는 것이 적합
- 300TB의 내구성이 중요한 미디어 콘텐츠 -> Amazon S3 : 99.999999999%의 내구성을 제공하며 대규모 데이터 저장에 적합
- 더 이상 사용하지 않는 900TB 아카이브 미디어는 비용 효율적인 장기 보관이 필요하므로 Amazon S3 Glacier 적합

오답 이유

- B
	- Amazon EFS는 내구성이 높지만, 300TB 규모의 대용량 객체 저장보다는 파일 시스템 형태의 접근에 적합하며, 비용이 S3보다 높습니다.
    
- C
	- EC2 인스턴스 스토어는 최대 I/O를 제공할 수 있지만 **인스턴스 종료 시 데이터가 손실**되므로 내구성 요구 사항을 충족하지 못합니다. 또한 아카이브를 S3로 설정하면 맞지만, 최대 성능용 스토리지 선택이 부적합합니다.
    
- D
	- EC2 인스턴스 스토어는 내구성이 없으므로 최대 성능 스토리지로 적합하지 않으며, S3는 300TB 저장에는 적합하지만 인스턴스 스토어로 최대 성능을 충족하는 부분이 부족합니다.

## #128
한 회사가 AWS 클라우드에서 컨테이너로 애플리케이션을 실행하려고 합니다. 이 애플리케이션은 상태가 없으며, 기본 인프라에서 발생하는 장애를 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다.  
이 요구사항을 충족하기 위해 솔루션 설계자가 수행해야 할 작업은 무엇입니까?

A. 애플리케이션 컨테이너를 실행하기 위해 Amazon EC2 Auto Scaling 그룹에서 스팟 인스턴스를 사용합니다.  
B. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 스팟 인스턴스를 사용합니다.  
C. 애플리케이션 컨테이너를 실행하기 위해 Amazon EC2 Auto Scaling 그룹에서 온디맨드 인스턴스를 사용합니다.  
D. Amazon Elastic Kubernetes Service(Amazon EKS) 관리형 노드 그룹에서 온디맨드 인스턴스를 사용합니다.

```
A company wants to run applications in containers in the AWS Cloud. These applications are stateless and can tolerate disruptions within the underlying infrastructure. The company needs a solution that minimizes cost and operational overhead.  
What should a solutions architect do to meet these requirements?

- A. Use Spot Instances in an Amazon EC2 Auto Scaling group to run the application containers.
- B. Use Spot Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.
- C. Use On-Demand Instances in an Amazon EC2 Auto Scaling group to run the application containers.
- D. Use On-Demand Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.
```

정답 : `A`

- 애플리케이션이 상태가 없고, 인프라 장애를 견딜 수 있으므로 스팟 인스턴스를 사용해 비용을 크게 절감
- EC2 오토 스케일링 그룹을 사용하면 인스턴스가 종료되거나 추가되는 상황에도 자동으로 컨테이너를 재배포할 수 있어 운영 오버헤드가 낮음
- EKS를 사용할 경우 쿠버네티스 클러스터 관리가 필요하며, 상태가 없는 단순 컨테이너 애플리케이션이라면 EKS를 도입하는 것은 불필요한 복잡성 추가

오답 이유
- B: EKS에서 스팟 인스턴스를 사용하는 것도 가능하지만, 관리형 Kubernetes 클러스터를 운영해야 하므로 불필요하게 운영 오버헤드가 증가합니다.
- C: 온디맨드 인스턴스를 사용하면 장애 시 안정적이지만, 비용이 높아지므로 최소 비용 요구사항을 충족하지 못합니다.
- D: EKS + 온디맨드는 가장 안정적이지만 비용과 운영 오버헤드가 모두 가장 높습니다.

## #129
한 회사가 온프레미스에서 멀티티어 웹 애플리케이션을 운영하고 있습니다. 이 웹 애플리케이션은 컨테이너화되어 여러 Linux 호스트에서 실행되며, 사용자 레코드를 포함하는 PostgreSQL 데이터베이스에 연결됩니다. 인프라를 유지 관리하고 용량 계획을 수행하는 운영 오버헤드가 회사의 성장을 제한하고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다.  
이 목표를 달성하기 위해 솔루션 설계자가 수행해야 할 작업의 조합은 무엇입니까? (두 가지 선택)

A. PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.  
B. 웹 애플리케이션을 Amazon EC2 인스턴스에서 호스팅되도록 마이그레이션합니다.  
C. 웹 애플리케이션 콘텐츠에 대해 Amazon CloudFront 배포를 설정합니다.  
D. 웹 애플리케이션과 PostgreSQL 데이터베이스 사이에 Amazon ElastiCache를 설정합니다.  
E. 웹 애플리케이션을 AWS Fargate와 Amazon Elastic Container Service(Amazon ECS)에서 호스팅되도록 마이그레이션합니다.

```
A company is running a multi-tier web application on premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company's growth. A solutions architect must improve the application's infrastructure.  
Which combination of actions should the solutions architect take to accomplish this? (Choose two.)

- A. Migrate the PostgreSQL database to Amazon Aurora.
- B. Migrate the web application to be hosted on Amazon EC2 instances.
- C. Set up an Amazon CloudFront distribution for the web application content.
- D. Set up Amazon ElastiCache between the web application and the PostgreSQL database.
- E. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS).
```


정답 : `A, E`

- A: Aurora는 완전관리형 관계형 데이터베이스로, 자동 백업, 고가용성, 성능 튜닝, 스케일링을 제공하여 운영 오버헤드를 크게 줄일 수 있음. 기존 PostgreSQL과 호환되어 마이그레이션 비용이 적음
- E: AWS Fargate는 서버를 직접 관리할 필요 없이 컨테이너를 실행할 수 있는 완전관리형 서비스. 인프라 운영 및 용량 계획 부담을 제거하고, 컨테이너 기반 웹 애플리케이션에 적합

오답 이유

- B: EC2로 이전하면 서버 관리와 용량 계획 책임이 여전히 남아 있어 운영 오버헤드가 줄지 않습니다.
- C: CloudFront는 전세계 사용자에게 콘텐츠를 빠르게 제공하는 CDN이지만, 인프라 운영 부담을 줄이는 목적과 직접 관련이 없습니다.
- D: ElastiCache는 데이터베이스 캐싱을 통해 성능을 향상시킬 수 있지만, 운영 오버헤드 감소와 용량 계획 문제를 근본적으로 해결하지 않습니다.

## #130
애플리케이션이 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40% 수준이거나 그 근처일 때 가장 성능이 좋습니다.  
Auto Scaling 그룹의 모든 인스턴스에서 원하는 성능을 유지하려면 솔루션 설계자가 무엇을 해야 합니까?

A. 간단한 스케일링 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다.  
B. 대상 추적 정책(Target Tracking Policy)을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다.  
C. AWS Lambda 함수를 사용하여 Auto Scaling 그룹의 원하는 용량을 업데이트합니다.  
D. 예약된 스케일링 작업(Scheduled Scaling Actions)을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다.

```
An application runs on Amazon EC2 instances across multiple Availability Zonas. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%.  
What should a solutions architect do to maintain the desired performance across all instances in the group?

- A. Use a simple scaling policy to dynamically scale the Auto Scaling group.
- B. Use a target tracking policy to dynamically scale the Auto Scaling group.
- C. Use an AWS Lambda function ta update the desired Auto Scaling group capacity.
- D. Use scheduled scaling actions to scale up and scale down the Auto Scaling group.
```

정답 : `B`

- 대상 추적 정책(Target Tracking Policy)은 오토 스케일링 그룹이 지정한 메트릭(이 경우 CPU 사용률)을 기준으로 자동으로 인스턴스 수를 조정
- 애플리케이션이 CPU 사용륭 40% 근처에서 최적의 성능을 낸다고 명시되어 있으믈, 오토 스케일링 그룹을 이 목표값을 기준으로 자동 조정하면 모든 인스턴스가 원하는 성능 유지 가능

오답 이유

- A: 단순 스케일링 정책(Simple Scaling Policy)은 특정 임계값을 초과할 때만 동작하며, 목표 CPU 사용률 근처를 지속적으로 유지하는 데 적합하지 않습니다.
- C: Lambda로 원하는 용량을 업데이트하는 방식은 수동 트리거 방식에 가까워 실시간 자동 조정이 어렵고 운영 오버헤드가 증가합니다.
- D: 예약된 스케일링(Scheduled Scaling)은 시간 기반으로만 스케일링되므로, 트래픽 변화에 따른 실시간 CPU 사용률 조정에는 적합하지 않습니다.


## #131
한 회사가 Amazon S3 버킷을 스토리지로 사용할 파일 공유 애플리케이션을 개발하고 있습니다. 회사는 모든 파일을 Amazon CloudFront 배포를 통해 제공하려고 합니다. 또한 회사는 S3 URL로 직접 접근하여 파일에 접근할 수 없도록 하기를 원합니다.  
솔루션 설계자가 이러한 요구 사항을 충족하려면 무엇을 해야 합니까?

A. 각 S3 버킷에 대해 개별 정책을 작성하여 CloudFront 접근만 읽기 권한을 부여합니다. 

B. IAM 사용자를 생성합니다. 해당 사용자에게 S3 버킷의 객체에 대한 읽기 권한을 부여합니다. CloudFront에 사용자를 할당합니다.  

C. CloudFront 배포 ID를 Principal로, 대상 S3 버킷을 ARN으로 지정하는 S3 버킷 정책을 작성합니다.  

D. 원본 액세스 ID(OAI)를 생성합니다. OAI를 CloudFront 배포에 할당합니다. S3 버킷 권한을 구성하여 오직 OAI만 읽기 권한을 가지도록 합니다.

```
A company is developing a file-sharing application that will use an Amazon S3 bucket for storage. The company wants to serve all the files through an Amazon CloudFront distribution. The company does not want the files to be accessible through direct navigation to the S3 URL.  
What should a solutions architect do to meet these requirements?

- A. Write individual policies for each S3 bucket to grant read permission for only CloudFront access.
- B. Create an IAM user. Grant the user read permission to objects in the S3 bucket. Assign the user to CloudFront.
- C. Write an S3 bucket policy that assigns the CloudFront distribution ID as the Principal and assigns the target S3 bucket as the Amazon Resource Name (ARN).
- D. Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission.
```

정답 : `D`

- CloudFront를 통해서만 파일을 제공하고 S3 URL 직접 접근을 차단하려면 Origin Access Identity(OAI)를 사용하는 것이 정석적인 방법
- OAI를 CloudFront 배포에 연결하면, 해당 OAI만 S3 객체에 접근할 수 있고, 사용자는 반드시 CloudFront를 통해서만 파일에 접근할 수 있음
- 이 방법은 S3 URL을 통한 직접 접근을 원천적으로 차단하면서, CloudFront의 캐싱 및 보안 기능을 활용 가능

OAI(Origin Access Identity)
- CloudFront가 S3 버킷에 접근할 때 사용하는 가상의 IAM 사용자. S3
- S3 버킷 정책에서 오직 OAI만 접근 가능하도록 설정하면 S3 URL 직접 접근을 차단할 수 있음

오답 이유

- A: “각 S3 버킷에 개별 정책 작성”은 CloudFront 전용 권한을 주는 방식이지만, OAI 같은 인증 주체를 지정하지 않으면 여전히 S3 URL 직접 접근이 가능할 수 있습니다.
    
- B: IAM 사용자를 CloudFront에 직접 할당할 수는 없습니다. CloudFront는 IAM 사용자 개념을 사용하지 않습니다.
    
- C: CloudFront 배포 ID는 IAM Principal로 사용할 수 없습니다. 대신 OAI 또는 OAC(Origin Access Control)를 사용해야 합니다.


## #132
한 회사의 웹사이트는 사용자에게 다운로드 가능한 과거 성능 보고서를 제공합니다. 이 웹사이트는 전 세계적인 수요를 충족하도록 확장 가능한 솔루션이 필요합니다. 솔루션은 비용 효율적이어야 하고 인프라 리소스의 프로비저닝을 제한해야 하며 가능한 가장 빠른 응답 시간을 제공해야 합니다.  
어떤 조합을 솔루션 설계자가 권장해야 이 요구사항을 충족합니까?

A. Amazon CloudFront 및 Amazon S3  
B. AWS Lambda 및 Amazon DynamoDB  
C. Application Load Balancer와 Amazon EC2 Auto Scaling  
D. Amazon Route 53과 내부 Application Load Balancers

```
A company’s website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company’s website demands globally. The solution should be cost-effective, limit the provisioning of infrastructure resources, and provide the fastest possible response time.  
Which combination should a solutions architect recommend to meet these requirements?

- A. Amazon CloudFront and Amazon S3
- B. AWS Lambda and Amazon DynamoDB
- C. Application Load Balancer with Amazon EC2 Auto Scaling
- D. Amazon Route 53 with internal Application Load Balancers
```

정답 : `A`

- Amazon S3에 정적 보고서 파일(예: PDF, CSV 등)을 저장하면 내구성과 화갖ㅇ성이 매우 높고 관리해야할 서버가 거의 없음
- CloudFront를 S3 오리진으로 구성하면 전 세계 엣지 로케이션에서 콘텐츠를 캐시하여 사용자에게 매우 낮은 지연 시간(가장 빠른 응답)을 제공. 또한 오리진의 부하를 크게 줄여 S3 비용/요청 부담도 완화

오답 이유

- **B. AWS Lambda 및 Amazon DynamoDB**
    - Lambda + DynamoDB는 서버리스로 관리 부담은 적지만, 다운로드용 대용량 정적 파일을 저장·전송하는 목적에는 부적합합니다. DynamoDB는 객체 스토리지로 설계되지 않았고 파일 전달 성능/비용 측면에서 비효율적입니다. 또 Lambda는 요청당 실행 비용·시간 한계가 있어 대용량 파일 제공엔 적절하지 않습니다.
    
- **C. Application Load Balancer와 Amazon EC2 Auto Scaling**
    - EC2 기반으로 파일을 서빙하면 직접 서버를 프로비저닝·운영해야 하므로 **인프라 관리 부담**과 비용이 크게 늘어납니다. 글로벌 사용자에게 낮은 지연을 주려면 여러 리전에 인스턴스/ALB를 배포해야 하며 복잡성과 비용이 증가합니다. 캐싱 계층(CloudFront)이 없으면 엣지 응답속도도 떨어집니다.
    
- **D. Amazon Route 53과 내부 Application Load Balancers**    
    - Route 53 + 내부 ALB 조합은 내부 라우팅 또는 리전 간 트래픽 분배 용도로만 적절하고, 전 세계 사용자에게 빠르게 정적 파일을 제공하기 위한 CDN 역할을 하지 못합니다. 또한 ‘내부’ ALB는 퍼블릭 다운로드 제공에 적합하지 않습니다.


## #133
한 회사는 온프레미스에서 Oracle 데이터베이스를 실행하고 있습니다. 회사의 AWS로의 마이그레이션의 일부로 회사는 데이터베이스를 사용 가능한 최신 버전으로 업그레이드하기를 원합니다. 회사는 또한 데이터베이스에 대한 재해 복구(DR)를 설정하기를 원합니다. 회사는 정상 운영과 DR 설정에 대한 운영 오버헤드를 최소화해야 합니다. 회사는 또한 데이터베이스의 기본 운영체제에 대한 접근을 유지해야 합니다.

어떤 솔루션이 이러한 요구사항을 충족합니까?

A. Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션합니다. 다른 AWS 리전으로 데이터베이스 복제를 설정합니다.  

B. Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션합니다. 자동화된 교차 리전 백업(Cross-Region automated backups)을 활성화하여 스냅샷을 다른 AWS 리전으로 복제합니다.  

C. Oracle 데이터베이스를 Amazon RDS Custom for Oracle로 마이그레이션합니다. 해당 데이터베이스에 대해 다른 AWS 리전에 리드 리플리카(read replica)를 생성합니다.  

D. Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션합니다. 다른 가용 영역(Availability Zone)에 대기(standby) 데이터베이스를 생성합니다.

```
A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system.  
Which solution will meet these requirements?

- A. Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region.
- B. Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region.
- C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.
- D. Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone.
```

정답 : `C`

- 요구사항
	- 최신 버전으로 업그레이드
	- DR(다른 리전) 구성
	- 정상 운영 및 DR 설정에서 운영 오버헤드 최소화
	- 데이터베이스 호스트의 기본 운영체제(OS)에 대한 접근 유지
- Amazon RDS for Oracle (표준)은 운영 부담을 줄여주지만 기본 운영체제에 대한 접근을 제공하지 않음
- EC2로의 마이그레이션(A)은 OS 접근을 완전히 제공하지만, 데이터베이스 패치, 백업, 복구, 모니터링, 고가용성/페일오버 구성 등 운영 오버헤드가 큼
- RDS Custom for Oracle은 RDS의 관리형 편의성(백업, 모니터링, 자동 패치 옵션 등)을 제공하면서 동시에 운영체제 수준의 접근(예: 운영 체제에서 실행되는 사용자 정의 도구 설치 및 실행, 특정 네이티브 구성 등)을 허용
- RDS Custom은 표준 RDS 기능과 통합되어 리전 간 복제(리드 레플리카) 또는 네이티브 복제 메커니즘을 통해 DR 시나리오를 구성할 수 있음
	- DR을 위해 RDS Custom 인스턴스의 리드 레플리카를 다른 리전에 생성하는 방법이 운영 부담을 줄이면서도 복구 목표 달성 가능

오답 이유

- **A. EC2로 마이그레이션하고 리전 간 복제 구성** — _불적합의 이유:_
    - 장점: 운영체제에 대한 완전한 접근 권한을 제공하므로 OS 수준 커스터마이제이션 및 네이티브 도구 사용 가능.
        
    - 단점: 데이터베이스 소프트웨어 패치, 백업/복구, 모니터링, 고가용성(페일오버) 구성, 용량 계획 등 모든 운영을 직접 관리해야 하므로 **운영 오버헤드가 매우 큼**. 질문에서 운영 오버헤드를 **최소화**하라는 요구와 충돌.
    
- **B. Amazon RDS for Oracle + 교차 리전 자동 백업 활성화** — _불적합의 이유:_    
    - 장점: RDS 표준은 관리형 기능(백업, 패치 옵션, 모니터링 등)을 제공하여 운영 burden이 적음. 교차 리전 자동 백업은 스냅샷을 다른 리전으로 복제하여 DR을 준비하는 데 도움.
        
    - 단점: RDS 표준은 **기본 운영체제에 대한 접근을 제공하지 않음**. 문제에서 OS 접근을 유지해야 하므로 요구사항 충족 불가.

- **D. Amazon RDS for Oracle + AZ 내 스탠바이(멀티-AZ)** — _불적합의 이유:_
    - 장점: Multi-AZ 스탠바이는 자동 페일오버로 가용성(내결함성)을 제공해 운영 편의성을 높임.
        
    - 단점: Multi-AZ는 같은 리전 내 고가용성(가용영역 장애 대비) 솔루션이며, **교차 리전 DR(리전 장애 대비)** 요건을 충족하려면 추가 복제/백업 설정이 필요. 또한 RDS 표준은 **운영체제 접근을 제공하지 않음**. 따라서 OS 접근 요구를 충족하지 못함.


## #134
한 회사는 애플리케이션을 서버리스 솔루션으로 전환하려고 합니다. 서버리스 솔루션은 기존 및 신규 데이터를 SQL로 분석할 수 있어야 합니다. 회사는 데이터를 Amazon S3 버킷에 저장합니다. 데이터는 암호화되어야 하고 다른 AWS 리전으로 복제되어야 합니다.  
다음 중 최소한의 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?

A. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)를 사용한 서버측 암호화(SSE-KMS)를 사용합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.  

B. 새 S3 버킷을 생성합니다. 데이터를 새 S3 버킷에 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)를 사용한 서버측 암호화(SSE-KMS)를 사용합니다. Amazon RDS를 사용하여 데이터를 쿼리합니다.  

C. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)를 사용한 서버측 암호화(SSE-S3)를 사용합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다.  

D. 기존 S3 버킷에 데이터를 로드합니다. S3 교차 리전 복제(CRR)를 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. Amazon S3 관리형 암호화 키(SSE-S3)를 사용한 서버측 암호화(SSE-S3)를 사용합니다. Amazon RDS를 사용하여 데이터를 쿼리합니다.

```
A company wants to move its application to a serverless solution. The serverless solution needs to analyze existing and new data by using SL. The company stores the data in an Amazon S3 bucket. The data requires encryption and must be replicated to a different AWS Region.  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region kays (SSE-KMS). Use Amazon Athena to query the data.
- B. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data.
- C. Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon Athena to query the data.
- D. Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon RDS to query the data.

```

정답 : `A`

- S3(오브젝트 저장) + Athena(S3 데이터 대상의 서버리스 SQL 쿼리 서비스) 조합은 완전히 서버리스이며, 운영(서버 패치, 스케일링 등) 부담이 거의 없음
- Athena는 S3의 데이터를 직접 SQL로 쿼리하므로 요구된 분석 방식과 정확히 일치
- S3 CRR은 객체를 한 리전에서 다른 리전으로 자동으로 복제
- SSE-KMS 다중리전키를 사용하면 KMS로 암호화된 객체를 리전 간에 복제할 때 키 관리 문제를 줄여줌

오답 이유

- **B (SSE-KMS + RDS)**
    - RDS는 관리형 DB 서비스지만 S3에 저장된 대규모 객체(특히 파일 레이크 성격)를 SQL로 쿼리하려면 데이터를 RDS로 ETL/로드해야 한다. 이는 추가적인 운영(데이터 로드·스키마 관리·관리형 데이터베이스 비용 등)과 복잡성을 초래한다. 또한 요구한 “서버리스로 분석” 관점에서 Athena를 쓰는 A보다 오버헤드가 크다.
    
- **C (SSE-S3 + Athena, 기존 버킷 사용)**
    - SSE-S3는 관리가 쉬워 운영 오버헤드가 더 적지만, **S3-CRR와의 보안·키 요건에서 일부 제약**이 있을 수 있다(예: SSE-KMS로 암호화한 객체는 KMS 키를 리전별로 준비해야 하고, 다중 리전 키 사용이 권장되는 시나리오에서 KMS 기반 로깅과 접근 제어 등 감사 요건이 중요할 때 SSE-S3는 세밀한 키 제어/감사를 제공하지 못함).
        
    - 문제 문장은 “데이터는 암호화되어야 하고 복제되어야 한다” — 보안/감사 요구가 강할 가능성이 높으므로 **SSE-KMS(특히 다중 리전 CMK)**를 선택하는 것이 기업 규정 준수와 감사/접근 제어를 만족시키는 더 올바른 선택이다.
        
    - 또한 C는 “기존 버킷”을 쓴다고 하지만, 기존 버킷에 이미 암호화 방식이 다르면 CRR나 KMS 구성에서 추가 작업(재암호화, 대상 리전 키 구성 등)이 필요할 수 있어 오히려 운영 부담이 늘 수 있다.
    
- **D (SSE-S3 + RDS)**
    - C와 B의 단점을 조합한 형태로, RDS 사용으로 인해 서버리스 분석 요건(운영 오버헤드 최소화)에 부합하지 않음.


## #135
회사는 AWS에서 워크로드를 실행합니다. 회사는 외부 공급업체의 서비스에 연결해야 합니다. 그 서비스는 공급업체의 VPC에서 호스팅됩니다. 회사 보안팀에 따르면 연결은 비공개여야 하며 대상 서비스로만 제한되어야 합니다. 연결은 오직 회사의 VPC에서만 시작되어야 합니다.  
어떤 솔루션이 이러한 요구사항을 충족합니까?

A. 회사의 VPC와 공급업체의 VPC 사이에 VPC 피어링 연결을 생성합니다. 대상 서비스로 연결되도록 라우트 테이블을 업데이트합니다.  

B. 공급업체에 자체 VPC에 가상 사설 게이트웨이(virtual private gateway)를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 대상 서비스에 연결합니다.  

C. 회사 VPC의 퍼블릭 서브넷에 NAT 게이트웨이를 생성합니다. 대상 서비스로 연결되도록 라우트 테이블을 업데이트합니다.  

D. 공급업체에 대상 서비스에 대한 VPC 엔드포인트를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 대상 서비스에 연결합니다.

```
A company runs workloads on AWS. The company needs to connect to a service from an external provider. The service is hosted in the provider's VPC. According to the company’s security team, the connectivity must be private and must be restricted to the target service. The connection must be initiated only from the company’s VPC.  
Which solution will mast these requirements?

- A. Create a VPC peering connection between the company's VPC and the provider's VPC. Update the route table to connect to the target service.
- B. Ask the provider to create a virtual private gateway in its VPC. Use AWS PrivateLink to connect to the target service.
- C. Create a NAT gateway in a public subnet of the company’s VPUpdate the route table to connect to the target service.
- D. Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service.
```

정답 : `D`

- AWS PrivateLink(Interface VPC Endpoint)는 소비자 VPC(회사)가 공급업체가 제공하는 서비스에 대해 인터페이스 엔드포인트(ENI)를 생성하여, 트래픽을 AWS 네트워크 내에서 직접 서비스로 전달
	- 통신이 퍼블릭 인터넷을 경유하지 않고 AWS 네트워크로만 이루어지므로 비공개
	- 소비자는 특정 서비스(공급업체가 노출한 엔드포인트 서비스)에 대해서만 엔드포인트를 생성하므로 액세스가 서비스 수준으로 제한
	- 연결은 소비자 측에서 엔드포인트를 생성(회사의 VPC에서 요청 및 초기화)해야 하므로 회사 VPC에서만 시작되는 요건을 만족
- 공급업체 측에서는 Endpoint Service(보통 NLB 뒤에 서비스)를 설정해 회사가 그 서비스에 대해 PrivateLink로 연결할 수 있게 함

오답 이유

- **A. VPC 피어링**
    - VPC 피어링은 VPC 간 L3 라우팅을 통해 서브넷 간 임의 트래픽을 허용합니다. 피어링은 특정 서비스만 제한해서 연결하기 어렵고, 피어링으로 연결되면 양쪽 VPC에서 라우트로 상대 VPC의 서브넷을 접근할 수 있어 **접근 범위가 넓고 양방향**입니다. 또한 보안팀 요구처럼 “대상 서비스로만 제한”하고 “회사에서만 시작”하는 요구를 만족시키기 어렵습니다.
    
- **B. 공급업체가 가상 사설 게이트웨이(virtual private gateway)를 생성하고 PrivateLink 사용**
    - 가상 사설 게이트웨이(VGW)는 VPN/Direct Connect용 게이트웨이이며 PrivateLink와는 무관합니다. 문장 조합 자체가 기술적으로 일관되지 않으며, VGW가 PrivateLink를 대체하지 못합니다.
    
- **C. NAT 게이트웨이**
    - NAT 게이트웨이는 프라이빗 인스턴스가 인터넷으로 아웃바운드 접속할 때 사용하는 인터넷 경유 아웃바운드 장치입니다. 이 방식은 트래픽이 퍼블릭 인터넷(또는 NAT을 통한 인터넷 경유)으로 나갈 수 있으므로 **비공개 연결 요건을 충족하지 못합니다**. 또한 대상 서비스가 공급업체 VPC에 있는 경우 라우팅/보안상 적합하지 않습니다.


## #136
한 회사가 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다.  
온프레미스 데이터베이스는 마이그레이션 동안 온라인 상태를 유지하고 접근 가능해야 합니다.  
Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다.  

이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 작업 조합은 무엇입니까? (두 가지를 선택하세요.)

A. 지속적인 복제 작업을 생성한다.  
B. 온프레미스 데이터베이스의 데이터베이스 백업을 생성한다.  
C. AWS Database Migration Service (AWS DMS) 복제 서버를 생성한다.  
D. AWS Schema Conversion Tool (AWS SCT)을 사용하여 데이터베이스 스키마를 변환한다.  
E. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 생성하여 데이터베이스 동기화를 모니터링한다.

```
A company is migrating its on-premises PostgreSQL database to Amazon Aurora PostgreSQL. The on-premises database must remain online and accessible during the migration. The Aurora database must remain synchronized with the on-premises database.  
Which combination of actions must a solutions architect take to meet these requirements? (Choose two.)

- A. Create an ongoing replication task.
- B. Create a database backup of the on-premises database.
- C. Create an AWS Database Migration Service (AWS DMS) replication server.
- D. Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT).
- E. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization.
```

정답 : `A, C`

- 요구사항 : 온프레미스 PostgreSQL -> Aurora PostgreSQL 마이그레이션 중에도 실시간 동기화가 필요하다는 것
- AWS DMS를 사용해야 하며, 지속적인 복제(Ongoing replication)를 통해 데이터가 계속 동기화
- DMS를 사용하려면 복제 서버를 반드시 생성해야 함

오답 이유

- **B. 데이터베이스 백업 생성** → 백업은 한 번에 옮기는 경우에는 사용 가능하지만, 문제에서 요구하는 **실시간 동기화**를 지원하지 않음.
    
- **D. AWS SCT 스키마 변환** → 스키마 변환은 DB 엔진 간 마이그레이션(예: Oracle → PostgreSQL) 시 필요. 여기서는 **PostgreSQL → Aurora PostgreSQL** 이므로 동일 엔진이며 SCT 불필요.
    
- **E. EventBridge 규칙 생성** → 단순 모니터링일 뿐, 실시간 동기화 기능을 제공하지 않음. 문제 요구사항을 충족하지 못함.


## #137
한 회사는 각 비즈니스 유닛에 대해 전용 AWS 계정을 생성하기 위해 AWS Organizations를 사용하고 있습니다.  
각 비즈니스 유닛은 요청 시 독립적으로 자신의 계정을 관리할 수 있습니다.  
한 계정의 루트 사용자 이메일 주소로 전송된 알림을 루트 이메일 수신자가 놓쳤습니다.  
회사는 앞으로 이러한 알림이 놓치지 않도록 하고 싶습니다.  
향후 알림은 계정 관리자에게만 제한되어야 합니다.  

이 요구사항을 충족하는 솔루션은 무엇입니까?

A. 회사의 이메일 서버를 구성하여 AWS 계정 루트 사용자 이메일 주소로 전송된 알림 이메일 메시지를 조직의 모든 사용자에게 전달한다.  

B. 모든 AWS 계정 루트 사용자 이메일 주소를 몇 명의 관리자가 알림에 응답할 수 있도록 하는 배포 그룹(distribution list)으로 구성한다.  
   AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS 계정 대체 연락처(alternate contacts)를 구성한다.  
   
C. 모든 AWS 계정 루트 사용자 이메일 메시지를 한 명의 관리자가 수신하도록 구성한다.  
   해당 관리자가 알림을 모니터링하고 적절한 그룹에 전달한다.  
   
D. 기존 모든 AWS 계정과 새로 생성된 모든 계정이 동일한 루트 사용자 이메일 주소를 사용하도록 구성한다.  
   AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS 계정 대체 연락처(alternate contacts)를 구성한다.  

```
A company uses AWS Organizations to create dedicated AWS accounts for each business unit to manage each business unit's account independently upon request. The root email recipient missed a notification that was sent to the root user email address of one account. The company wants to ensure that all future notifications are not missed. Future notifications must be limited to account administrators.  
Which solution will meet these requirements?

- A. Configure the company’s email server to forward notification email messages that are sent to the AWS account root user email address to all users in the organization.
- B. Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.
- C. Configure all AWS account root user email messages to be sent to one administrator who is responsible for monitoring alerts and forwarding those alerts to the appropriate groups.
- D. Configure all existing AWS accounts and all newly created accounts to use the same root user email address. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.
```

정답 : `B`

- AWS에서는 계정 루트 사용자 이메일은 반드시 존재해야 하며 삭제 불가
- AWS Organizations에서 Alternate Contacts (Builling, Operations, Security 연락처)를 설정할 수 있어 루트 이메일 대신 관리자들이 알림을 받도록 구성 가능
- 문제의 요구사항 -> 알림이 계정 관리자에게만 제한되어야 한다 이므로 조직 전체가 아닌, 특정 관리자 그룹이 받아야 함
- 따라서 루트 이메일을 distribution list로 관리 + Alternate Contacts를 통해 AWS가 직접 관리자에게 알림 전달하도록 구성

오답 이유

- **A. 모든 사용자에게 전달** → 보안 문제. 알림을 모든 조직 사용자에게 전달하면 관리자 한정 조건을 위반.
    
- **C. 한 명의 관리자만 설정** → SPOF(Single Point of Failure). 한 명이 놓치면 다시 알림 누락 가능.
    
- **D. 모든 계정이 동일한 루트 이메일 사용** → 모범 사례 위반. 각 계정은 별도 루트 이메일을 가져야 하며, 동일 이메일 사용은 보안 및 관리 위험 증가.


## #138
1. 문제 전체 한글 번역:

한 회사는 AWS에서 전자상거래 애플리케이션을 운영합니다.  
새 주문이 들어올 때마다 메시지는 단일 가용 영역의 Amazon EC2 인스턴스에서 실행되는 RabbitMQ 큐에 게시됩니다.  
이 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션이 처리합니다.  
이 애플리케이션은 PostgreSQL 데이터베이스(또 다른 EC2 인스턴스)에 세부 정보를 저장합니다.  
모든 EC2 인스턴스는 동일한 가용 영역에 있습니다.  

회사는 **운영 오버헤드를 최소화하면서 가장 높은 가용성**을 제공하도록 아키텍처를 재설계해야 합니다.  
이 요구사항을 충족하기 위해 솔루션 설계자가 해야 할 일은 무엇입니까?

A. 큐를 Amazon MQ의 활성/대기(액티브/스탠바이)로 이중화된 RabbitMQ 인스턴스 쌍으로 마이그레이션합니다. 애플리케이션을 호스트하는 EC2 인스턴스에 대해 Multi-AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스트하는 EC2 인스턴스에 대해 또 다른 Multi-AZ Auto Scaling 그룹을 생성합니다.  

B. 큐를 Amazon MQ의 활성/대기(액티브/스탠바이)로 이중화된 RabbitMQ 인스턴스 쌍으로 마이그레이션합니다. 애플리케이션을 호스트하는 EC2 인스턴스에 대해 Multi-AZ Auto Scaling 그룹을 생성합니다. 데이터베이스를 Amazon RDS for PostgreSQL의 Multi-AZ 배포로 마이그레이션합니다.  

C. 큐를 호스트하는 EC2 인스턴스에 대해 Multi-AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스트하는 EC2 인스턴스에 대해 또 다른 Multi-AZ Auto Scaling 그룹을 생성합니다. 데이터베이스를 Amazon RDS for PostgreSQL의 Multi-AZ 배포로 마이그레이션합니다.  

D. 큐를 호스트하는 EC2 인스턴스에 대해 Multi-AZ Auto Scaling 그룹을 생성합니다. 애플리케이션을 호스트하는 EC2 인스턴스에 대해 또 다른 Multi-AZ Auto Scaling 그룹을 생성합니다. PostgreSQL 데이터베이스를 호스트하는 EC2 인스턴스에 대해 세 번째 Multi-AZ Auto Scaling 그룹을 생성합니다.

```
A company runs its ecommerce application on AWS. Every new order is published as a massage in a RabbitMQ queue that runs on an Amazon EC2 instance in a single Availability Zone. These messages are processed by a different application that runs on a separate EC2 instance. This application stores the details in a PostgreSQL database on another EC2 instance. All the EC2 instances are in the same Availability Zone.  
The company needs to redesign its architecture to provide the highest availability with the least operational overhead.  
What should a solutions architect do to meet these requirements?

- A. Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Create another Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database.
- B. Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.
- C. Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.
- D. Create a Multi-AZ Auto Scaling group for EC2 instances that host the RabbitMQ queue. Create another Multi-AZ Auto Scaling group for EC2 instances that host the application. Create a third Multi-AZ Auto Scaling group for EC2 instances that host the PostgreSQL database
```

정답 : `B`

- Amazon MQ (관리형 RabbitMQ)
	- 관리형 브로커 서비스로서 가용영역에 걸친 active/standby 구성(또는 서비스에서 제공하는 HA)을 제공
	- 브로커 운영(패치, 패치 적용, 스케일링, 패치/백업 등)을 AWS에 위임하여 운영 부담을 크게 줄임
- 오토 스케일링 그룹(멀티 AZ)으로 애플리케이션 호스트
	- 소비자 애플리케이션은 상태 없는 처리 혹은 재시도 로직을 갖고 있으므로 여러 AZ에 걸쳐 오토스케일링을 구성하면 인스턴스 장애 시 자동 교체 및 확장으로 가용성 확보
- Amazon RDS for PostgreSQL (Multi-AZ)
	- 데이터 계층을 관리형 RDS Multi-AZ로 옮기면 자동 페일오버, 백업, 패치 일부 자동화 등을 통해 운영 오버헤드가 크게 줄면서도 데이터베이스 수준의 고가용성을 보장

오답 이유

- **A (DB를 EC2 Auto Scaling으로 운영)**
    - 브로커를 Amazon MQ로 옮긴 점은 적절하나 **PostgreSQL을 EC2에 Auto Scaling으로 운영**하면 데이터베이스의 상태 유지·동기화·스토리지 관리·백업·복제·복구 등을 직접 관리해야 하므로 운영 오버헤드가 큽니다. DB는 일반적으로 Auto Scaling으로 처리할 수 없고, 상태 저장 DB에는 관리형 Multi-AZ RDS가 더 적합합니다.
    
- **C (RabbitMQ를 EC2 Auto Scaling으로 운영)**
    - 큐를 EC2 기반의 RabbitMQ로 유지하면 브로커의 HA/패치/운영을 직접 해야 하므로 운영 오버헤드가 큽니다. Amazon MQ로 이전하는 편이 운영 부담을 줄일 수 있습니다.
    
- **D (모든 구성요소를 EC2 Auto Scaling으로 운영)**
    - 메시지 브로커와 DB까지 EC2 Auto Scaling에 맡기면 **운영 오버헤드가 가장 큼**. 또한 데이터베이스를 Auto Scaling으로 운영하는 것은 설계상 적절하지 않습니다(데이터 일관성/스토리지 문제).


## #139
보고 팀은 매일 Amazon S3 버킷에서 파일을 수신합니다. 보고 팀은 수작업으로 매일 같은 시간에 이 초기 S3 버킷에서 분석 S3 버킷으로 파일을 검토하고 복사하여 Amazon QuickSight와 함께 사용합니다. 추가 팀들이 초기 S3 버킷에 더 크고 많은 파일을 보내기 시작하고 있습니다.  
보고 팀은 파일이 초기 S3 버킷에 들어오면 자동으로 분석 S3 버킷으로 파일을 이동시키고 싶습니다. 보고 팀은 또한 복사된 데이터에서 패턴 매칭 코드를 실행하기 위해 AWS Lambda 함수를 사용하기를 원합니다. 추가로 보고 팀은 데이터 파일을 Amazon SageMaker Pipelines의 파이프라인으로 전송하길 원합니다.  
운영 오버헤드를 **최소화**하면서 이러한 요구사항을 충족하려면 솔루션 설계자는 무엇을 해야 합니까?

A. 파일을 분석 S3 버킷으로 복사하도록 Lambda 함수를 생성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker Pipelines를 구성합니다. 이벤트 유형으로 s3:ObjectCreated:Put을 구성합니다.  

B. 파일을 분석 S3 버킷으로 복사하도록 Lambda 함수를 생성합니다. 분석 S3 버킷이 Amazon EventBridge(Amazon CloudWatch Events)로 이벤트 알림을 보내도록 구성합니다. EventBridge(CloudWatch Events)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상에 Lambda 및 SageMaker Pipelines를 구성합니다.  

C. S3 버킷 간에 S3 복제를 구성합니다. 분석 S3 버킷에 대한 S3 이벤트 알림을 생성합니다. 이벤트 알림의 대상으로 Lambda 및 SageMaker Pipelines를 구성합니다. 이벤트 유형으로 s3:ObjectCreated:Put을 구성합니다.  

D. S3 버킷 간에 S3 복제를 구성합니다. 분석 S3 버킷이 Amazon EventBridge(Amazon CloudWatch Events)로 이벤트 알림을 보내도록 구성합니다. EventBridge(CloudWatch Events)에서 ObjectCreated 규칙을 구성합니다. 규칙의 대상에 Lambda 및 SageMaker Pipelines를 구성합니다.

```
A reporting team receives files each day in an Amazon S3 bucket. The reporting team manually reviews and copies the files from this initial S3 bucket to an analysis S3 bucket each day at the same time to use with Amazon QuickSight. Additional teams are starting to send more files in larger sizes to the initial S3 bucket.  
The reporting team wants to move the files automatically analysis S3 bucket as the files enter the initial S3 bucket. The reporting team also wants to use AWS Lambda functions to run pattern-matching code on the copied data. In addition, the reporting team wants to send the data files to a pipeline in Amazon SageMaker Pipelines.  
What should a solutions architect do to meet these requirements with the LEAST operational overhead?

- A. Create a Lambda function to copy the files to the analysis S3 bucket. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.
- B. Create a Lambda function to copy the files to the analysis S3 bucket. Configure the analysis S3 bucket to send event notifications to Amazon EventBridge (Amazon CloudWatch Events). Configure an ObjectCreated rule in EventBridge (CloudWatch Events). Configure Lambda and SageMaker Pipelines as targets for the rule.
- C. Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.
- D. Configure S3 replication between the S3 buckets. Configure the analysis S3 bucket to send event notifications to Amazon EventBridge (Amazon CloudWatch Events). Configure an ObjectCreated rule in EventBridge (CloudWatch Events). Configure Lambda and SageMaker Pipelines as targets for the rule.
```

정답 : `D`

- "S3 복제"는 관리형 기능으로, 초기 버킷에 객체가 업로드될 때 운영자가 작성한 코드 없이 AWS가 자동으로 분석 버킷으로 복사해줌 -> 람다로 직접 복사하는 방식보다 유지관리가 훨씬 편함
- 분석 버킷에서 EventBridge로 이벤트를 보낸 뒤, EventBridge 규칙의 대상으로 람다와 SageMaker Pipelines를 구성하면, 이벤트 기반으로 자동으로 처리가 연계
- EventBridge는 람다를 직접 대상으로 실행할 수 있고 AWS 서비스 호출을 규칙 대상으로 구성할 수 있어 SageMaker Pipelines 시작을 자동화 가능
- 결과적으로
	- 파일 복사는 AWS 관리형 기능으로 처리
	- -> 분석 버킷의 ObjectCreated 이벤트는 EventBridge로 라우팅
	- -> EventBrdige가 람다와 SageMaker 파이프라인 실행을 트리거
오답 이유

- **A (Lambda로 복사 + S3 이벤트 직접 Lambda/SageMaker 대상 구성)**
    - S3 이벤트 알림은 **Lambda, SQS, SNS, EventBridge** 등을 대상으로 보낼 수 있습니다(일반적 대상). 하지만 **S3 이벤트 알림에서 직접 SageMaker Pipelines를 대상**으로 지정하는 것은 지원되지 않습니다. 따라서 SageMaker를 직접 대상에 넣을 수 없고, Lambda로 복사 관리와 추가 로직(재시도, 오류 처리)을 유지해야 하므로 운영 부담이 커집니다.
    
- **B (Lambda로 복사 + EventBridge 규칙으로 Lambda 및 SageMaker 대상)**
    - 이 구성은 EventBridge를 사용해 SageMaker를 호출할 수 있으므로 기능적으로 가능하지만, **파일 복사를 Lambda가 담당**하므로 복사용 Lambda 함수의 운영(코드, 권한, 예외 처리)이 필요합니다. S3 복제를 사용하면 이 복사 관리를 AWS에 위임할 수 있어 운영 오버헤드가 더 작습니다.
    
- **C (S3 복제 + S3 이벤트 직접 Lambda/SageMaker 대상)**
    - S3 복제는 적절하지만, **S3 이벤트에서 SageMaker를 직접 대상**으로 지정할 수 없기 때문에 SageMaker 파이프라인 트리거링을 위해서는 EventBridge를 중간에 두어야 합니다. 따라서 C는 기술적으로 불완전/지원되지 않는 구성이 포함되어 있습니다.


## #140
솔루션 설계자는 회사가 AWS에서 애플리케이션을 실행하는 비용을 최적화하도록 도와야 합니다. 애플리케이션은 아키텍처 내에서 컴퓨트로 Amazon EC2 인스턴스, AWS Fargate 및 AWS Lambda를 사용합니다.  
EC2 인스턴스는 애플리케이션의 데이터 수집 레이어를 실행합니다. EC2 사용은 산발적이고 예측할 수 없습니다. EC2에서 실행되는 워크로드는 언제든지 중단될 수 있습니다. 애플리케이션 프런트 엔드는 Fargate에서 실행되며, Lambda는 API 계층을 제공합니다. 프런트 엔드 활용률과 API 계층 활용률은 향후 1년 동안 예측 가능합니다.  
이 애플리케이션을 호스팅하는 데 가장 비용 효율적인 조합의 구매 옵션은 무엇입니까? (두 가지 선택)

A. 데이터 수집 레이어에 Spot 인스턴스를 사용합니다.  
B. 데이터 수집 레이어에 온디맨드 인스턴스를 사용합니다.  
C. 프런트 엔드와 API 계층에 대해 1년 Compute Savings Plan을 구매합니다.  
D. 데이터 수집 레이어에 대해 1년 All Upfront 예약 인스턴스를 구매합니다.  
E. 프런트 엔드와 API 계층에 대해 1년 EC2 인스턴스 Savings Plan을 구매합니다.

```
A solutions architect needs to help a company optimize the cost of running an application on AWS. The application will use Amazon EC2 instances, AWS Fargate, and AWS Lambda for compute within the architecture.  
The EC2 instances will run the data ingestion layer of the application. EC2 usage will be sporadic and unpredictable. Workloads that run on EC2 instances can be interrupted at any time. The application front end will run on Fargate, and Lambda will serve the API layer. The front-end utilization and API layer utilization will be predictable over the course of the next year.  
Which combination of purchasing options will provide the MOST cost-effective solution for hosting this application? (Choose two.)

- A. Use Spot Instances for the data ingestion layer
- B. Use On-Demand Instances for the data ingestion layer
- C. Purchase a 1-year Compute Savings Plan for the front end and API layer.
- D. Purchase 1-year All Upfront Reserved instances for the data ingestion layer.
- E. Purchase a 1-year EC2 instance Savings Plan for the front end and API layer.
```

정답 : `A, C`

- A - Spot Instances for dta ingestion
	- 데이터 수집 레이어의 EC2 사용이 산발적이고 예측 불가능하며 워크로드가 언제든지 중단되어도 문제없음
	- 때문에 Spot 인스턴스의 장점(최대 절감율, 중단 가능)을 그대로 활용할 수 있는 이상적인 상황
	- Spot은 온디맨드 대비 매우 저렴하므로 비용 최적화에 가장 적합
- C - 1 year Copmute Savings Plan for front end and API layer
	- 프런트 엔드는 Fargate, API 계층은 람다로 실행되며 둘 다 향후 1년간 예층 가능
	- Compute Savings Plans는 EC2 뿐만 아니라 Fargate와 람다 사용량에도 적용되어(약정 사용량에 따라) 비용을 절감
		- 예측 가능한 사용량에 대해 1년 약정을 걸면 비용을 크게 낮출 수 있음
		- 참고로 EC2 인스턴스 Savings Plan은 EC2 전용이며 Fargate와 람다에는 적용되지 않음

오답 이유

- **B (On-Demand for data ingestion)**
    - 온디맨드는 유연하지만 Spot보다 비용이 높음. 워크로드가 중단 가능하고 사용량이 산발적이며 비용 최적화를 목표로 할 때 온디맨드는 최선의 선택이 아닙니다.
    
- **D (1-year All Upfront Reserved Instances for data ingestion)**
    - Reserved Instances는 장기·지속적이고 예측 가능한 용량에 적합합니다. 문제에서는 EC2 사용이 **산발적·예측 불가**하고 워크로드는 **중단 가능**하므로 RI(특히 All Upfront)는 자원 낭비 가능성이 큼.
    
- **E (1-year EC2 instance Savings Plan for front end and API layer)**
    - EC2 인스턴스 Savings Plan은 **EC2 전용** 약정으로, **Fargate와 Lambda에는 적용되지 않음**. 본 시나리오의 프런트 엔드(Fargate)와 API(Lambda)에 적용 가능한 것은 **Compute Savings Plan**이므로 E는 부적합.
