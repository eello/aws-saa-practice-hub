---
created: 2025-10-02 11:04:05
last_modified: 2025-10-02 14:14:10
---
## #261
회사는 최근 리테일 웹사이트를 전 세계 대상으로 배포한다고 발표했습니다. 웹사이트는 Elastic Load Balancer 뒤의 여러 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 걸친 Auto Scaling 그룹에서 실행됩니다.

회사는 고객이 웹사이트에 접근하는 데 사용하는 디바이스에 따라 서로 다른 버전의 콘텐츠를 제공하고자 합니다.

이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 작업의 조합은 무엇입니까? (두 개 선택)

A. Amazon CloudFront가 콘텐츠의 여러 버전을 캐시하도록 구성합니다.
B. Network Load Balancer에서 호스트 헤더를 구성하여 트래픽을 서로 다른 인스턴스로 포워딩합니다.
C. Lambda@Edge 함수를 구성하여 User-Agent 헤더에 따라 특정 오브젝트를 사용자에게 전송합니다.
D. AWS Global Accelerator를 구성합니다. 요청을 Network Load Balancer(NLB)로 포워딩합니다. NLB를 구성하여 서로 다른 EC2 인스턴스로 호스트 기반 라우팅을 설정합니다.
E. AWS Global Accelerator를 구성합니다. 요청을 Network Load Balancer(NLB)로 포워딩합니다. NLB를 구성하여 서로 다른 EC2 인스턴스로 경로 기반 라우팅을 설정합니다.

```
A company recently announced the deployment of its retail website to a global audience. The website runs on multiple Amazon EC2 instances behind an Elastic Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones.  
  
The company wants to provide its customers with different versions of content based on the devices that the customers use to access the website.  
  
Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)

- A. Configure Amazon CloudFront to cache multiple versions of the content.
- B. Configure a host header in a Network Load Balancer to forward traffic to different instances.
- C. Configure a Lambda@Edge function to send specific objects to users based on the User-Agent header.
- D. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up host-based routing to different EC2 instances.
- E. Configure AWS Global Accelerator. Forward requests to a Network Load Balancer (NLB). Configure the NLB to set up path-based routing to different EC2 instances.
```

정답 : `A, C`

- 디바이스(모바일/데스트콥 등)에 따라 다른 오브젝트를 캐시/서빙하려면 CloudFront의 캐시 키에 관련 헤더(User-Agent 등) 또는 쿠키/쿼리를 포함해 여러 버전을 캐시하도록 구성 가능
- Lambda@Edge(뷰어/오리진 요청 이벤트)를 사용하면 User-Agent 헤더를 검사해 경로 재작성/오브젝트 매핑으로 디바이스별 다른 오브젝트를 선택적으로 반환 가능

오답 이유

- **B. NLB에서 호스트 헤더 기반 라우팅**: **호스트/경로 기반 라우팅은 ALB 기능**입니다. NLB는 L4 로드 밸런서로 헤더 기반 라우팅을 지원하지 않습니다.
    
- **D/E. Global Accelerator + NLB 호스트/경로 라우팅**: Global Accelerator는 엣지에서 애니캐스트 가속을 제공하지만, **NLB가 호스트/경로 라우팅을 지원하지 않으므로** 요구(디바이스별 콘텐츠 분기)를 해결하지 못합니다. 또한 본 요구에 GA는 필수 아님.


## #262
한 회사가 다중 계층 웹 애플리케이션에 Amazon ElastiCache를 사용하려고 계획합니다. 솔루션스 아키텍트는 ElastiCache 클러스터용 Cache VPC와 애플리케이션의 Amazon EC2 인스턴스용 App VPC를 생성했습니다. 두 VPC는 us-east-1 리전에 있습니다.

솔루션스 아키텍트는 애플리케이션의 EC2 인스턴스가 ElastiCache 클러스터에 액세스할 수 있도록 하는 솔루션을 구현해야 합니다.

다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 두 VPC 사이에 피어링 연결을 생성합니다. 두 VPC의 라우트 테이블에 피어링 연결에 대한 경로 항목을 추가합니다. ElastiCache 클러스터의 보안 그룹에 인바운드 규칙을 구성하여 애플리케이션의 보안 그룹으로부터의 인바운드 연결을 허용합니다.
B. Transit VPC를 생성합니다. Cache VPC와 App VPC의 VPC 라우트 테이블을 업데이트하여 트래픽이 Transit VPC를 통해 라우팅되도록 합니다. ElastiCache 클러스터의 보안 그룹에 인바운드 규칙을 구성하여 애플리케이션의 보안 그룹으로부터의 인바운드 연결을 허용합니다.
C. 두 VPC 사이에 피어링 연결을 생성합니다. 두 VPC의 라우트 테이블에 피어링 연결에 대한 경로 항목을 추가합니다. 피어링 연결의 보안 그룹에 인바운드 규칙을 구성하여 애플리케이션의 보안 그룹으로부터의 인바운드 연결을 허용합니다.
D. Transit VPC를 생성합니다. Cache VPC와 App VPC의 VPC 라우트 테이블을 업데이트하여 트래픽이 Transit VPC를 통해 라우팅되도록 합니다. Transit VPC의 보안 그룹에 인바운드 규칙을 구성하여 애플리케이션의 보안 그룹으로부터의 인바운드 연결을 허용합니다.

```
A company plans to use Amazon ElastiCache for its multi-tier web application. A solutions architect creates a Cache VPC for the ElastiCache cluster and an App VPC for the application’s Amazon EC2 instances. Both VPCs are in the us-east-1 Region.  
  
The solutions architect must implement a solution to provide the application’s EC2 instances with access to the ElastiCache cluster.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the ElastiCache cluster’s security group to allow inbound connection from the application’s security group.
- B. Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route traffic through the Transit VPC. Configure an inbound rule for the ElastiCache cluster's security group to allow inbound connection from the application’s security group.
- C. Create a peering connection between the VPCs. Add a route table entry for the peering connection in both VPCs. Configure an inbound rule for the peering connection’s security group to allow inbound connection from the application’s security group.
- D. Create a Transit VPC. Update the VPC route tables in the Cache VPC and the App VPC to route traffic through the Transit VPC. Configure an inbound rule for the Transit VPC’s security group to allow inbound connection from the application’s security group.
```

정답 : `A`

- 동일 리전의 두 VPC 간 통신을 가장 단순하고 저비용으로 연결하는 방법은 VPC 피어링
- 피어링 후 양쪽 라우트 테이블에 상대 VPC CIDR로 가는 경로를 추가
- ElastiCache 클러스터가 속한 보안 그룹에 애플리케이션 EC2 인스턴스의 보안 그룹을 소스로 허용하면
- 사설 IP로 안전하게 접근 가능 → 추가 요금(전송 요금 제외)과 운영 오버헤드가 매우 낮음

오답 이유

- **B. Transit VPC**
    - 별도 허브 VPC(가상 어플라이언스 등) 운영이 필요해 **복잡하고 비용↑**. 두 VPC만 연결하는 단순 케이스에서는 VPC 피어링이 더 **비용 효율적**입니다. (현행 모범 사례는 Transit **Gateway**이지, Transit **VPC**는 레거시 패턴)
    
- **C. 피어링 연결의 보안 그룹**
    - **피어링 연결에는 보안 그룹이 없습니다.** 보안 그룹은 ENI/리소스에 붙습니다. 허용 규칙은 **ElastiCache 보안 그룹**에 설정해야 합니다.
    
- **D. Transit VPC + Transit VPC의 보안 그룹**
    - 위와 같은 이유로 **과도한 아키텍처**이며, 트래픽 제어는 최종 리소스 보안 그룹에서 수행되어야 합니다.



## #263
한 회사가 여러 마이크로서비스로 구성된 애플리케이션을 구축하고 있습니다. 회사는 AWS에서 소프트웨어를 배포하기 위해 컨테이너 기술을 사용하기로 결정했습니다. 회사는 유지보수와 스케일링에 대한 지속적인 노력을 최소화하는 솔루션이 필요합니다. 회사는 추가 인프라를 관리할 수 없습니다.

이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 작업의 조합은 무엇입니까? (두 개 선택)

A. Amazon Elastic Container Service (Amazon ECS) 클러스터를 배포합니다.
B. 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 Kubernetes 컨트롤 플레인을 배포합니다.
C. Amazon EC2 런치 타입으로 Amazon ECS 서비스를 배포합니다. 원하는 작업 수(desired task number)를 2 이상으로 지정합니다.
D. Fargate 런치 타입으로 Amazon ECS 서비스를 배포합니다. 원하는 작업 수(desired task number)를 2 이상으로 지정합니다.
E. 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 Kubernetes 워커 노드를 배포합니다. 각 마이크로서비스에 대해 두 개 이상의 복제본을 지정하는 디플로이먼트를 생성합니다.

```
A company is building an application that consists of several microservices. The company has decided to use container technologies to deploy its software on AWS. The company needs a solution that minimizes the amount of ongoing effort for maintenance and scaling. The company cannot manage additional infrastructure.  
  
Which combination of actions should a solutions architect take to meet these requirements? (Choose two.)

- A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster.
- B. Deploy the Kubernetes control plane on Amazon EC2 instances that span multiple Availability Zones.
- C. Deploy an Amazon Elastic Container Service (Amazon ECS) service with an Amazon EC2 launch type. Specify a desired task number level of greater than or equal to 2.
- D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.
- E. Deploy Kubernetes worker nodes on Amazon EC2 instances that span multiple Availability Zones. Create a deployment that specifies two or more replicas for each microservice.
```

정답 : `A, D`

- ECS Fargate 런치 타입 : 서버리스 컨테이너 실행으로 EC2 인스턴스/노드 관리 없이 배포･스케일링 가능
	- 자동 확장/패치 부담이 적어 운영 오버헤드 최소화, 원하는 작업 수를 2 이상으로 설정해 가용성 확보
- ECS 클러스터 생성 : Fargate를 사용하더라도 논리적 ECS 클러스터 필요. 서비스와 태스크를 이 클러스터에 배치

오답 이유

- **B, E (EKS/자체 Kubernetes 컨트롤 플레인·워커 노드)**: EC2 기반 노드 및 컨트롤 플레인/애드온 관리가 필요하여 **추가 인프라 관리 불가** 요건과 상충.
    
- **C (ECS EC2 런치 타입)**: 컨테이너 호스트인 **EC2 인스턴스 관리(용량/패치/스케일링)** 가 필요 → 운영 오버헤드 증가.


## #264
한 회사가 10개의 Amazon EC2 인스턴스에 웹 애플리케이션을 호스팅하고 있으며, 트래픽은 Amazon Route 53을 통해 라우팅됩니다. 회사는 가끔 애플리케이션을 탐색하려고 할 때 타임아웃 오류를 경험합니다. 네트워킹 팀은 일부 DNS 쿼리가 비정상 인스턴스의 IP 주소를 반환하여 타임아웃 오류가 발생한다는 사실을 발견했습니다.

솔루션스 아키텍트는 이러한 타임아웃 오류를 극복하기 위해 무엇을 구현해야 합니까?

A. 각 EC2 인스턴스에 대해 Route 53 단순(Simple) 라우팅 정책 레코드를 생성합니다. 각 레코드에 헬스 체크를 연결합니다.  
B. 각 EC2 인스턴스에 대해 Route 53 장애 조치(Failover) 라우팅 정책 레코드를 생성합니다. 각 레코드에 헬스 체크를 연결합니다.  
C. EC2 인스턴스를 오리진으로 하는 Amazon CloudFront 배포를 생성합니다. EC2 인스턴스에 헬스 체크를 연결합니다.  
D. EC2 인스턴스 앞에 헬스 체크가 있는 Application Load Balancer(ALB)를 생성합니다. Route 53에서 ALB로 라우팅합니다.  

```
A company has a web application hosted over 10 Amazon EC2 instances with traffic directed by Amazon Route 53. The company occasionally experiences a timeout error when attempting to browse the application. The networking team finds that some DNS queries return IP addresses of unhealthy instances, resulting in the timeout error.  
  
What should a solutions architect implement to overcome these timeout errors?

- A. Create a Route 53 simple routing policy record for each EC2 instance. Associate a health check with each record.
- B. Create a Route 53 failover routing policy record for each EC2 instance. Associate a health check with each record.
- C. Create an Amazon CloudFront distribution with EC2 instances as its origin. Associate a health check with the EC2 instances.
- D. Create an Application Load Balancer (ALB) with a health check in front of the EC2 instances. Route to the ALB from Route 53.
```

정답 : `D`

- ALB는 EC2 인스턴스 그룹의 상태를 지속적으로 헬스 체크
- 비정상 인스턴스는 자동으로 트래픽 대상에서 제외 → Route 53은 항상 ALB의 DNS 이름을 반환 → 트래픽은 정상 인스턴스에만 도달

오답 이유

- **A. Simple Routing + 헬스 체크**
    - Simple routing은 **헬스 체크와 함께 사용 불가**합니다. 레코드가 여러 개일 경우 단순 라운드 로빈이므로 비정상 인스턴스로도 트래픽을 보낼 수 있음.
    
- **B. Failover Routing + 헬스 체크**
    - Failover 정책은 기본(primary)과 보조(secondary) 리소스 쌍으로만 동작합니다. 10개의 인스턴스와 같이 다수 대상 로드 밸런싱에는 적합하지 않습니다.
    
- **C. CloudFront**
    - CloudFront는 캐싱/글로벌 전송 최적화 서비스이지, 다수의 EC2 인스턴스 상태를 직접 헬스 체크하여 트래픽을 분배하지 않습니다. 오리진 상태 확인 기능도 제한적임


## #265
솔루션스 아키텍트는 웹, 애플리케이션, 데이터베이스 계층으로 구성된 고가용성 애플리케이션을 설계해야 합니다. HTTPS 콘텐츠는 가능한 한 엣지(Edge)에 가깝게, 최소한의 전송 시간으로 제공되어야 합니다.

다음 중 이러한 요구 사항을 충족하며 가장 보안성이 높은 솔루션은 무엇입니까?

A. 퍼블릭 서브넷의 다중 Amazon EC2 인스턴스와 함께 퍼블릭 Application Load Balancer(ALB)를 구성합니다. 퍼블릭 ALB를 오리진으로 사용하여 Amazon CloudFront가 HTTPS 콘텐츠를 제공하도록 구성합니다.  
B. 프라이빗 서브넷의 다중 Amazon EC2 인스턴스와 함께 퍼블릭 Application Load Balancer를 구성합니다. EC2 인스턴스를 오리진으로 사용하여 Amazon CloudFront가 HTTPS 콘텐츠를 제공하도록 구성합니다.  
C. 프라이빗 서브넷의 다중 Amazon EC2 인스턴스와 함께 퍼블릭 Application Load Balancer(ALB)를 구성합니다. 퍼블릭 ALB를 오리진으로 사용하여 Amazon CloudFront가 HTTPS 콘텐츠를 제공하도록 구성합니다.  
D. 퍼블릭 서브넷의 다중 Amazon EC2 인스턴스와 함께 퍼블릭 Application Load Balancer를 구성합니다. EC2 인스턴스를 오리진으로 사용하여 Amazon CloudFront가 HTTPS 콘텐츠를 제공하도록 구성합니다.  

```
A solutions architect needs to design a highly available application consisting of web, application, and database tiers. HTTPS content delivery should be as close to the edge as possible, with the least delivery time.  
  
Which solution meets these requirements and is MOST secure?

- A. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.
- B. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.
- C. Configure a public Application Load Balancer (ALB) with multiple redundant Amazon EC2 instances in private subnets. Configure Amazon CloudFront to deliver HTTPS content using the public ALB as the origin.
- D. Configure a public Application Load Balancer with multiple redundant Amazon EC2 instances in public subnets. Configure Amazon CloudFront to deliver HTTPS content using the EC2 instances as the origin.
```

정답 : `C`

- Amazon CloudFront는 전 세계 엣지 로케이션에서 HTTPS 트래픽을 종단하고 캐시하기 때문에 사용자와 가장 가까운 위치에서 콘텐츠 전달
- 보안 최적 배치
	- EC2 인스턴스는 프라이빗 서브넷에 두어 외부에서 직접 접근 X
	- 외부에는 퍼블릭 ALB만 두고, ALB가 트래픽을 프라이빗 인스턴스에 전달
- CloudFront는 퍼블릭 엔드포인트(ALB의 DNS 이름)를 오리진으로 지정해야 하므로 퍼블릭 ALB 필요

오답 이유

- **A**: CloudFront 오리진으로 퍼블릭 ALB를 사용하는 것은 맞지만, 인스턴스를 퍼블릭 서브넷에 두면 직접 노출되어 공격 위험이 증가합니다.
    
- **B**: 인스턴스가 프라이빗 서브넷에 있는 것은 좋지만, CloudFront 오리진을 EC2 인스턴스로 직접 지정할 수 없습니다. 퍼블릭 ALB가 필요합니다.
    
- **D**: 인스턴스를 퍼블릭 서브넷에 두고 EC2 자체를 오리진으로 쓰는 것은 보안상 최악의 선택입니다.


## #266
한 회사가 AWS에서 인기 있는 게임 플랫폼을 운영하고 있습니다. 이 애플리케이션은 지연 시간(latency)에 매우 민감한데, 지연은 사용자 경험에 영향을 주고 일부 플레이어에게 불공정한 이점을 줄 수 있습니다. 애플리케이션은 모든 AWS 리전에 배포되어 있습니다. 각 리전에서 Application Load Balancer(ALB) 뒤에 구성된 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 솔루션스 아키텍트는 애플리케이션의 상태를 모니터링하고 트래픽을 정상 엔드포인트로 리다이렉트하는 메커니즘을 구현해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. AWS Global Accelerator에서 가속기를 구성합니다. 애플리케이션이 수신 대기하는 포트에 대한 리스너를 추가하고, 각 리전의 리전 엔드포인트에 연결합니다. 엔드포인트로 ALB를 추가합니다.
B. Amazon CloudFront 배포를 생성하고 오리진 서버로 ALB를 지정합니다. 캐시 동작을 오리진 캐시 헤더를 사용하도록 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화합니다.
C. Amazon CloudFront 배포를 생성하고 오리진 서버로 Amazon S3를 지정합니다. 캐시 동작을 오리진 캐시 헤더를 사용하도록 구성합니다. AWS Lambda 함수를 사용하여 트래픽을 최적화합니다.
D. 애플리케이션의 데이터 저장소로 Amazon DynamoDB를 구성합니다. 애플리케이션 데이터를 호스팅하는 DynamoDB에 대한 인메모리 캐시로 작동하도록 DynamoDB Accelerator(DAX) 클러스터를 생성합니다.

```
A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region. It runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect traffic to healthy endpoints.  
  
Which solution meets these requirements?

- A. Configure an accelerator in AWS Global Accelerator. Add a listener for the port that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint.
- B. Create an Amazon CloudFront distribution and specify the ALB as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.
- C. Create an Amazon CloudFront distribution and specify Amazon S3 as the origin server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic.
- D. Configure an Amazon DynamoDB database to serve as the data store for the application. Create a DynamoDB Accelerator (DAX) cluster to act as the in-memory cache for DynamoDB hosting the application data.
```

정답 : `A`

- 글로벌 헬스 체크 & 자동 페일오버: Global Accelerator는 각 리전 엔드포인트(ALB/EC2/NLB 등)의 상태를 지속적으로 모니터링하고 비정상 시 자동으로 가장 가까운 정상 엔드포인트로 트래픽을 우회
- 지연 최소화: 전 세계 Anycast 고정 IP를 통해 가장 가까운 엣지 PoP로 인입 후 AWS 백본을 타고 리전으로 전달해 레이지가 낮고 예측 가능한 경로 제공
- 프로토콜 제약 적음: L4 수준(TCP/UDP) 트래픽도 지원하므로, 웹뿐 아니라 게임 트래픽 패턴에도 적합

오답 이유

- **B. CloudFront + ALB 오리진**: CloudFront는 **HTTP/HTTPS 콘텐츠 캐시/전달**에 최적화되어 있으며, 애플리케이션 레벨 캐싱이 어려운 실시간 게임 트래픽이나 **비HTTP** 트래픽에는 부적합합니다. 글로벌 헬스 기반 리전 우회도 GA만큼 세밀하지 않습니다.
    
- **C. CloudFront + S3 오리진**: 정적 콘텐츠 전송용으로, 동적 게임 세션 라우팅/헬스 기반 리다이렉트 요구와 무관합니다.
    
- **D. DynamoDB + DAX**: 데이터 지연을 줄이는 캐시 구성일 뿐, **엔드포인트 헬스 모니터링**이나 **글로벌 트래픽 라우팅/우회**와는 관련이 없습니다.


## #267
한 회사에는 백만 명의 사용자가 사용하는 모바일 앱이 있습니다. 회사는 데이터 사용량을 거의 실시간(near-real time)으로 분석해야 합니다. 또한 데이터를 거의 실시간으로 암호화해야 하며, 이후 처리를 위해 중앙 위치에 Apache Parquet 형식으로 데이터를 저장해야 합니다.

다음 중 운영 오버헤드가 가장 적은 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon Kinesis 데이터 스트림을 생성하여 데이터를 Amazon S3에 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 데이터를 Kinesis Data Analytics 애플리케이션으로 보냅니다.
B. Amazon Kinesis 데이터 스트림을 생성하여 데이터를 Amazon S3에 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 데이터를 EMR 클러스터로 보냅니다.
C. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 데이터를 Amazon S3에 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다.
D. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 데이터를 Amazon S3에 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다.

```
A company has one million users that use its mobile app. The company must analyze the data usage in near-real time. The company also must encrypt the data in near-real time and must store the data in a centralized location in Apache Parquet format for further processing.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data. Invoke an AWS Lambda function to send the data to the Kinesis Data Analytics application.
- B. Create an Amazon Kinesis data stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data. Invoke an AWS Lambda function to send the data to the EMR cluster.
- C. Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon EMR cluster to analyze the data.
- D. Create an Amazon Kinesis Data Firehose delivery stream to store the data in Amazon S3. Create an Amazon Kinesis Data Analytics application to analyze the data.
```

정답 : `D`

- 최소 운영 오버헤드: Kinesis Data Firehose와 Kinesis Data Analytics(KDA)는 완전관리형으로 클러스터 프로비저닝/패치/확장 관리 필요 없음
- 암호화 & 포맷 변환: Firehose는 서버측 암호화(SSE-S3/SSE-KMS)를 지원하고, 데이터 포뱃 변환(Parquet/ORC) 기능을 제공
	- S3에 Parquet로 중앙 저장 자동화 가능
- 실시간 분석: KDA(특히 SQL 애플리케이션)는 Kinesis Data Firehose/Streams로부터 스트리밍 입력을 받아 지연이 낮은 실시간 집계/필터링/변환을 수행 가능
- 확장성: 수백만 사용자 규모의 이벤트를 자동으로 버퍼링/압축/배치해 S3에 안정적을 적재

오답 이유

- **A. Kinesis Data Streams + KDA + Lambda로 전송**: 스트림 → S3 저장 로직이 빠져 있고, **KDA로 보내기 위해 Lambda를 호출**하는 구성은 불필요한 오케스트레이션과 운영 복잡도를 추가합니다. 또 Parquet 변환/암호화 자동화가 내장되지 않습니다.
    
- **B. Streams + EMR**: EMR 클러스터는 **운영/비용/확장 관리 오버헤드**가 큽니다. 요구는 “최소 운영 오버헤드”입니다.
    
- **C. Firehose + EMR**: Firehose로 적재는 적절하나, 분석을 위해 **EMR을 운영**하는 것은 불필요하게 무겁습니다. KDA가 더 가볍고 관리형입니다.


## #268
한 게임 회사가 점수를 표시하는 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon RDS for MySQL 데이터베이스에 데이터를 저장합니다. 사용자들은 데이터베이스 읽기 성능으로 인해 긴 지연과 중단을 겪기 시작했습니다. 회사는 애플리케이션 아키텍처 변경을 최소화하면서 사용자 경험을 개선하고자 합니다.

이 요구사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 데이터베이스 앞단에 Amazon ElastiCache를 사용합니다.
B. 애플리케이션과 데이터베이스 사이에 RDS Proxy를 사용합니다.
C. 애플리케이션을 EC2 인스턴스에서 AWS Lambda로 마이그레이션합니다.
D. 데이터베이스를 Amazon RDS for MySQL에서 Amazon DynamoDB로 마이그레이션합니다.

```
A gaming company has a web application that displays scores. The application runs on Amazon EC2 instances behind an Application Load Balancer. The application stores data in an Amazon RDS for MySQL database. Users are starting to experience long delays and interruptions that are caused by database read performance. The company wants to improve the user experience while minimizing changes to the application’s architecture.  
  
What should a solutions architect do to meet these requirements?

- A. Use Amazon ElastiCache in front of the database.
- B. Use RDS Proxy between the application and the database.
- C. Migrate the application from EC2 instances to AWS Lambda.
- D. Migrate the database from Amazon RDS for MySQL to Amazon DynamoDB.
```

정답 : `A`

- 읽기 트래픽으로 인한 지연 문제는 캐시 계층(ElastiCache for Redis/Memecached)를 두어 핫 데이터/자주 조회되는 점수를 메모리에 캐싱하면 즉시 완화
- 애플리케이션 코드에서 캐시 조회 → 미스 시 DB 조회 후 캐시에 적재하는 패턴만 추가
	- 아키텍처 변경을 최소화하면서 읽기 성능/지연을 크게 개선 가능

오답 이유

- **B. RDS Proxy**: 주로 **연결 풀링/버스트 제어/장애 조치 시 연결 유지**에 효과적이며, **순수 읽기 성능 향상**에는 직접적이지 않습니다.
    
- **C. Lambda로 마이그레이션**: 실행 환경을 바꿔도 **DB 읽기 병목 자체**는 해소되지 않으며, 변경 폭이 큼.
    
- **D. DynamoDB로 마이그레이션**: 데이터 모델/쿼리 패턴 대폭 변경이 필요하고, **“변경 최소화”** 요구와 상충합니다.


## #269
전자상거래 회사가 Amazon RDS 기반 웹 애플리케이션의 성능 저하를 확인했습니다. 성능 저하는 비즈니스 애널리스트가 트리거하는 읽기 전용 SQL 쿼리 수 증가로 인한 것입니다. 솔루션스 아키텍트는 기존 웹 애플리케이션에 최소한의 변경으로 문제를 해결해야 합니다.

솔루션스 아키텍트는 무엇을 권장해야 합니까?

A. 데이터를 Amazon DynamoDB로 내보내고 비즈니스 애널리스트가 해당 쿼리를 실행하도록 합니다.
B. 데이터를 Amazon ElastiCache에 적재하고 비즈니스 애널리스트가 해당 쿼리를 실행하도록 합니다.
C. 기본 데이터베이스의 읽기 복제본을 생성하고 비즈니스 애널리스트가 해당 쿼리를 실행하도록 합니다.
D. 데이터를 Amazon Redshift 클러스터로 복사하고 비즈니스 애널리스트가 해당 쿼리를 실행하도록 합니다.

```
An ecommerce company has noticed performance degradation of its Amazon RDS based web application. The performance degradation is attributed to an increase in the number of read-only SQL queries triggered by business analysts. A solutions architect needs to solve the problem with minimal changes to the existing web application.  
  
What should the solutions architect recommend?

- A. Export the data to Amazon DynamoDB and have the business analysts run their queries.
- B. Load the data into Amazon ElastiCache and have the business analysts run their queries.
- C. Create a read replica of the primary database and have the business analysts run their queries.
- D. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries.
```

정답 : `C`

- RDS 읽기 복제본은 기본(프라이머리) DB의 읽기 트래픽을 분산하기 위한 표준 해법
- 애플리케이션 변경 없이 읽기 전용 워크로드를 오프로딩할 수 있음
- 비즈니스 애널리스트의 읽기 전용 SQL 쿼리를 복제본으로 유도하면, 기본 DB의 리소스를 보호해 웹 애플리케이션의 성능 저하를 즉시 완화
- 관리형 복제(비동기)로 운영 오버헤드가 낮고, 필요 시 복제본을 수평 확장 할 수 있음

오답 이유

- **A. DynamoDB로 내보내기**: 스키마·쿼리 모델이 관계형과 상이하여 **애널리스트 쿼리/도구를 크게 변경**해야 하며, SQL 기반 분석에 부적합. “최소 변경” 요구와 불일치.
    
- **B. ElastiCache에 적재**: 인메모리 캐시는 **키-값/캐시 패턴**에 적합하며 임의의 **복잡한 SQL 쿼리** 실행 환경이 아님. 또한 캐시 동기화/적재 로직 등 **애플리케이션 변경이 큼**.
    
- **D. Redshift로 복사**: DW로의 ETL/스키마 변경/파이프라인 운영이 필요해 **운영 복잡도 증가**. 또한 실시간성·최소 변경 요건에 비해 과도한 솔루션.


## #270
한 회사가 중앙 집중식 AWS 계정을 사용하여 다양한 Amazon S3 버킷에 로그 데이터를 저장하고 있습니다. 솔루션스 아키텍트는 데이터가 S3 버킷에 업로드되기 전에 반드시 저장 시 암호화(at rest)가 적용되도록 해야 합니다. 또한 데이터는 전송 중(in transit)에도 암호화되어야 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 클라이언트 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다.  
B. 서버 측 암호화를 사용하여 S3 버킷에 업로드되는 데이터를 암호화합니다.  
C. S3 업로드 시 S3 관리형 암호화 키(SSE-S3)를 사용한 서버 측 암호화를 요구하는 버킷 정책을 생성합니다.  
D. 기본 AWS Key Management Service(AWS KMS) 키를 사용하여 S3 버킷 암호화를 활성화합니다.  

```
A company is using a centralized AWS account to store log data in various Amazon S3 buckets. A solutions architect needs to ensure that the data is encrypted at rest before the data is uploaded to the S3 buckets. The data also must be encrypted in transit.  
  
Which solution meets these requirements?

- A. Use client-side encryption to encrypt the data that is being uploaded to the S3 buckets.
- B. Use server-side encryption to encrypt the data that is being uploaded to the S3 buckets.
- C. Create bucket policies that require the use of server-side encryption with S3 managed encryption keys (SSE-S3) for S3 uploads.
- D. Enable the security option to encrypt the S3 buckets through the use of a default AWS Key Management Service (AWS KMS) key.
```

정답 : `C`

- S3 버킷 정책으로 SSE-S3 강제 → 업로드되는 모든 객체에 대해 자동 서버 측 암호화 강제
- 중앙 관리에 적합하며, 업로드 전에 애플리케이션이 따로 암호화를 처리할 필요가 없어 운영 오버헤드 최소화
- S3는 HTTPS/TLS를 기본적으로 지원하므로 전송 중 암호화(in transit)도 자동으로 충족

오답 이유

- **A. 클라이언트 측 암호화**: 가능하지만, 애플리케이션/클라이언트에서 직접 키 관리 및 암호화를 수행해야 하므로 운영 복잡성이 커짐. 요구사항의 “중앙 집중 관리” 및 “운영 효율”과 맞지 않음.
    
- **B. 단순히 서버 측 암호화 사용**: 옵션 자체만으로는 **강제 보장**이 안 됩니다. 클라이언트가 암호화를 지정하지 않을 수도 있기 때문에 정책 적용이 필요.
    
- **D. KMS 기본 키 사용**: 기본 SSE-KMS 설정은 가능하지만, 모든 업로드에서 반드시 암호화를 사용하도록 **강제하는 정책**이 필요합니다. 단순히 기본 KMS 키를 설정하는 것만으로는 “업로드 전에 암호화 강제” 요건을 완전히 충족하지 못함.


## #271
솔루션스 아키텍트는 야간 배치 처리 작업이 시작되기 전에 원하는 Amazon EC2 용량에 도달하기까지 1시간이 걸려 자동으로 확장되는 것을 관찰했습니다. 피크 용량은 매일 밤 동일하며, 배치 작업은 항상 새벽 1시에 시작됩니다. 솔루션스 아키텍트는 원하는 EC2 용량에 빠르게 도달하면서 배치 작업 완료 후 Auto Scaling 그룹이 축소되도록 하는 비용 효율적인 솔루션을 찾아야 합니다.

어떤 조치를 취해야 합니까?

A. Auto Scaling 그룹의 최소 용량을 늘립니다.  
B. Auto Scaling 그룹의 최대 용량을 늘립니다.  
C. 원하는 컴퓨팅 수준으로 확장되도록 예약된 스케일링을 구성합니다.  
D. 각 스케일링 작업 중 더 많은 EC2 인스턴스를 추가하도록 스케일링 정책을 변경합니다.  

```
A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the ‘same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete.  
  
What should the solutions architect do to meet these requirements?

- A. Increase the minimum capacity for the Auto Scaling group.
- B. Increase the maximum capacity for the Auto Scaling group.
- C. Configure scheduled scaling to scale up to the desired compute level.
- D. Change the scaling policy to add more EC2 instances during each scaling operation.
```

정답 : `C`

- 매일 같은 시간(1 AM)에 배치 작업이 시작되고, 필요한 피크 용량도 동일
- 동적 스케일링을 기다릴 필요 없이 예약된 스케일링(Scheduled Scaling)을 설정해 매일 작업 시작 전 원하는 인스턴스 수까지 미리 확장
- 작업이 끝난 후에 다시 축소되도록 예약을 추가할 수 있어 비용 효율적

오답 이유

- **A. 최소 용량 증가**: 항상 높은 용량을 유지해야 하므로 비용 낭비가 큽니다. 작업이 없는 시간에도 불필요한 인스턴스가 유지됩니다.
    
- **B. 최대 용량 증가**: 현재 문제는 최대치가 아니라 **피크까지 도달하는 시간 지연**입니다. 따라서 효과 없음.
    
- **D. 스케일링 정책 변경**: 더 빠르게 확장할 수는 있지만, 불필요한 인스턴스가 더 많이 뜨거나 조정이 어렵습니다. 또한 피크 시점이 고정되어 있으므로 예약 스케일링이 더 단순하고 확실한 해법입니다.


## #272
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스 플릿에서 동적 웹사이트를 제공하고 있습니다. 전 세계 고객을 위해 웹사이트는 여러 언어를 지원해야 합니다. 웹사이트 아키텍처는 us-west-1 리전에서 실행 중이며, 다른 지역의 사용자들에게 높은 요청 지연이 나타나고 있습니다.

웹사이트는 사용자의 위치와 관계없이 빠르고 효율적으로 요청을 처리해야 합니다. 그러나 회사는 기존 아키텍처를 여러 리전에 걸쳐 재구성하고 싶지 않습니다.

요구사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 기존 아키텍처를 Amazon S3 버킷에서 제공되는 웹사이트로 대체합니다. S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 구성합니다. 캐시 동작 설정을 Accept-Language 요청 헤더 기반으로 캐시하도록 설정합니다.
B. ALB를 오리진으로 하는 Amazon CloudFront 배포를 구성합니다. 캐시 동작 설정을 Accept-Language 요청 헤더 기반으로 캐시하도록 설정합니다.
C. ALB와 통합된 Amazon API Gateway API를 생성합니다. API를 HTTP 통합 유형으로 구성합니다. API Gateway 스테이지에서 Accept-Language 요청 헤더 기반으로 API 캐시를 활성화합니다.
D. 추가 리전마다 EC2 인스턴스를 시작하고 해당 리전의 캐시 서버 역할을 하도록 NGINX를 구성합니다. 모든 EC2 인스턴스와 ALB를 지리적 위치(geolocation) 라우팅 정책을 사용하는 Amazon Route 53 레코드 집합 뒤에 둡니다.

```
A company serves a dynamic website from a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The website needs to support multiple languages to serve customers around the world. The website’s architecture is running in the us-west-1 Region and is exhibiting high request latency for users that are located in other parts of the world.  
  
The website needs to serve requests quickly and efficiently regardless of a user’s location. However, the company does not want to recreate the existing architecture across multiple Regions.  
  
What should a solutions architect do to meet these requirements?

- A. Replace the existing architecture with a website that is served from an Amazon S3 bucket. Configure an Amazon CloudFront distribution with the S3 bucket as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.
- B. Configure an Amazon CloudFront distribution with the ALB as the origin. Set the cache behavior settings to cache based on the Accept-Language request header.
- C. Create an Amazon API Gateway API that is integrated with the ALB. Configure the API to use the HTTP integration type. Set up an API Gateway stage to enable the API cache based on the Accept-Language request header.
- D. Launch an EC2 instance in each additional Region and configure NGINX to act as a cache server for that Region. Put all the EC2 instances and the ALB behind an Amazon Route 53 record set with a geolocation routing policy.
```

정답 : `B`

- CloudFront는 전 세계 엣지 로케이션에서 사용자의 요청을 종단/캐시하여, 단일 리전에만 백엔드가 있어도 **전역 사용자에게 낮은 지연**을 제공
- 오리진을 **기존 ALB**로 지정하므로, 백엔드(EC2/ALB) 구조를 다른 리전에 재구축할 필요가 없음
- 캐시 키에 **Accept-Language 헤더**를 포함하도록 캐시 동작을 설정하면, 언어별로 별도의 객체/응답을 캐시해 **다국어 페이지를 효율적으로 제공**
- 동적 페이지도 CloudFront의 오리진 패스스루 및 캐시 정책으로 적절히 캐싱하거나 미캐시 처리 가능(쿠키/헤더/쿼리 기반 캐시 키 제어)

오답 이유

- **A (S3로 대체)**: S3 정적 웹 호스팅은 **동적 웹 애플리케이션**을 바로 대체하기 어렵습니다. 기존 아키텍처를 **대체**하라고 하여 요구사항(재구성 원치 않음)과 불일치.
    
- **C (API Gateway + 캐시)**: API Gateway는 주로 API용이며, 웹 전체(정적/동적/자산) 트래픽 프런트로 쓰기엔 부적절하고 **전역 엣지 캐시/전송 최적화**는 CloudFront가 적합합니다.
    
- **D (리전별 NGINX + Route 53)**: 리전마다 EC2를 띄워 **아키텍처를 사실상 재구성**하는 방식이라 운영 복잡/비용 증가. 요구사항과 상충.


## #273
급성장 중인 이커머스 회사가 단일 AWS 리전에서 워크로드를 운영하고 있습니다. 솔루션스 아키텍트는 다른 AWS 리전을 포함하는 재해 복구(DR) 전략을 수립해야 합니다. 회사는 DR 리전의 데이터베이스가 가능한 한 낮은 지연으로 최신 상태를 유지하길 원합니다. DR 리전의 나머지 인프라는 축소된 용량으로 실행되되, 필요 시 확장할 수 있어야 합니다.

다음 중 가장 낮은 RTO(복구 시간 목표)로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?

A. Amazon Aurora 글로벌 데이터베이스와 파일럿 라이트 배포를 사용합니다.
B. Amazon Aurora 글로벌 데이터베이스와 웜 스탠바이 배포를 사용합니다.
C. Amazon RDS 멀티 AZ DB 인스턴스와 파일럿 라이트 배포를 사용합니다.
D. Amazon RDS 멀티 AZ DB 인스턴스와 웜 스탠바이 배포를 사용합니다.

```
A rapidly growing ecommerce company is running its workloads in a single AWS Region. A solutions architect must create a disaster recovery (DR) strategy that includes a different AWS Region. The company wants its database to be up to date in the DR Region with the least possible latency. The remaining infrastructure in the DR Region needs to run at reduced capacity and must be able to scale up if necessary.  
  
Which solution will meet these requirements with the LOWEST recovery time objective (RTO)?

- A. Use an Amazon Aurora global database with a pilot light deployment.
- B. Use an Amazon Aurora global database with a warm standby deployment.
- C. Use an Amazon RDS Multi-AZ DB instance with a pilot light deployment.
- D. Use an Amazon RDS Multi-AZ DB instance with a warm standby deployment.
```

정답 : `B`

- Aurora Global Database는 주 리전에서 DR 리전으로 전용 복제(비동기, 전용 네트워크 경로)를 사용해 아주 낮은 복제 지연(보통 1초 미만)으로 데이터 동기화
- 웜 스탠바이는 DR 리전에 축소 용량으로 핵심 컴퓨팅/애플리케이션이 이미 구동 중인 상태로, 장애 시 빠르게 증설(스케일 아웃)하여 서비스 복구 가능
	- 파일럿 라이트보다 RTO가 더 짧음
	- 파일럿 라이트(Pilot Light): 최소 핵심(주로 DB)만 켜둠 → 비용↓, RTO↑

오답 이유

- **A. Aurora + 파일럿 라이트**: 데이터베이스 측면은 적합하나, 애플리케이션 계층이 대부분 꺼져 있어 **기동/배포 시간이 필요** → **RTO가 길어짐**.
    
- **C/D. RDS Multi-AZ**: Multi-AZ는 **단일 리전 내 동기식 스탠바이**를 제공할 뿐 **교차 리전 DR**이 아닙니다. 질문은 “다른 리전”을 포함해야 하므로 부적합. (교차 리전은 별도의 Read Replica 등으로 구성해야 하나 보기에는 없음.)


## #274
한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행하고 있습니다. 회사는 애플리케이션에 대한 재해 복구(DR) 솔루션을 구현해야 합니다. DR 솔루션은 RTO(복구 시간 목표)가 4시간 미만이어야 합니다. 또한 DR 솔루션은 정상 운영 중에 가능한 한 적은 AWS 리소스를 사용해야 합니다.

다음 중 운영 효율성이 가장 높은 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. EC2 인스턴스를 백업하기 위해 Amazon Machine Image(AMI)를 생성합니다. AMI를 보조(세컨더리) AWS 리전으로 복사합니다. AWS Lambda와 커스텀 스크립트를 사용하여 보조 리전에서 인프라 배포를 자동화합니다.
B. EC2 인스턴스를 백업하기 위해 Amazon Machine Image(AMI)를 생성합니다. AMI를 보조 AWS 리전으로 복사합니다. AWS CloudFormation을 사용하여 보조 리전에서 인프라 배포를 자동화합니다.
C. 보조 AWS 리전에서 EC2 인스턴스를 시작합니다. 보조 리전의 EC2 인스턴스를 항상 활성 상태로 유지합니다.
D. 보조 가용 영역에서 EC2 인스턴스를 시작합니다. 보조 가용 영역의 EC2 인스턴스를 항상 활성 상태로 유지합니다.

```
A company runs an application on Amazon EC2 instances. The company needs to implement a disaster recovery (DR) solution for the application. The DR solution needs to have a recovery time objective (RTO) of less than 4 hours. The DR solution also needs to use the fewest possible AWS resources during normal operations.  
  
Which solution will meet these requirements in the MOST operationally efficient way?

- A. Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS Lambda and custom scripts.
- B. Create Amazon Machine Images (AMIs) to back up the EC2 instances. Copy the AMIs to a secondary AWS Region. Automate infrastructure deployment in the secondary Region by using AWS CloudFormation.
- C. Launch EC2 instances in a secondary AWS Region. Keep the EC2 instances in the secondary Region active at all times.
- D. Launch EC2 instances in a secondary Availability Zone. Keep the EC2 instances in the secondary Availability Zone active at all times.
```

정답 : `B`

- 정상 시 리소스를 최소화하면서 장애 시 템플릿 기반으로 신속 복구가 가능한 파일럿 라이트/백업&복구 패턴
- AMI를 교차 리전에 복사해두고, AWS CloudFormation으로 네트워킹/보안그룹/오토스케일링/ALB 등 전체 스택을 선언적으로 신속 재구성
	- 운영 효율과 재현성이 높고, 스크립트보다 오류･드리프트가 적어 RTO < 4시간 달성에 유리
	- AWS CloudFormation : 인프라 코드를 선언하여 신속･일관된 재배포/복구 가능. 파라미터로 DR 리전에 맞춘 변형도 용이

오답 이유

- **A. Lambda + 커스텀 스크립트**: 가능하나 **운영 복잡도와 유지보수 부담**이 큼. 스크립트 신뢰성/예측 가능성이 낮아 **운영 효율성** 측면에서 B보다 열등.
    
- **C. 보조 리전에 상시 가동**: **웜 스탠바이/핫 스탠바이**에 해당하여 정상 시 리소스 사용·비용이 큼. “가능한 한 적은 리소스” 요구에 부적합.
    
- **D. 동일 리전 내 AZ 활성**: DR은 **다른 리전**을 포함해야 한다는 전제에서 벗어남. 또한 상시 가동으로 비용↑.


## #275
회사는 내부 브라우저 기반 애플리케이션을 운영합니다. 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 걸친 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 근무 시간 동안 20개 인스턴스로 스케일 업하지만, 야간에는 2개 인스턴스로 스케일 다운합니다. 직원들은 아침 근무 시작 시 애플리케이션이 매우 느리다고 불평하지만, 오전 중반에는 잘 동작합니다.

직원들의 불만을 해결하면서 비용을 최소화하도록 스케일링을 어떻게 변경해야 합니까?

A. 사무실이 열리기 직전에 원하는 용량(desired capacity)을 20으로 설정하는 예약 작업을 구현합니다.
B. 더 낮은 CPU 임계값에서 트리거되는 단계(step) 스케일링을 구현하고, 쿨다운 기간을 줄입니다.
C. 더 낮은 CPU 임계값에서 트리거되는 타깃 추적(target tracking) 스케일링을 구현하고, 쿨다운 기간을 줄입니다.
D. 사무실이 열리기 직전에 최소 및 최대 용량을 20으로 설정하는 예약 작업을 구현합니다.

```
A company runs an internal browser-based application. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight. Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning.  
  
How should the scaling be changed to address the staff complaints and keep costs to a minimum?

- A. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens.
- B. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.
- C. Implement a target tracking action triggered at a lower CPU threshold, and decrease the cooldown period.
- D. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens.
```

정답 : `A`

- 아침 근무 시작 시에는 예측 가능한 트래픽 급증
- 동적 스케일링(지표 기반)은 부하가 실제로 상승한 뒤에야 인스턴스를 증설하므로 워밍업 시간으로 초기에 느림
- 예약 스케일링으로 근무 시작 직전에 desired capacity를 20으로 미리 올려두면 개시 시점부터 충분한 용량 확보로 초기 지연 해소
- 근무 종료 후에는 기존 정책대로 축소되어 비용도 최소화

오답 이유

- **B. 단계 스케일링 + 낮은 임계값/쿨다운 감소**: 부하 발생 후에 반응하므로 초기 러시를 커버하려면 여전히 시간이 걸립니다. 또한 잦은 스케일링 이벤트로 비효율 가능.
    
- **C. 타깃 추적 + 낮은 임계값/쿨다운 감소**: 마찬가지로 사후 반응형입니다. 예측 가능한 시간 기반 급증에는 예약 스케일링이 더 적합합니다.
    
- **D. 최소/최대 용량을 20으로 예약 설정**: 아침에 빠른 성능은 확보되지만 **최소/최대 모두 20으로 고정**하면 근무 시간 외에도 20개를 유지할 위험이 있어 **비용이 증가**합니다. desired만 올리는 A가 더 비용 효율적입니다.


## #276
한 회사가 여러 Amazon EC2 인스턴스(오토 스케일링 그룹)에 배포된 다중 계층 애플리케이션을 운영하고 있습니다. 애플리케이션의 데이터 계층은 Amazon RDS for Oracle 인스턴스이며, Oracle 전용 PL/SQL 함수를 사용합니다. 애플리케이션 트래픽이 꾸준히 증가하고 있어 EC2 인스턴스가 과부하되고 RDS 인스턴스의 스토리지가 부족해지고 있습니다. 오토 스케일링 그룹에는 스케일링 지표가 없고, 최소 정상 인스턴스 수만 정의되어 있습니다. 회사는 트래픽이 안정적이지만 예측 불가능한 속도로 계속 증가하다가 어느 시점에 안정화될 것으로 예상합니다.

증가하는 트래픽에 대해 시스템이 자동으로 스케일링되도록 하려면 솔루션스 아키텍트는 무엇을 해야 합니까? (두 가지 선택)

A. RDS for Oracle 인스턴스에서 스토리지 자동 스케일링을 구성합니다.
B. 자동 스토리지 스케일링을 사용하기 위해 데이터베이스를 Amazon Aurora로 마이그레이션합니다.
C. RDS for Oracle 인스턴스의 사용 가능 스토리지가 낮을 때 알람을 구성합니다.
D. 오토 스케일링 그룹이 평균 CPU를 스케일링 지표로 사용하도록 구성합니다.
E. 오토 스케일링 그룹이 평균 사용 가능 메모리를 스케일링 지표로 사용하도록 구성합니다.

```
A company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application’ s data layer that uses Oracle-specific PL/SQL functions. Traffic to the application has been steadily increasing. This is causing the EC2 instances to become overloaded and the RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off.  
  
What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Choose two.)

- A. Configure storage Auto Scaling on the RDS for Oracle instance.
- B. Migrate the database to Amazon Aurora to use Auto Scaling storage.
- C. Configure an alarm on the RDS for Oracle instance for low free storage space.
- D. Configure the Auto Scaling group to use the average CPU as the scaling metric.
- E. Configure the Auto Scaling group to use the average free memory as the scaling metric.
```

정답 : `A, D`

- RDS 스토리지 자동 스케일링을 켜면 여유 공간이 임계치에 도달할 때 자동으로 스토리지를 확장하여 스토리지 부족으로 인한 중단 예방
- 오토 스케일링 그룹의 스케일링 지표로 평균 CPU를 사용하면 부하가 증가할 때 EC2 인스턴스 수를 자동으로 확장/축소해 애플리케이션 계층의 과부화 완화

오답 이유

- **B. Aurora로 마이그레이션**: 애플리케이션이 **Oracle 전용 PL/SQL**을 사용하므로 호환되지 않습니다. 마이그레이션은 큰 변경을 요구하며 문제의 핵심(자동 확장) 해결과도 거리가 있습니다.
    
- **C. RDS 스토리지 알람**: 알람은 **통지**만 할 뿐 자동 확장은 수행하지 않습니다. 요구사항은 자동으로 스케일하는 것입니다.
    
- **E. 평균 메모리 지표 사용**: 메모리는 EC2 기본 지표가 아니어서 **CloudWatch 에이전트 설치/커스텀 지표** 구성이 필요합니다. 운영 오버헤드가 증가하며 일반적으로 **CPU가 더 표준적**이고 신뢰할 수 있는 스케일 트리거입니다.


## #277
회사는 동영상 콘텐츠를 게시하고 어떤 모바일 플랫폼에서도 사용할 수 있도록 트랜스코딩하는 온라인 서비스를 제공합니다. 애플리케이션 아키텍처는 여러 Amazon EC2 Linux 인스턴스가 처리할 동영상 콘텐츠에 접근할 수 있도록 동영상을 수집·저장하는 데 Amazon Elastic File System (Amazon EFS) Standard를 사용합니다. 시간이 지나며 서비스의 인기가 높아지자 스토리지 비용이 너무 비싸졌습니다.

가장 비용 효율적인 스토리지 솔루션은 무엇입니까?

A. AWS Storage Gateway for files를 사용하여 동영상 콘텐츠를 저장하고 처리합니다.
B. AWS Storage Gateway for volumes를 사용하여 동영상 콘텐츠를 저장하고 처리합니다.
C. 동영상 콘텐츠 저장에는 Amazon EFS를 사용합니다. 처리가 완료되면 파일을 Amazon Elastic Block Store (Amazon EBS)로 전송합니다.
D. 동영상 콘텐츠 저장에는 Amazon S3를 사용합니다. 처리를 위해 파일을 일시적으로 서버에 연결된 Amazon Elastic Block Store (Amazon EBS) 볼륨으로 이동합니다.

```
A company provides an online service for posting video content and transcoding it for use by any mobile platform. The application architecture uses Amazon Elastic File System (Amazon EFS) Standard to collect and store the videos so that multiple Amazon EC2 Linux instances can access the video content for processing. As the popularity of the service has grown over time, the storage costs have become too expensive.  
  
Which storage solution is MOST cost-effective?

- A. Use AWS Storage Gateway for files to store and process the video content.
- B. Use AWS Storage Gateway for volumes to store and process the video content.
- C. Use Amazon EFS for storing the video content. Once processing is complete, transfer the files to Amazon Elastic Block Store (Amazon EBS).
- D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing.
```

정답 : `D`

- 대용량･장기 보관에는 S3가 EFS Standard보다 훨씬 저렴
- 트랜스코딩 시에는 각 워커(EC2) 인스턴스의 EBS에 임시로 내려받아 로컬 블록 스토리지 I/O로 고성능 처리
- 원본은 S3, 작업 단위별로 워커가 S3에서 가져와 처리하므로 EFS의 다중 동시 파일 시스템 접근이 필요없음

오답 이유

- **A. Storage Gateway for files**: 온프레미스 ↔ AWS 하이브리드 파일 게이트웨이 용도입니다. 이미 워크로드가 **AWS 내**에서 동작하므로 부적합하며 비용/운영 복잡성만 증가합니다.
    
- **B. Storage Gateway for volumes**: 블록 볼륨 캐시/백업을 위한 하이브리드 시나리오입니다. 마찬가지로 클라우드 내 워크로드에는 맞지 않습니다.
    
- **C. EFS에 계속 저장 후 EBS로 이동**: 장기 저장을 계속 **EFS Standard**로 유지하므로 비용 문제를 해결하지 못합니다. EFS → EBS 이동은 처리 중에만 의미가 있으나 핵심 비용 절감(장기 보관)을 달성하지 못합니다.


## #278
한 회사가 직원 데이터를 계층적 구조적 관계로 저장하는 애플리케이션을 만들고자 합니다. 회사는 직원 데이터에 대한 고트래픽 조회에 최소 지연으로 응답해야 하며, 어떤 민감한 데이터도 보호해야 합니다. 또한 직원 데이터에 금융 정보가 존재하는 경우 매월 이메일 메시지를 수신해야 합니다.

이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 단계의 조합은 무엇입니까? (두 가지 선택)

A. Amazon Redshift를 사용하여 직원 데이터를 계층 구조로 저장합니다. 매달 데이터를 Amazon S3로 언로드합니다.
B. Amazon DynamoDB를 사용하여 직원 데이터를 계층 구조로 저장합니다. 매달 데이터를 Amazon S3로 내보냅니다.
C. AWS 계정에 대해 Amazon Macie를 구성합니다. 월별 이벤트를 AWS Lambda로 보내도록 Macie를 Amazon EventBridge와 통합합니다.
D. Amazon S3의 직원 데이터를 분석하기 위해 Amazon Athena를 사용합니다. 분석 대시보드를 게시하고 사용자와 공유하기 위해 Athena를 Amazon QuickSight와 통합합니다.
E. AWS 계정에 대해 Amazon Macie를 구성합니다. 월별 알림을 Amazon Simple Notification Service(Amazon SNS) 구독을 통해 보내도록 Macie를 Amazon EventBridge와 통합합니다.

```
A company wants to create an application to store employee data in a hierarchical structured relationship. The company needs a minimum-latency response to high-traffic queries for the employee data and must protect any sensitive data. The company also needs to receive monthly email messages if any financial information is present in the employee data.  
  
Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)

- A. Use Amazon Redshift to store the employee data in hierarchies. Unload the data to Amazon S3 every month.
- B. Use Amazon DynamoDB to store the employee data in hierarchies. Export the data to Amazon S3 every month.
- C. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly events to AWS Lambda.
- D. Use Amazon Athena to analyze the employee data in Amazon S3. Integrate Athena with Amazon QuickSight to publish analysis dashboards and share the dashboards with users.
- E. Configure Amazon Macie for the AWS account. Integrate Macie with Amazon EventBridge to send monthly notifications through an Amazon Simple Notification Service (Amazon SNS) subscription.
```

정답 : `B, E`

- DynamoDB는 밀리초 단위 응답 지연으로 대량 읽기 트래픽 처리에 적합
	- 단일 테이블 설계로 계층적 데이터를 모델링 용이
	- 내장 보안(서버측 암호화, 세분화된 IAM)으로 민감 정보 보호에도 유리
	- 월 1회 S3로 내보내기를 수행하면 이후 데이터 검사/검색에 활용할 수 있음
- Macie + EventBridge + SNS 이메일 알림
	- S3에 적재된 데이터를 Amazon Macie가 정기(월별) 분류 작업으로 검사해 금융 정보를 탐지
	- EventBridge → SNS 이메일로 결과 알림을 자동 전송
	- Amazon Macie : S3의 데이터에 대해 개인/금융 등 민감정보 자동 식별 및 분류

오답 이유

- **A (Redshift)**: 컬럼 기반 DWH로 **OLAP**에 적합하며 OLTP 성 격의 **최소 지연 고트래픽 조회**에는 부적합합니다. 또한 PL/SQL 등 계층 트랜잭션 조회에 맞지 않습니다.
    
- **C (Macie → Lambda)**: 이메일 요구사항을 직접 충족하지 못합니다. Lambda로 후속 처리 가능하나, **이메일 알림은 SNS가 간편**하고 요구에 더 정확히 부합합니다.
    
- **D (Athena + QuickSight)**: 분석/시각화에는 유용하지만, 핵심 요구인 **최소 지연 응답**과 **민감정보 월별 이메일 알림**을 직접 충족하지 못합니다.


## #279
한 회사에는 Amazon DynamoDB 테이블을 사용하는 애플리케이션이 있습니다. 회사의 컴플라이언스 요구사항에 따르면 데이터베이스 백업은 매달 수행되어야 하며, 6개월 동안은 사용 가능해야 하고, 7년간 보존되어야 합니다.

다음 중 어떤 솔루션이 이러한 요구사항을 충족합니까?

A. 각 달의 첫째 날에 DynamoDB 테이블을 백업하도록 AWS Backup 계획을 생성합니다. 6개월 후 백업을 콜드 스토리지로 전환하도록 수명 주기 정책을 지정합니다. 각 백업의 보존 기간을 7년으로 설정합니다.
B. 각 달의 첫째 날에 DynamoDB 테이블의 주문형(on-demand) 백업을 생성합니다. 6개월 후에 백업을 Amazon S3 Glacier Flexible Retrieval로 전환합니다. 7년이 지난 백업을 삭제하도록 S3 수명 주기 정책을 생성합니다.
C. AWS SDK를 사용하여 DynamoDB 테이블의 주문형 백업을 생성하는 스크립트를 개발합니다. 매달 첫째 날에 스크립트를 실행하는 Amazon EventBridge 규칙을 설정합니다. 6개월이 지난 DynamoDB 백업을 콜드 스토리지로 전환하고 7년이 지난 백업을 삭제하는 두 번째 스크립트를 매달 둘째 날에 실행하도록 설정합니다.
D. AWS CLI를 사용하여 DynamoDB 테이블의 주문형 백업을 생성합니다. cron 표현식으로 매달 첫째 날에 명령을 실행하는 Amazon EventBridge 규칙을 설정합니다. 명령에서 6개월 후 백업을 콜드 스토리지로 전환하고 7년 후 백업을 삭제하도록 지정합니다.

```
A company has an application that is backed by an Amazon DynamoDB table. The company’s compliance requirements specify that database backups must be taken every month, must be available for 6 months, and must be retained for 7 years.  
  
Which solution will meet these requirements?

- A. Create an AWS Backup plan to back up the DynamoDB table on the first day of each month. Specify a lifecycle policy that transitions the backup to cold storage after 6 months. Set the retention period for each backup to 7 years.
- B. Create a DynamoDB on-demand backup of the DynamoDB table on the first day of each month. Transition the backup to Amazon S3 Glacier Flexible Retrieval after 6 months. Create an S3 Lifecycle policy to delete backups that are older than 7 years.
- C. Use the AWS SDK to develop a script that creates an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the script on the first day of each month. Create a second script that will run on the second day of each month to transition DynamoDB backups that are older than 6 months to cold storage and to delete backups that are older than 7 years.
- D. Use the AWS CLI to create an on-demand backup of the DynamoDB table. Set up an Amazon EventBridge rule that runs the command on the first day of each month with a cron expression. Specify in the command to transition the backups to cold storage after 6 months and to delete the backups after 7 years.
```

정답 : `A`

- AWS Backup은 DynamoDB를 네이티브로 지원
- 백업 계획에서 월간 스케줄, 라이프사이클 전환(6개월 후 콜드 스토리지로 이동), 보존 기간(7년)을 정책 기반으로 자동 적용 가능

오답 이유

- **B. DynamoDB 온디맨드 백업 + S3/Glacier 전환**
    
    - DynamoDB 온디맨드 백업은 사용자가 **S3 버킷으로 직접 관리/이동**하지 않습니다. S3 라이프사이클이나 Glacier 클래스로 **사용자 전환 불가**입니다.
        
    
- **C. 스크립트로 백업/전환/삭제**
    
    - 온디맨드 백업 자체에 대해 사용자가 **콜드 스토리지 전환/삭제 정책**을 직접 적용할 수 없습니다. 또한 불필요한 커스텀 운영 오버헤드가 큽니다.
        
    
- **D. CLI + EventBridge로 전환/삭제 지정**
    
    - 마찬가지로 CLI로 **온디맨드 백업을 콜드 스토리지로 전환**하는 옵션이 없습니다. 전환/보존 정책은 **AWS Backup 라이프사이클**에서 관리해야 합니다.


## #280
한 회사가 Amazon CloudFront를 웹사이트와 함께 사용하고 있습니다. 회사는 CloudFront 배포에 로깅을 활성화했으며, 로그는 회사의 Amazon S3 버킷에 저장됩니다. 회사는 로그에 대해 고급 분석을 수행하고 시각화를 구축해야 합니다.

이 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. Amazon Athena에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 결과를 AWS Glue로 시각화합니다.
B. Amazon Athena에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 결과를 Amazon QuickSight로 시각화합니다.
C. Amazon DynamoDB에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 결과를 AWS Glue로 시각화합니다.
D. Amazon DynamoDB에서 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. 결과를 Amazon QuickSight로 시각화합니다.

```
A company is using Amazon CloudFront with its website. The company has enabled logging on the CloudFront distribution, and logs are saved in one of the company’s Amazon S3 buckets. The company needs to perform advanced analyses on the logs and build visualizations.  
  
What should a solutions architect do to meet these requirements?

- A. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.
- B. Use standard SQL queries in Amazon Athena to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.
- C. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with AWS Glue.
- D. Use standard SQL queries in Amazon DynamoDB to analyze the CloudFront logs in the S3 bucket. Visualize the results with Amazon QuickSight.
```

정답 : `B`

- CloudFront 로그는 S3에 저장되므로, Athena를 통해 서버리스 방식으로 S3 데이터를 표준 SQL로 분석 가능
- BI 및 시각화는 Amazon QuickSight가 제공
- 운영 오버헤드가 거의 없고 로그 분석 및 시각화를 위해 AWS에서 권장되는 패턴

오답 이유

- **A. Athena + AWS Glue**
    - Glue는 데이터 카탈로그 및 ETL 도구이지 시각화 도구가 아님. 분석은 가능해도 시각화는 QuickSight가 맞음.
    
- **C. DynamoDB + AWS Glue**
    - CloudFront 로그는 S3에 저장되며, DynamoDB에서 SQL로 직접 분석할 수 없음. 잘못된 서비스 조합.
    
- **D. DynamoDB + QuickSight**
    - DynamoDB는 이 케이스에서 로그 저장소가 아님. Athena를 써야 하며, DynamoDB를 통한 SQL 분석은 지원되지 않음.