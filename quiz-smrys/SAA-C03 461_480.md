---
created: 2025-10-13 17:17:31
last_modified: 2025-10-15 15:22:22
---
## #461
한 회사가 단일 AWS 리전에서 모바일 게임 앱을 개발하고 있습니다. 앱은 Auto Scaling 그룹의 여러 Amazon EC2 인스턴스에서 실행됩니다. 회사는 앱 데이터를 Amazon DynamoDB에 저장합니다. 앱은 사용자와 서버 간에 TCP 트래픽과 UDP 트래픽을 사용하여 통신합니다. 애플리케이션은 전 세계적으로 사용될 것입니다. 회사는 모든 사용자에게 가능한 가장 낮은 지연 시간을 보장하고자 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. AWS Global Accelerator를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 사용하는 가속기 엔드포인트 뒤에 애플리케이션 로드 밸런서(ALB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 그룹을 업데이트하여 ALB에 인스턴스를 등록합니다.
B. AWS Global Accelerator를 사용하여 가속기를 생성합니다. Global Accelerator 통합을 사용하는 가속기 엔드포인트 뒤에 네트워크 로드 밸런서(NLB)를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 그룹을 업데이트하여 NLB에 인스턴스를 등록합니다.
C. Amazon CloudFront 콘텐츠 전송 네트워크(CDN) 엔드포인트를 생성합니다. 엔드포인트 뒤에 NLB를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 그룹을 업데이트하여 NLB에 인스턴스를 등록합니다. CloudFront가 오리진으로 NLB를 사용하도록 업데이트합니다.
D. Amazon CloudFront CDN 엔드포인트를 생성합니다. 엔드포인트 뒤에 ALB를 생성하고 TCP 및 UDP 포트에서 수신 대기합니다. Auto Scaling 그룹을 업데이트하여 ALB에 인스턴스를 등록합니다. CloudFront가 오리진으로 ALB를 사용하도록 업데이트합니다.

```
A company is developing a mobile gaming app in a single AWS Region. The app runs on multiple Amazon EC2 instances in an Auto Scaling group. The company stores the app data in Amazon DynamoDB. The app communicates by using TCP traffic and UDP traffic between the users and the servers. The application will be used globally. The company wants to ensure the lowest possible latency for all users.  
  
Which solution will meet these requirements?

- A. Use AWS Global Accelerator to create an accelerator. Create an Application Load Balancer (ALB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB.
- B. Use AWS Global Accelerator to create an accelerator. Create a Network Load Balancer (NLB) behind an accelerator endpoint that uses Global Accelerator integration and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB.
- C. Create an Amazon CloudFront content delivery network (CDN) endpoint. Create a Network Load Balancer (NLB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the NLB. Update CloudFront to use the NLB as the origin.
- D. Create an Amazon CloudFront content delivery network (CDN) endpoint. Create an Application Load Balancer (ALB) behind the endpoint and listening on the TCP and UDP ports. Update the Auto Scaling group to register instances on the ALB. Update CloudFront to use the ALB as the origin.
```

정답 : `B`

- AWS Global Accelerator는 Anycast 고정 IP를 제공하여 사용자를 가장 가까운 엣지 로케이션으로 유도하고, 전용 AWS 글로벌 네트워크를 통해 단일 리전의 엔드포인트로 최적 경로 전송 → 지연 최소화
- 게임 트래픽은 TCP와 UDP를 사용. ALB는 UDP 미지원, NLB는 TCP/UDP 리스너를 지원하므로 적합
- 가속기 엔드포인트에 NLB 통합 후 오토스케일링 그룹의 인스턴스를 NLB 대상 그룹에 등록하면 자동 확장과 헬스체크로 가용성과 성능 보장

오답 이유

- **A (Global Accelerator + ALB)**: ALB는 **HTTP/HTTPS(L7)** 전용으로 **UDP 미지원** → 요구사항 불충족.
    
- **C/D (CloudFront + NLB/ALB)**: CloudFront는 **HTTP/HTTPS 콘텐츠 캐싱** 용도로, **임의 TCP 및 UDP 패스스루**를 지원하지 않음 → 실시간 게임 트래픽(특히 UDP)에 부적합.


## #462
한 회사에는 고객 주문을 처리하는 애플리케이션이 있습니다. 회사는 이 애플리케이션을 Amazon EC2 인스턴스에서 호스팅하고 있으며, 주문은 Amazon Aurora 데이터베이스에 저장됩니다. 가끔 트래픽이 높을 때 워크로드가 주문을 충분히 빠르게 처리하지 못합니다.

주문을 가능한 한 빠르고 신뢰성 있게 데이터베이스에 기록하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 트래픽이 높을 때 EC2 인스턴스의 인스턴스 크기를 늘립니다. 주문을 Amazon Simple Notification Service(Amazon SNS)에 기록합니다. 데이터베이스 엔드포인트를 SNS 주제에 구독시킵니다.
B. 주문을 Amazon Simple Queue Service(Amazon SQS) 큐에 기록합니다. Application Load Balancer 뒤의 Auto Scaling 그룹의 EC2 인스턴스들이 SQS 큐에서 읽어 데이터베이스에 주문을 처리하도록 합니다.
C. 주문을 Amazon Simple Notification Service(Amazon SNS)에 기록합니다. 데이터베이스 엔드포인트를 SNS 주제에 구독시킵니다. Application Load Balancer 뒤의 Auto Scaling 그룹의 EC2 인스턴스들이 SNS 주제에서 읽도록 합니다.
D. EC2 인스턴스가 CPU 임계값에 도달할 때 주문을 Amazon SQS 큐에 기록합니다. Application Load Balancer 뒤의 Auto Scaling 그룹의 EC2 인스턴스가 예약된 확장을 통해 SQS 큐에서 읽어 데이터베이스에 주문을 처리하도록 합니다.

```
A company has an application that processes customer orders. The company hosts the application on an Amazon EC2 instance that saves the orders to an Amazon Aurora database. Occasionally when traffic is high the workload does not process orders fast enough.  
  
What should a solutions architect do to write the orders reliably to the database as quickly as possible?

- A. Increase the instance size of the EC2 instance when traffic is high. Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic.
- B. Write orders to an Amazon Simple Queue Service (Amazon SQS) queue. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database.
- C. Write orders to Amazon Simple Notification Service (Amazon SNS). Subscribe the database endpoint to the SNS topic. Use EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SNS topic.
- D. Write orders to an Amazon Simple Queue Service (Amazon SQS) queue when the EC2 instance reaches CPU threshold limits. Use scheduled scaling of EC2 instances in an Auto Scaling group behind an Application Load Balancer to read from the SQS queue and process orders into the database.
```

정답 : `B`

- SQS를 앞단 버퍼로 두면 주문 수신과 DB 쓰기를 비동기 분리하여 급격한 트래픽 급증에도 내구성 있게 흡수
- 프로듀서는 큐에 빠르게 기록하고 응답하여 지연을 최소화하고 소비자 워커는 큐 길이 기반으로 수평 확장하며 Aurora에 쓰기를 병렬 처리

오답 이유

- **A. 인스턴스 사이즈 업 + SNS 구독**
    수직 확장은 급증 흡수에 한계가 있고, **DB 엔드포인트는 SNS 구독 대상이 아님**(SNS는 HTTP/S, SQS, Lambda 등). 내구 버퍼 부재로 스파이크 처리 취약.

- **C. SNS 사용**
    SNS는 퍼브/섭 알림이며 **큐잉/버퍼링·재처리 제어**가 부족합니다. 또한 “DB 엔드포인트 구독”은 불가능. 주문 처리 파이프라인에는 **SQS**가 적합.

- **D. CPU 임계 시에만 SQS로**
    스파이크 초입에서 이미 드롭/지연이 발생할 수 있습니다. 또한 **예약 스케일링**은 트래픽 변동에 즉각 대응하지 못하며, 상시 큐 삽입이 아닌 조건부 삽입은 신뢰성 저하.


## #463
한 IoT 회사가 사용자의 수면 데이터를 수집하는 센서가 탑재된 매트리스를 출시합니다. 센서는 데이터를 Amazon S3 버킷으로 전송합니다. 센서는 매트리스 하나당 매일 밤 약 2MB의 데이터를 수집합니다. 회사는 매트리스별로 데이터를 처리하고 요약해야 합니다. 결과는 가능한 한 빨리 제공되어야 합니다. 데이터 처리는 1GB 메모리가 필요하며 30초 이내에 완료됩니다.

가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Scala 작업을 사용한 AWS Glue
B. Apache Spark 스크립트를 사용한 Amazon EMR
C. Python 스크립트를 사용한 AWS Lambda
D. PySpark 작업을 사용한 AWS Glue

```
An IoT company is releasing a mattress that has sensors to collect data about a user’s sleep. The sensors will send data to an Amazon S3 bucket. The sensors collect approximately 2 MB of data every night for each mattress. The company must process and summarize the data for each mattress. The results need to be available as soon as possible. Data processing will require 1 GB of memory and will finish within 30 seconds.  
  
Which solution will meet these requirements MOST cost-effectively?

- A. Use AWS Glue with a Scala job
- B. Use Amazon EMR with an Apache Spark script
- C. Use AWS Lambda with a Python script
- D. Use AWS Glue with a PySpark job
```

정답 : `C`

- Lambda는 최대 10GB 메모리, 15분 실행을 지원하므로 1GB/30초 요구에 충분
- S3 ObjectCreated 이벤트로 Lambda를 즉시 트리거하여 파일 도착 직후 거의 실시간 처리 가능
- 호출･GB-초 기반 과금이며, 매트리스별로 소용량(2MB)･단시간 처리에 최적. 클러스터 기동/유지 비용 없음
- 매트리스 수 증가 시 자동 동시성 확장으로 처리량 확보

오답 이유

- **A/D. AWS Glue(Scala/PySpark)**
    서버리스 ETL이지만 **DPU 단위 최소 요금/실행 오버헤드(콜드 스타트/세션 기동)** 가 커서 **작은 파일·짧은 작업**에 비경제적. “가능한 한 빨리”에도 불리.

- **B. Amazon EMR + Spark**
    클러스터 프로비저닝/관리 비용과 기동 지연이 발생. 상시 클러스터면 고정비, 온디맨드 클러스터면 **스핀업 지연**으로 **지연·비용** 모두 불리.


## #464
한 회사는 온라인 쇼핑 애플리케이션을 호스팅하고 있으며 모든 주문을 Amazon RDS for PostgreSQL 단일 AZ(DB 인스턴스)로 저장합니다. 경영진은 단일 장애 지점을 제거하고자 하며, 애플리케이션 코드를 변경하지 않고 데이터베이스 다운타임을 최소화할 수 있는 접근 방안을 솔루션스 아키텍트에게 요청했습니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 기존 DB 인스턴스를 수정하여 Multi-AZ 옵션을 지정함으로써 Multi-AZ 배포로 변환합니다.
B. 새로운 RDS Multi-AZ 배포를 생성합니다. 현재 RDS 인스턴스의 스냅샷을 생성하고 해당 스냅샷으로 새 Multi-AZ 배포를 복원합니다.
C. 다른 가용 영역에 PostgreSQL 데이터베이스의 읽기 전용 복제본을 생성합니다. Amazon Route 53 가중치 레코드 세트를 사용하여 데이터베이스 전반에 요청을 분산합니다.
D. RDS for PostgreSQL 데이터베이스를 최소 그룹 크기 2의 Amazon EC2 Auto Scaling 그룹에 배치합니다. Amazon Route 53 가중치 레코드 세트를 사용하여 인스턴스 전반에 요청을 분산합니다.

```
A company hosts an online shopping application that stores all orders in an Amazon RDS for PostgreSQL Single-AZ DB instance. Management wants to eliminate single points of failure and has asked a solutions architect to recommend an approach to minimize database downtime without requiring any changes to the application code.  
  
Which solution meets these requirements?

- A. Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.
- B. Create a new RDS Multi-AZ deployment. Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot.
- C. Create a read-only replica of the PostgreSQL database in another Availability Zone. Use Amazon Route 53 weighted record sets to distribute requests across the databases.
- D. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two. Use Amazon Route 53 weighted record sets to distribute requests across instances.
```

정답 : `A`

- RDS Multi-AZ 배포는 다른 AZ에 동기식 스탠바이를 유지하고 장애 시 자동 페일오버를 제공
- 엔드포인트가 동일하므로 애플리케이션 코드 변경이 필요 없음
- 운영 중 인스턴스 수정으로 Multi-AZ를 활성화하면 최소한의 중단으로 고가용성 확보

오답 이유

- **B. 스냅샷으로 새 Multi-AZ 배포 복원**
    가능하긴 하지만 **새 클러스터로 마이그레이션/컷오버**가 필요해 절차가 복잡하고 다운타임 위험이 큽니다. A가 더 간단하고 다운타임이 적습니다.

- **C. 읽기 복제본 + Route 53**
    **읽기 전용**이므로 쓰기 트래픽을 처리할 수 없습니다. 또한 자동 페일오버가 아니고 애플리케이션/라우팅 변경이 필요합니다.

- **D. RDS를 EC2 Auto Scaling 그룹에 배치**
    RDS는 **관리형 DB 서비스**로 EC2 오토스케일링에 배치할 수 없습니다. 개념적으로 부적절합니다.


## #465
한 회사가 고객 수요를 지원하기 위한 애플리케이션을 개발 중입니다. 회사는 동일한 가용 영역(Availability Zone) 내의 여러 Amazon EC2 Nitro 기반 인스턴스에 애플리케이션을 배포하려고 합니다. 또한 더 높은 애플리케이션 가용성을 달성하기 위해 애플리케이션이 여러 EC2 Nitro 기반 인스턴스의 여러 블록 스토리지 볼륨에 동시에 쓰기(write)할 수 있는 기능을 제공하고자 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 범용 SSD (gp3) EBS 볼륨과 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 사용
B. 처리량 최적화 HDD (st1) EBS 볼륨과 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 사용
C. 프로비저닝된 IOPS SSD (io2) EBS 볼륨과 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 사용
D. 범용 SSD (gp2) EBS 볼륨과 Amazon Elastic Block Store (Amazon EBS) Multi-Attach 사용

```
A company is developing an application to support customer demands. The company wants to deploy the application on multiple Amazon EC2 Nitro-based instances within the same Availability Zone. The company also wants to give the application the ability to write to multiple block storage volumes in multiple EC2 Nitro-based instances simultaneously to achieve higher application availability.  
  
Which solution will meet these requirements?

- A. Use General Purpose SSD (gp3) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach
- B. Use Throughput Optimized HDD (st1) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach
- C. Use Provisioned IOPS SSD (io2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach
- D. Use General Purpose SSD (gp2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach
```

정답 : `C`

- EBS Multi-Attach는 동일 AZ 내 여러 Nitro 기반 인스턴스에 하나의 EBS 볼륨을 동시에 연결하여 다중 쓰기/읽기 접근 가능
	- 애플리케이션 수준의 동시 접근/락 관리 필요
- Multi-Attach는 io1/io2 볼륨만 지원하며 io2는 io1 대비 더 나은 내구성/가격 대비 성능을 제공

오답 이유

- **A (gp3 + Multi-Attach)**: gp3는 **Multi-Attach를 지원하지 않습니다**.
    
- **B (st1 + Multi-Attach)**: st1은 HDD 등급으로 **Multi-Attach 미지원**이며 트랜잭션 워크로드에도 부적합.
    
- **D (gp2 + Multi-Attach)**: gp2 역시 **Multi-Attach 미지원**입니다.


## #466
한 회사는 Amazon EC2(단일 가용 영역)와 Amazon RDS Multi-AZ DB 인스턴스를 사용하는 상태 비저장 2계층 애플리케이션을 설계했습니다. 새로운 경영진은 애플리케이션의 고가용성을 보장하길 원합니다.

요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?

A. 애플리케이션이 Multi-AZ EC2 Auto Scaling을 사용하도록 구성하고 Application Load Balancer를 생성합니다.
B. 애플리케이션이 EC2 인스턴스의 스냅샷을 찍어 다른 AWS 리전으로 전송하도록 구성합니다.
C. Amazon Route 53 지연 시간 기반 라우팅을 구성하여 요청이 애플리케이션으로 전달되도록 합니다.
D. Amazon Route 53 규칙을 구성하여 들어오는 요청을 처리하고 Multi-AZ Application Load Balancer를 생성합니다.

```
A company designed a stateless two-tier application that uses Amazon EC2 in a single Availability Zone and an Amazon RDS Multi-AZ DB instance. New company management wants to ensure the application is highly available.  
  
What should a solutions architect do to meet this requirement?

- A. Configure the application to use Multi-AZ EC2 Auto Scaling and create an Application Load Balancer
- B. Configure the application to take snapshots of the EC2 instances and send them to a different AWS Region
- C. Configure the application to use Amazon Route 53 latency-based routing to feed requests to the application
- D. Configure Amazon Route 53 rules to handle incoming requests and create a Multi-AZ Application Load Balancer
```

정답 : `A`

- 현재 웹/애플리케이션 계층이 단일 AZ에 있어 단일 장애 지점(SPOF)
- 여러 AZ에 EC2 인스턴스를 배치한 오토스케일링 그룹과 그 앞단의 ALB를 구성하면 인스턴스/AZ 장애 시에도 트래픽을 정상 인스턴스로 분산해 고가용성 달성

오답 이유

- **B. 스냅샷을 다른 리전으로 전송**: 백업/재해 복구 목적일 뿐 **실시간 가용성**을 높이지 못합니다. 다운타임 감소에 직접 기여하지 않습니다.
    
- **C. Route 53 지연 시간 기반 라우팅**: 단일 리전/단일 AZ의 단일 엔드포인트만 있을 경우 **효과가 없습니다**. 지연 기반 라우팅은 다수 리전/엔드포인트 전제가 필요합니다.
    
- **D. Route 53 규칙 + Multi-AZ ALB**: ALB만으로는 **백엔드 EC2가 단일 AZ**라면 여전히 SPOF가 남습니다. 핵심은 **EC2를 다중 AZ로 배치**하는 것이며, Route 53은 필수 요소가 아닙니다.


## #467
한 회사가 AWS Organizations를 사용하고 있습니다. 한 멤버 계정이 Compute Savings Plan을 구매했습니다. 그러나 멤버 계정 내 워크로드 변경으로 인해, 해당 계정은 Compute Savings Plan 약정의 전체 혜택을 더 이상 받지 못하고 있습니다. 회사는 구매한 컴퓨팅 파워의 50% 미만만 사용하고 있습니다.

A. Compute Savings Plan을 구매한 멤버 계정의 콘솔에서 Billing Preferences 섹션으로 이동하여 할인 공유(discount sharing)를 활성화합니다.  
B. 회사의 Organizations 관리 계정 콘솔에서 Billing Preferences 섹션으로 이동하여 할인 공유(discount sharing)를 활성화합니다.  
C. 다른 AWS 계정의 추가 컴퓨팅 워크로드를 Compute Savings Plan을 보유한 계정으로 마이그레이션합니다.  
D. 초과 Savings Plan 약정을 Reserved Instance Marketplace에서 판매합니다.

```
A company uses AWS Organizations. A member account has purchased a Compute Savings Plan. Because of changes in the workloads inside the member account, the account no longer receives the full benefit of the Compute Savings Plan commitment. The company uses less than 50% of its purchased compute power.

- A. Turn on discount sharing from the Billing Preferences section of the account console in the member account that purchased the Compute Savings Plan.
- B. Turn on discount sharing from the Billing Preferences section of the account console in the company's Organizations management account.
- C. Migrate additional compute workloads from another AWS account to the account that has the Compute Savings Plan.
- D. Sell the excess Savings Plan commitment in the Reserved Instance Marketplace.
```

정답 : `B`

- Savings Plan 할인은 AWS Organizations에서 "Discount Sharing" 기능이 활성화 돼있을 때 조직 내 다른 계정의 사용량에도 적용될 수 있음
- Compute Savings Plan은 계정 간 공유가 가능하며, 기본적으로 관리 계정에서만 할인 공유 설정을 제어 가능
- 따라서, 현재 특정 멤버 계정에서 구매한 Savings Plan의 사용률이 낮다면, 관리 계정에서 할인 공유를 켜서 조직 전체에 적용하면 다른 계정의 컴퓨팅 사용량에도 할인 혜택을 분배 가능

오답 이유

- **A. 멤버 계정에서 할인 공유 활성화**
    → 할인 공유 설정은 **오직 관리 계정**에서만 수행할 수 있습니다. 멤버 계정에는 이 옵션이 없습니다.

- **C. 다른 계정의 워크로드를 이동**
    → 기술적으로 가능하지만 **운영 비용과 위험이 크며**, 단순히 할인 최적화를 위해 워크로드를 마이그레이션하는 것은 **비효율적**입니다.

- **D. Reserved Instance Marketplace에서 판매**
    → **Savings Plan은 재판매 불가**합니다. RI(Reserved Instance)만 Marketplace에서 판매할 수 있습니다.


## #468
한 회사가 고객을 위한 검색 카탈로그를 제공하는 마이크로서비스 애플리케이션을 개발하고 있습니다.  
회사는 애플리케이션의 프론트엔드를 사용자에게 제공하기 위해 REST API를 사용해야 합니다.  
이 REST API는 회사가 **프라이빗 VPC 서브넷의 컨테이너 내에서 호스팅하는 백엔드 서비스**에 접근해야 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. Amazon API Gateway를 사용하여 WebSocket API를 설계합니다.  
   애플리케이션을 프라이빗 서브넷의 Amazon Elastic Container Service (Amazon ECS)에 호스팅합니다.  
   API Gateway가 Amazon ECS에 접근할 수 있도록 프라이빗 VPC 링크를 생성합니다.

B. Amazon API Gateway를 사용하여 REST API를 설계합니다.  
   애플리케이션을 프라이빗 서브넷의 Amazon Elastic Container Service (Amazon ECS)에 호스팅합니다.  
   API Gateway가 Amazon ECS에 접근할 수 있도록 프라이빗 VPC 링크를 생성합니다.

C. Amazon API Gateway를 사용하여 WebSocket API를 설계합니다.  
   애플리케이션을 프라이빗 서브넷의 Amazon Elastic Container Service (Amazon ECS)에 호스팅합니다.  
   API Gateway가 Amazon ECS에 접근할 수 있도록 보안 그룹을 생성합니다.

D. Amazon API Gateway를 사용하여 REST API를 설계합니다.  
   애플리케이션을 프라이빗 서브넷의 Amazon Elastic Container Service (Amazon ECS)에 호스팅합니다.  
   API Gateway가 Amazon ECS에 접근할 수 있도록 보안 그룹을 생성합니다.

```
A company is developing a microservices application that will provide a search catalog for customers. The company must use REST APIs to present the frontend of the application to users. The REST APIs must access the backend services that the company hosts in containers in private VPC subnets.  
  
Which solution will meet these requirements?

- A. Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.
- B. Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.
- C. Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS.
- D. Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS.
```

정답 : `B`

- "REST API"를 요구하므로 API Gateway의 REST API 유형을 사용해야 함
- 백엔드 서비스가 프라이빗 서브넷의 ECS 컨테이너에서 실행되므로, API Gateway가 퍼블릭 네트워크 대신 VPC 내부로 안전하게 연결되어야 함
	- 이때 필요한 구성은 VPC Link(Private Integration): API Gateway → Private NLB → ECS 서비스
	- VPC Link: API Gateway가 VPC 내부의 프라이빗 리소스에 접근할 수 있게 하는 PrivateLink 기반 전용 통로
- 보안 그룹 설정만으로는 퍼블릭 API Gateway가 프라이빗 서브넷 리소스에 직접 접근할 수 없으므로 VPC Link가 필수

오답 이유

- **A (WebSocket + VPC Link)**
    WebSocket은 **양방향 통신(예: 채팅, 실시간 데이터)** 용도이며, 문제는 “REST API”를 요구하므로 부적절.

- **C (WebSocket + Security Group)**
    위와 동일하게 REST 요구사항에 어긋나며, Security Group만으로 API Gateway와 프라이빗 서브넷 간 직접 통신 불가.

- **D (REST + Security Group)**
    API Gateway는 **VPC 외부 서비스**이며, VPC 내부 리소스(ECS Private Subnet)로 접근하려면 **VPC Link**가 필요.
    Security Group만으로는 라우팅 불가능.


## #469
한 회사가 수집된 원시 데이터를 Amazon S3 버킷에 저장하고 있습니다. 이 데이터는 회사의 고객을 대신해 여러 종류의 분석에 사용됩니다. 요청된 분석의 유형에 따라 S3 객체에 대한 액세스 패턴이 달라집니다.

회사는 이러한 액세스 패턴을 예측하거나 제어할 수 없습니다. 또한 S3 비용을 줄이길 원합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. S3 복제를 사용하여 자주 액세스되지 않는 객체를 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환합니다.  
B. S3 Lifecycle 규칙을 사용하여 객체를 S3 Standard에서 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환합니다.  
C. S3 Lifecycle 규칙을 사용하여 객체를 S3 Standard에서 S3 Intelligent-Tiering으로 전환합니다.  
D. S3 Inventory를 사용하여 액세스되지 않은 객체를 식별하고 S3 Standard에서 S3 Intelligent-Tiering으로 전환합니다.

```
A company stores raw collected data in an Amazon S3 bucket. The data is used for several types of analytics on behalf of the company's customers. The type of analytics requested determines the access pattern on the S3 objects.  
  
The company cannot predict or control the access pattern. The company wants to reduce its S3 costs.  
  
Which solution will meet these requirements?

- A. Use S3 replication to transition infrequently accessed objects to S3 Standard-Infrequent Access (S3 Standard-IA)
- B. Use S3 Lifecycle rules to transition objects from S3 Standard to Standard-Infrequent Access (S3 Standard-IA)
- C. Use S3 Lifecycle rules to transition objects from S3 Standard to S3 Intelligent-Tiering
- D. Use S3 Inventory to identify and transition objects that have not been accessed from S3 Standard to S3 Intelligent-Tiering
```

정답 : `C`

- 문제의 핵심은 "액세스 패턴을 예측하거나 제어할 수 없음"
- S3 Intelligent-Tiering은 객체별로 접근 패턴을 자동으로 모니터링하고
	- 자주 접근되는 데이터는 Frequent Access Tier, 거의 접근되지 않는 데이터는 Infrequent Access Tier로 자동 전환
- 사용자가 명시적으로 주기를 정하거나 패턴을 예측할 필요가 없기 때문에 예측 불가능한 액세스 패턴에 대해 가장 비용 효율적인 솔루션

오답 이유

- **A. S3 Replication → Standard-IA 전환**
    S3 복제(Replication)는 다른 버킷이나 리전에 데이터를 복제하기 위한 기능으로,
    **스토리지 클래스 전환 기능이 아님**. 비용 절감 목적에 부적합.

- **B. Lifecycle → Standard-IA**
    Standard-IA는 “드물게 접근되지만 장기 보관” 시 유리하나,
    **예측 불가능한 액세스 패턴에서는 잦은 접근이 발생할 경우 높은 요금(조회 비용)** 이 발생할 수 있음.

- **D. S3 Inventory로 식별 후 전환**
    Inventory는 **리포팅 도구**일 뿐 자동 전환 기능이 없습니다.
    별도의 처리 로직이 필요하여 **운영 오버헤드가 증가**합니다.


## #470
한 회사는 IPv6 주소를 사용하는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다.  
이 애플리케이션들은 인터넷을 사용하여 다른 외부 애플리케이션과 통신을 시작해야 합니다.  
그러나 회사의 보안 정책에 따르면, 어떤 외부 서비스도 EC2 인스턴스에 대한 연결을 시작할 수 없습니다.  

이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?

A. NAT 게이트웨이를 생성하고 서브넷의 라우팅 테이블 대상지로 설정합니다.  
B. 인터넷 게이트웨이를 생성하고 서브넷의 라우팅 테이블 대상지로 설정합니다.  
C. 가상 프라이빗 게이트웨이를 생성하고 서브넷의 라우팅 테이블 대상지로 설정합니다.  
D. Egress 전용 인터넷 게이트웨이를 생성하고 서브넷의 라우팅 테이블 대상지로 설정합니다.

```
A company has applications hosted on Amazon EC2 instances with IPv6 addresses. The applications must initiate communications with other external applications using the internet. However the company’s security policy states that any external service cannot initiate a connection to the EC2 instances.  
  
What should a solutions architect recommend to resolve this issue?

- A. Create a NAT gateway and make it the destination of the subnet's route table
- B. Create an internet gateway and make it the destination of the subnet's route table
- C. Create a virtual private gateway and make it the destination of the subnet's route table
- D. Create an egress-only internet gateway and make it the destination of the subnet's route table
```

정답 : `D`

- IPv6 트래픽의 경우 NAT 게이트웨이 사용 불가능
- Egress-only Internet Gateway는 IPv6 전용으로, 내부 인스턴스가 인터넷으로 아웃바운드 연결은 허용하지만 외부에서의 인바운드 연결은 차단

오답 이유

- **A. NAT 게이트웨이**
    NAT 게이트웨이는 IPv4 전용입니다. IPv6 주소를 사용하는 인스턴스에는 사용할 수 없습니다.

- **B. 인터넷 게이트웨이**
    인터넷 게이트웨이는 양방향(ingress 및 egress) 트래픽을 모두 허용합니다.
    따라서 외부 서비스가 EC2 인스턴스로 연결을 시작할 수 있어 보안 정책을 위반합니다.

- **C. 가상 프라이빗 게이트웨이(Virtual Private Gateway)**
    이는 VPN 연결 또는 AWS Direct Connect 연결용으로 사용됩니다.
    일반적인 인터넷 통신에는 사용되지 않습니다.


## #471
한 회사가 VPC 내의 컨테이너에서 실행되는 애플리케이션을 만들고 있습니다.  
이 애플리케이션은 Amazon S3 버킷에 데이터를 저장하고 액세스합니다.  
개발 단계 동안, 애플리케이션은 매일 1TB의 데이터를 Amazon S3에 저장하고 액세스할 예정입니다.  
회사는 **비용을 최소화**하고, 가능하다면 **인터넷을 통해 트래픽이 이동하는 것을 방지**하고자 합니다.  

이 요구사항을 충족하는 솔루션은 무엇입니까?

A. S3 버킷에 S3 Intelligent-Tiering 활성화  
B. S3 버킷에 S3 Transfer Acceleration 활성화  
C. Amazon S3용 게이트웨이 VPC 엔드포인트를 생성하고, 이 엔드포인트를 VPC의 모든 라우팅 테이블에 연결  
D. Amazon S3용 인터페이스 엔드포인트를 VPC에 생성하고, 이 엔드포인트를 VPC의 모든 라우팅 테이블에 연결

```
A company is creating an application that runs on containers in a VPC. The application stores and accesses data in an Amazon S3 bucket. During the development phase, the application will store and access 1 TB of data in Amazon S3 each day. The company wants to minimize costs and wants to prevent traffic from traversing the internet whenever possible.  
  
Which solution will meet these requirements?

- A. Enable S3 Intelligent-Tiering for the S3 bucket
- B. Enable S3 Transfer Acceleration for the S3 bucket
- C. Create a gateway VPC endpoint for Amazon S3. Associate this endpoint with all route tables in the VPC
- D. Create an interface endpoint for Amazon S3 in the VPC. Associate this endpoint with all route tables in the VPC
```

정답 : `C`

- S3 게이트웨이 VPC 엔드포인트는 Amazon S3 및 DynamoDB 전용으로 제공되는 가장 비용 효율적인 프라이빗 연결 방법
- VPC 내부 트래픽이 인터넷을 거치지 않고 AWS 네트워크 내에서 S3에 직접 연결

오답 이유

- **A. S3 Intelligent-Tiering 활성화**
    - 저장 클래스 자동 전환으로 **S3 스토리지 비용**을 줄일 수는 있지만, 트래픽 라우팅(인터넷 통신)과는 전혀 관련 없음
    
- **B. S3 Transfer Acceleration 활성화**
    - CloudFront 엣지 로케이션을 통해 전송 속도 향상 → 오히려 **인터넷 경유 비용 증가** + **추가 요금 발생**
    
- **D. 인터페이스 엔드포인트 사용**
    - S3용 인터페이스 엔드포인트는 존재하지 않으며, 인터페이스 엔드포인트는 PrivateLink 기반으로 다른 AWS 서비스(API Gateway 등)에 사용됨.
    - S3는 **게이트웨이 엔드포인트**만 지원함

## #472
한 회사는 Amazon DynamoDB를 기반으로 한 데이터 저장소를 사용하는 모바일 채팅 애플리케이션을 가지고 있습니다.  
사용자들은 새로운 메시지가 가능한 한 낮은 지연 시간으로 읽히기를 원합니다.  
솔루션스 아키텍트는 최소한의 애플리케이션 변경으로 최적의 솔루션을 설계해야 합니다.

솔루션스 아키텍트가 선택해야 하는 방법은 무엇입니까?

A. 새로운 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. 코드를 DAX 엔드포인트를 사용하도록 업데이트합니다.  
B. 증가한 읽기 부하를 처리하기 위해 DynamoDB 읽기 복제본을 추가합니다. 애플리케이션을 읽기 복제본의 읽기 엔드포인트를 가리키도록 업데이트합니다.  
C. DynamoDB의 새로운 메시지 테이블에 대한 읽기 용량 단위를 두 배로 늘립니다. 기존 DynamoDB 엔드포인트를 계속 사용합니다.  
D. 애플리케이션 스택에 Amazon ElastiCache for Redis 캐시를 추가합니다. 애플리케이션을 DynamoDB 대신 Redis 캐시 엔드포인트를 가리키도록 업데이트합니다.

```
A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes.  
  
Which method should the solutions architect select?

- A. Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint.
- B. Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas.
- C. Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint.
- D. Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB.
```

정답 : `A`

- DAX는 DynamoDB 전용 인메모리 캐시로 마이크로초~밀리초 수준의 읽기 지연을 제공
- 애플리케이션 변경은 엔드포인트만 DAX로 교체하면 되는 수준

오답 이유

- **B. DynamoDB 읽기 복제본 추가**
    - DynamoDB에는 일반적인 의미의 “읽기 복제본(read replica)” 개념이 없습니다. 글로벌 테이블은 다지역 복제이지만 지연 시간 최적화 목적/구성 방식이 다르고, 이 선택지의 표현과 맞지 않습니다. 또한 앱 변경이 더 큽니다.
    
- **C. 읽기 용량 단위(RCU) 두 배**
    - RCU 증설은 **처리량(스루풋)** 문제 해결책이며, **지연 시간**을 획기적으로 낮추지 않습니다. 요구사항은 “가능한 한 낮은 지연 시간”입니다.
    
- **D. ElastiCache for Redis 추가**
    - 범용 캐시로 지연을 줄일 수는 있으나, **키 설계·동기화·무효화** 등 애플리케이션 변경 및 운영 복잡도가 커집니다. “최소한의 애플리케이션 변경” 조건에 덜 적합합니다. 또한 DynamoDB 전용 최적화인 DAX가 더 직접적인 해법입니다.


## #473
한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹사이트를 호스팅하고 있습니다.  
이 웹사이트는 정적 콘텐츠를 제공합니다. 웹사이트 트래픽이 증가하고 있으며, 회사는 비용 증가 가능성에 대해 우려하고 있습니다.

A. 엣지 로케이션에서 상태 파일을 캐시하기 위해 Amazon CloudFront 배포를 생성합니다.  
B. Amazon ElastiCache 클러스터를 생성합니다. 캐시된 파일을 제공하기 위해 ALB를 ElastiCache 클러스터에 연결합니다.  
C. AWS WAF 웹 ACL을 생성하여 ALB와 연결합니다. 정적 파일을 캐시하도록 웹 ACL에 규칙을 추가합니다.  
D. 대안적인 AWS 리전에 두 번째 ALB를 생성합니다. 데이터 전송 비용을 최소화하기 위해 사용자 트래픽을 가장 가까운 리전으로 라우팅합니다.

```
A company hosts a website on Amazon EC2 instances behind an Application Load Balancer (ALB). The website serves static content. Website traffic is increasing, and the company is concerned about a potential increase in cost.

- A. Create an Amazon CloudFront distribution to cache state files at edge locations
- B. Create an Amazon ElastiCache cluster. Connect the ALB to the ElastiCache cluster to serve cached files
- C. Create an AWS WAF web ACL and associate it with the ALB. Add a rule to the web ACL to cache static files
- D. Create a second ALB in an alternative AWS Region. Route user traffic to the closest Region to minimize data transfer costs
```

정답 : `A`

- 정적 콘텐츠는 Amazon CloudFront를 통해 엣지에서 캐시하면 원본(EC2 behind ALB)으로의 요청과 데이터 전송을 줄여 성능을 높이고 비용 절감

오답 이유

- **B. ElastiCache에 ALB 연결**
    - ElastiCache(Redis/Memcached)는 **애플리케이션 레벨** 캐시로, ALB가 직접 연결해 정적 파일을 제공하는 구조가 아닙니다. HTTP 객체 캐싱/전송 최적화 용도가 아니며, 웹 정적 자산 캐싱은 CloudFront가 담당합니다.

    
- **C. WAF로 캐싱**
    - **AWS WAF는 보안(필터링/차단) 서비스**입니다. 캐싱 기능이 없습니다. 정적 파일 캐시는 CloudFront의 역할입니다.

    
- **D. 리전에 ALB 추가 후 지리 라우팅**
    - 다지역 ALB만으로는 정적 콘텐츠 캐싱/전송 최적화가 되지 않습니다. 오히려 운영 복잡성과 비용이 증가할 수 있으며, 비용 절감 목적에 부합하지 않습니다. 글로벌 전송 최적화와 비용 절감에는 CloudFront가 적합합니다.


## #474
한 회사는 다른 리전의 워크로드와 격리된 워크로드를 지원하고 실행하기 위해 여러 AWS 리전에 걸쳐 여러 VPC를 보유하고 있습니다.  
최근 애플리케이션 출시 요구사항으로 인해, 회사의 모든 VPC들은 모든 리전에 있는 다른 모든 VPC들과 통신해야 합니다.

다음 중 관리 작업을 가장 적게 하면서 이러한 요구사항을 충족할 수 있는 솔루션은 무엇입니까?

A. 단일 리전에서 VPC 통신을 관리하기 위해 VPC 피어링을 사용합니다. 리전 간 VPC 통신을 관리하기 위해 리전 간 VPC 피어링을 사용합니다.  
B. 모든 리전에 걸쳐 AWS Direct Connect 게이트웨이를 사용하여 리전 간 VPC들을 연결하고 VPC 통신을 관리합니다.  
C. 단일 리전에서 VPC 통신을 관리하기 위해 AWS Transit Gateway를 사용하고, 리전 간 VPC 통신을 관리하기 위해 Transit Gateway 피어링을 사용합니다.  
D. 모든 리전에 걸쳐 AWS PrivateLink를 사용하여 리전 간 VPC들을 연결하고 VPC 통신을 관리합니다.

```
A company has multiple VPCs across AWS Regions to support and run workloads that are isolated from workloads in other Regions. Because of a recent application launch requirement, the company’s VPCs must communicate with all other VPCs across all Regions.  
  
Which solution will meet these requirements with the LEAST amount of administrative effort?

- A. Use VPC peering to manage VPC communication in a single Region. Use VPC peering across Regions to manage VPC communications.
- B. Use AWS Direct Connect gateways across all Regions to connect VPCs across regions and manage VPC communications.
- C. Use AWS Transit Gateway to manage VPC communication in a single Region and Transit Gateway peering across Regions to manage VPC communications.
- D. Use AWS PrivateLink across all Regions to connect VPCs across Regions and manage VPC communications
```

정답 : `C`

- AWS Transit Gateway(TGW)는 다수의 VPC를 허브-스포크 형태로 중앙에서 연결･라우팅 관리 가능
- 리전 간에는 Transit Gateway 피어링으로 TGW 간에 연결해 전역 메시 구조를 간소화

오답 이유

- **A. VPC 피어링(동일/리전 간)**
    - VPC 간 각각 피어링을 맺어야 하므로 VPC 수가 많을수록 **풀메시 관리 지옥(N² 링크, 다수의 라우트 업데이트)** 발생. 대규모 전역 연결에 부적합.

    
- **B. Direct Connect 게이트웨이**
    - DX 게이트웨이는 **온프레미스 ↔ 여러 VPC/리전** 연결을 단순화하는 용도. **VPC ↔ VPC 간 라우팅을 직접 해결**하는 메커니즘이 아님. 요구사항(모든 VPC 상호 통신)과 불일치.

    
- **D. AWS PrivateLink**
    - 특정 서비스(엔드포인트)를 **소비자 VPC에 프라이빗으로 노출**하는 모델(서비스 퍼블리셔-컨슈머). 범용 **VPC 간 레이어3 라우팅** 대체가 아님. 모든 서브넷/포트 트래픽을 자유롭게 주고받는 목적에 부적합.


## #475
한 회사가 Amazon Elastic Container Service (Amazon ECS)를 사용하여 컨테이너화된 애플리케이션을 설계하고 있습니다.  
이 애플리케이션은 고도로 내구성이 뛰어나며, 다른 AWS 리전으로 데이터를 복구할 수 있는 공유 파일 시스템에 접근해야 합니다.  
복구 시점 목표(RPO)는 8시간입니다. 또한, 파일 시스템은 리전 내의 각 가용 영역(Availability Zone)에 마운트 대상을 제공해야 합니다.

솔루션스 아키텍트는 AWS Backup을 사용하여 다른 리전으로의 복제를 관리하고자 합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 멀티 AZ 배포로 구성된 Amazon FSx for Windows File Server  
B. 멀티 AZ 배포로 구성된 Amazon FSx for NetApp ONTAP  
C. Standard 스토리지 클래스를 사용하는 Amazon Elastic File System (Amazon EFS)  
D. Amazon FSx for OpenZFS

```
A company is designing a containerized application that will use Amazon Elastic Container Service (Amazon ECS). The application needs to access a shared file system that is highly durable and can recover data to another AWS Region with a recovery point objective (RPO) of 8 hours. The file system needs to provide a mount target m each Availability Zone within a Region.  
  
A solutions architect wants to use AWS Backup to manage the replication to another Region.  
  
Which solution will meet these requirements?

- A. Amazon FSx for Windows File Server with a Multi-AZ deployment
- B. Amazon FSx for NetApp ONTAP with a Multi-AZ deployment
- C. Amazon Elastic File System (Amazon EFS) with the Standard storage class
- D. Amazon FSx for OpenZFS
```

정답 : `C`

- EFS는 리전별 서비스로 각 AZ마다 마운트 대상을 제공하며, 다중 AZ에 걸쳐 데이터를 저장하는 높은 내구성을 기본 제공
- AWS Backup과 네이티브 통합되어 정기 스케줄 백업 및 교차 리전 백업 복사를 설정할 수 있어 백업 주기를 8시간으로 구성해 RPO 8시간 충족
- ECS에서 EFS 볼륨으로 간단히 마운트할 수 있어 운영 복잡도가 낮음

오답 이유

- **A. FSx for Windows File Server (Multi-AZ)**
    - SMB 기반 **Windows 워크로드**에 적합하며, Linux 기반 ECS 컨테이너와의 **호환성이 떨어집니다**.
    - AWS Backup 백업/복원은 가능하지만, 문제의 **“각 AZ에 마운트 대상”** 요구는 **EFS의 네이티브 특성**에 더 부합합니다.
    
- **B. FSx for NetApp ONTAP (Multi-AZ)**
    - AWS Backup으로 백업/교차 리전 복사 가능하나, **ECS + 표준 NFS 공유** 요구와 **AZ별 마운트 타깃 제공**이라는 조건에는 **EFS가 더 직접적이고 단순**한 해법입니다.
    - 또한 ONTAP는 기능이 풍부하지만 **구성/운영 복잡도와 비용**이 상대적으로 큽니다. 요구사항 달성에 **과도한 솔루션**일 수 있습니다.
    
- **D. FSx for OpenZFS**
    - 고성능 NFS 파일 시스템이지만, 서비스 특성상 **리전 전역(각 AZ 마운트 타깃) 형태의 제공 모델이 아닙니다**.
    - 교차 리전 복구를 하려면 백업/복원으로 우회해야 하고, **ECS에서의 광범위한 멀티 AZ 마운트 요구**에는 **EFS가 더 적합**합니다.

## #476
회사는 가까운 미래에 급격한 성장을 예상하고 있습니다. 솔루션스 아키텍트는 기존 사용자들을 구성하고 AWS에서 새 사용자들에게 권한을 부여해야 합니다. 솔루션스 아키텍트는 IAM 그룹을 생성하기로 결정했습니다. 솔루션스 아키텍트는 부서별로 새 사용자들을 IAM 그룹에 추가할 예정입니다.

새 사용자에게 권한을 부여하기 위한 가장 보안적인 추가 작업은 무엇입니까?

A. 서비스 제어 정책(SCP)을 적용하여 액세스 권한을 관리한다.  
B. 최소 권한을 가진 IAM 역할을 생성하고, 해당 역할을 IAM 그룹에 연결한다.  
C. 최소 권한을 가진 IAM 정책을 생성하고, 해당 정책을 IAM 그룹에 연결한다.  
D. IAM 역할을 생성하고, 최대 권한을 정의하는 권한 경계(permissions boundary)를 역할에 연결한다.

```
A company is expecting rapid growth in the near future. A solutions architect needs to configure existing users and grant permissions to new users on AWS. The solutions architect has decided to create IAM groups. The solutions architect will add the new users to IAM groups based on department.  
  
Which additional action is the MOST secure way to grant permissions to the new users?

- A. Apply service control policies (SCPs) to manage access permissions
- B. Create IAM roles that have least privilege permission. Attach the roles to the IAM groups
- C. Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups
- D. Create IAM roles. Associate the roles with a permissions boundary that defines the maximum permissions
```

정답 : `C`

- IAM 그룹에 정책을 직접 연갈하는 것이 여러 사용자에게 일관된 최소 권한을 적용하는 가장 일반적이고 보안적인 방법
- IAM 그룹은 단순히 사용자 모음을 의미하므로, 그룹에 IAM 정책을 연결하면 그룹에 속한 모든 사용자에게 동일한 권한이 적용
- 이렇게 하면 신규 사용자를 그룹에 추가하기만 해도 자동으로 올바른 권한이 부여

오답 이유

**A. 서비스 제어 정책(SCP)을 적용하여 액세스 권한을 관리**
- SCP는 **AWS Organizations** 수준에서 **계정 전체의 최대 허용 권한을 제어**하는 용도입니다.
- 개별 사용자나 그룹의 세부 권한 관리에는 부적절합니다.

**B. 최소 권한을 가진 IAM 역할을 생성하고, 해당 역할을 IAM 그룹에 연결**
- IAM 역할(Role)은 **그룹에 직접 연결할 수 없습니다.**
- 역할은 EC2, Lambda, 다른 계정의 사용자 등 **임시 보안 주체**가 가정(assume)할 때 사용하는 것입니다.

**D. IAM 역할을 생성하고, 최대 권한을 정의하는 권한 경계(permissions boundary)를 역할에 연결**
- 권한 경계(permissions boundary)는 **개별 IAM 사용자나 역할의 최대 허용 한도를 제한**하는 기능입니다.
- 이는 상위 제한(guardrail)로 유용하지만, 기본적인 그룹 기반 권한 부여를 대체하지는 못합니다.

## #477

## #478
한 로펌이 대중과 정보를 공유해야 합니다. 정보에는 공개적으로 읽을 수 있어야 하는 수백 개의 파일이 포함되어 있습니다. 지정된 미래 날짜 이전에는 누구든지 파일을 수정하거나 삭제하는 것이 금지됩니다.

이 요구 사항을 가장 안전한 방식으로 충족하는 솔루션은 무엇입니까?

A. 정적 웹사이트 호스팅으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. 지정된 날짜까지 S3 버킷에 액세스하는 모든 AWS 주체에게 읽기 전용 IAM 권한을 부여합니다.
B. S3 버전 관리를 활성화한 새 Amazon S3 버킷을 생성합니다. 지정된 날짜에 맞는 보존 기간으로 S3 Object Lock을 사용합니다. S3 버킷을 정적 웹사이트 호스팅으로 구성합니다. 객체에 대한 읽기 전용 액세스를 허용하도록 S3 버킷 정책을 설정합니다.
C. S3 버전 관리를 활성화한 새 Amazon S3 버킷을 생성합니다. 객체가 수정되거나 삭제될 경우 AWS Lambda 함수를 실행하도록 이벤트 트리거를 구성합니다. 원본 버전을 개인 S3 버킷에서 복원하도록 Lambda 함수를 구성합니다.
D. 정적 웹사이트 호스팅으로 구성된 Amazon S3 버킷에 모든 파일을 업로드합니다. 파일이 포함된 폴더를 선택합니다. 지정된 날짜에 맞는 보존 기간으로 S3 Object Lock을 사용합니다. S3 버킷에 액세스하는 모든 AWS 주체에게 읽기 전용 IAM 권한을 부여합니다.

```
A law firm needs to share information with the public. The information includes hundreds of files that must be publicly readable. Modifications or deletions of the files by anyone before a designated future date are prohibited.  
  
Which solution will meet these requirements in the MOST secure way?

- A. Upload all files to an Amazon S3 bucket that is configured for static website hosting. Grant read-only IAM permissions to any AWS principals that access the S3 bucket until the designated date.
- B. Create a new Amazon S3 bucket with S3 Versioning enabled. Use S3 Object Lock with a retention period in accordance with the designated date. Configure the S3 bucket for static website hosting. Set an S3 bucket policy to allow read-only access to the objects.
- C. Create a new Amazon S3 bucket with S3 Versioning enabled. Configure an event trigger to run an AWS Lambda function in case of object modification or deletion. Configure the Lambda function to replace the objects with the original versions from a private S3 bucket.
- D. Upload all files to an Amazon S3 bucket that is configured for static website hosting. Select the folder that contains the files. Use S3 Object Lock with a retention period in accordance with the designated date. Grant read-only IAM permissions to any AWS principals that access the S3 bucket.
```

정답 : `B`

- 지정된 날짜 전까지 어떠한 주체(루트 포함)도 객체를 수정/삭제 못하게 하는 불변성 → S3 Object Lock(컴플라이언스 모드)로 만족
- 공개 읽기는 버킷 정책 또는 정적 웹사이트 호스팅과 함께 안전하게 구성
	- R/W 통제를 IAM 만으로는 불변성 보장 불가

오답 이유

- **A. S3 정적 웹사이트 + 읽기 전용 IAM 권한**
    - IAM 권한만으로는 **삭제/수정 금지의 ‘절대적 불변성’** 을 보장하지 못합니다(권한 변경 가능, 루트/관리자에 의해 우회 가능). **Object Lock 미사용**이 치명적입니다.
    
- **C. S3 버전 관리 + 이벤트 트리거 Lambda로 되돌리기**
    - 사후 복구 방식으로 **삭제/수정 자체를 방지하지 못함**. 이벤트 지연/실패 시 **짧은 노출 창구**가 생기며, 컴플라이언스 수준의 **WORM 요건 미충족**입니다.
    
- **D. 폴더 선택 후 Object Lock 적용 + IAM 읽기 전용**
    - **Object Lock은 버킷 단위 설정(버킷 생성 시 활성화 필요)** 이며, “폴더만 선택 적용” 개념이 아닙니다. 또한 IAM만으로는 불변성 보장 불가입니다. 전제 요건 위반으로 부적합합니다.

## #479
한 회사는 새로운 웹사이트를 위한 인프라의 프로토타입을 수동으로 프로비저닝하여 만들고 있습니다. 이 인프라에는 Auto Scaling 그룹, Application Load Balancer, 그리고 Amazon RDS 데이터베이스가 포함됩니다. 구성에 대해 철저한 검증을 마친 후, 회사는 개발 및 프로덕션 용도로 두 개의 가용 영역에서 인프라를 자동화된 방식으로 즉시 배포할 수 있는 기능을 원합니다.

이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?

A. AWS Systems Manager를 사용하여 두 개의 가용 영역에서 프로토타입 인프라를 복제하고 프로비저닝합니다.
B. 프로토타입 인프라를 가이드로 사용하여 템플릿으로 인프라를 정의합니다. AWS CloudFormation으로 인프라를 배포합니다.
C. AWS Config를 사용하여 프로토타입 인프라에 사용되는 리소스의 인벤토리를 기록합니다. AWS Config를 사용하여 두 개의 가용 영역에 프로토타입 인프라를 배포합니다.
D. AWS Elastic Beanstalk을 사용하고 프로토타입 인프라에 대한 자동화된 참조를 사용하도록 구성하여 두 개의 가용 영역에 새로운 환경을 자동으로 배포합니다.

```
A company is making a prototype of the infrastructure for its new website by manually provisioning the necessary infrastructure. This infrastructure includes an Auto Scaling group, an Application Load Balancer and an Amazon RDS database. After the configuration has been thoroughly validated, the company wants the capability to immediately deploy the infrastructure for development and production use in two Availability Zones in an automated fashion.  
  
What should a solutions architect recommend to meet these requirements?

- A. Use AWS Systems Manager to replicate and provision the prototype infrastructure in two Availability Zones
- B. Define the infrastructure as a template by using the prototype infrastructure as a guide. Deploy the infrastructure with AWS CloudFormation.
- C. Use AWS Config to record the inventory of resources that are used in the prototype infrastructure. Use AWS Config to deploy the prototype infrastructure into two Availability Zones.
- D. Use AWS Elastic Beanstalk and configure it to use an automated reference to the prototype infrastructure to automatically deploy new environments in two Availability Zones.
```

정답 : `B`

- 검증된 구성을 코드(IaC)로 템플릿화하면 개발/프로덕션 환경을 반복 가능하고 일관되게 두 개 AZ에 즉시 배포 가능
- CloudFormation은 Auto Scaling 그룹, ALB, RDS(Multi-AZ 포함) 등 모든 스택을 선언적으로 정의･프로비저닝하며 매개변수/매핑/조건을 통해 환경별 차이도 쉽게 관리

오답 이유

- **A. AWS Systems Manager**
    - 패치/런커맨드/파라미터/오토메이션 등 **운영 관리 도구**이며, **네트워크·ASG·ALB·RDS 전체 스택을 복제·프로비저닝하는 IaC 도구가 아님**.
    
- **C. AWS Config**
    - 리소스 **구성 기록/규정 준수 평가** 서비스로, **인프라 배포 기능이 목적이 아님**. 기록된 인벤토리로 **스택 재생성 불가**.
    
- **D. AWS Elastic Beanstalk**
    - 애플리케이션 배포 추상화 서비스로, 문제의 “프로토타입 인프라에 대한 자동 참조”라는 기능은 없음. 세밀한 **VPC/서브넷/ALB/RDS 설계 재현**에는 **CloudFormation이 적합**.


## #480
한 비즈니스 애플리케이션이 Amazon EC2에서 호스팅되고 있으며, 암호화된 객체 스토리지를 위해 Amazon S3를 사용하고 있습니다.  
최고 정보 보안 책임자(CISO)는 두 서비스 간의 모든 애플리케이션 트래픽이 공용 인터넷을 통하지 않아야 한다고 지시했습니다.

이 컴플라이언스 요구사항을 충족하기 위해 솔루션스 아키텍트가 사용해야 하는 기능은 무엇입니까?

A. AWS Key Management Service (AWS KMS)  
B. VPC 엔드포인트(VPC endpoint)  
C. 프라이빗 서브넷(Private subnet)  
D. 가상 프라이빗 게이트웨이(Virtual private gateway)

```
A business application is hosted on Amazon EC2 and uses Amazon S3 for encrypted object storage. The chief information security officer has directed that no application traffic between the two services should traverse the public internet.  
  
Which capability should the solutions architect use to meet the compliance requirements?

- A. AWS Key Management Service (AWS KMS)
- B. VPC endpoint
- C. Private subnet
- D. Virtual private gateway
```

정답 : `B`

- EC2 인스턴스가 S3와 통신할 때, 기본적으로 트래픽은 IGW를 통해 공용 인터넷을 통과
- VPC 엔드포인트를 사용하면 VPC 내부에서 S3에 비공개 연결(PrivateLink) 가능
- S3는 게이트웨이 엔드포인트를 사용하며, 이 엔드포인트는 트래픽을 AWS 네트워크 내에서만 라우팅

오답 이유

- **A. AWS Key Management Service (AWS KMS)**
    - 객체 암호화 키를 관리하는 서비스로, 네트워크 경로(공용 인터넷 통과 여부)와는 **무관**합니다.
    - 암호화는 데이터 보호 수준을 높이지만, 트래픽이 인터넷을 통과하지 않도록 하지는 않습니다.
    
- **C. Private subnet**
    - 프라이빗 서브넷은 **인터넷 게이트웨이에 라우팅되지 않는 서브넷**이지만, S3와의 통신 시에는 여전히 인터넷 게이트웨이 또는 NAT 게이트웨이가 필요합니다.
    - 따라서 **S3와의 직접적 사설 연결**을 제공하지 않으며, **VPC 엔드포인트**가 추가로 필요합니다.
    
- **D. Virtual private gateway**
    - 이는 **온프레미스 네트워크와 VPC 간 VPN 연결**을 위한 구성요소입니다.
    - EC2 ↔ S3 간 내부 트래픽 제어와는 관계가 없습니다.