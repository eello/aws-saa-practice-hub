---
created: 2025-09-29 11:34:54
last_modified: 2025-09-29 16:00:36
---
## #161
한 회사가 JSON 문서를 처리하고 결과를 온프레미스 SQL 데이터베이스에 출력하는 작은 Python 애플리케이션을 보유하고 있습니다. 애플리케이션은 하루에 수천 번 실행됩니다. 회사는 애플리케이션을 AWS 클라우드로 이전하려고 합니다. 회사는 **높은 가용성**, **최대 확장성**, 그리고 **운영 오버헤드를 최소화**할 수 있는 솔루션이 필요합니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. JSON 문서를 Amazon S3 버킷에 저장합니다. Python 코드를 여러 Amazon EC2 인스턴스에서 실행하여 문서를 처리합니다. 결과는 Amazon Aurora DB 클러스터에 저장합니다.  

B. JSON 문서를 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 생성하여 S3 버킷에 문서가 도착할 때마다 Python 코드를 실행하여 문서를 처리합니다. 결과는 Amazon Aurora DB 클러스터에 저장합니다.  

C. JSON 문서를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. EBS Multi-Attach 기능을 사용하여 볼륨을 여러 Amazon EC2 인스턴스에 연결합니다. Python 코드를 EC2 인스턴스에서 실행하여 문서를 처리합니다. 결과는 Amazon RDS DB 인스턴스에 저장합니다.  

D. JSON 문서를 Amazon Simple Queue Service(Amazon SQS) 큐에 메시지로 저장합니다. Python 코드를 컨테이너로 Amazon Elastic Container Service(Amazon ECS) 클러스터에 배포하고 Amazon EC2 시작 유형으로 구성합니다. 컨테이너를 사용하여 SQS 메시지를 처리합니다. 결과는 Amazon RDS DB 인스턴스에 저장합니다.


```
A company has a small Python application that processes JSON documents and outputs the results to an on-premises SQL database. The application runs thousands of times each day. The company wants to move the application to the AWS Cloud. The company needs a highly available solution that maximizes scalability and minimizes operational overhead.  
  
Which solution will meet these requirements?

- A. Place the JSON documents in an Amazon S3 bucket. Run the Python code on multiple Amazon EC2 instances to process the documents. Store the results in an Amazon Aurora DB cluster.
- B. Place the JSON documents in an Amazon S3 bucket. Create an AWS Lambda function that runs the Python code to process the documents as they arrive in the S3 bucket. Store the results in an Amazon Aurora DB cluster.
- C. Place the JSON documents in an Amazon Elastic Block Store (Amazon EBS) volume. Use the EBS Multi-Attach feature to attach the volume to multiple Amazon EC2 instances. Run the Python code on the EC2 instances to process the documents. Store the results on an Amazon RDS DB instance.
- D. Place the JSON documents in an Amazon Simple Queue Service (Amazon SQS) queue as messages. Deploy the Python code as a container on an Amazon Elastic Container Service (Amazon ECS) cluster that is configured with the Amazon EC2 launch type. Use the container to process the SQS messages. Store the results on an Amazon RDS DB instance.
```

정답 : `B`

- AWS Lambda는 서버리스 컴퓨팅으로 높은 가용성과 자동 확장성을 제공, 운영 오버헤드가 거의 없음
- S3 이벤트를 트리거로 람다를 실행하면 문서가 도착할 때마다 자동 처리 가능, 수천 번의 호출도 람다가 자동으로 확장 처리
- 결과를 Aurora DB 클러스터에 저장하면 관리형 관계형 데이터베이스를 사용하여 고가용성과 확정성을 확보
- EC2나 ECS 기반 솔루션(A, C, D)은 관리해야 할 인스턴스가 많고, 오버헤드와 확장성 측면에서 람다 대비 불리

오답 이유

- **A. EC2 여러 대 사용 + S3 → Aurora**
    - 수천 번 실행 시 EC2 인스턴스 관리, 스케일링, 모니터링 부담 증가. Lambda 대비 운영 오버헤드 높음.
    
- **C. EBS Multi-Attach + EC2 → RDS**
    - EBS Multi-Attach는 일부 제한이 있고, EC2 관리 필요. 서버리스 요구사항 불충족.
    
- **D. SQS + ECS(EC2) → RDS**
    - ECS 클러스터 관리 필요, EC2 인스턴스 운영 오버헤드 존재. Lambda 대비 확장과 관리 효율성 낮음.


## #162
한 회사가 금융 리스크 모델링을 위해 AWS에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 합니다. 회사의 HPC 워크로드는 Linux에서 실행됩니다. 각 HPC 워크플로는 수백 개의 Amazon EC2 Spot 인스턴스에서 실행되며, 단기 실행되고 수천 개의 출력 파일을 생성하여 궁극적으로 분석 및 장기 저장을 위해 영구 스토리지에 저장됩니다.

회사는 온프레미스 데이터를 장기 영구 스토리지로 복사하여 모든 EC2 인스턴스가 데이터를 처리할 수 있도록 하기를 원합니다. 또한 데이터 세트와 출력 파일을 읽고 쓰기 위해 **영구 스토리지와 통합된 고성능 파일 시스템** 솔루션이 필요합니다.

이 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?

A. Amazon FSx for Lustre를 Amazon S3와 통합  
B. Amazon FSx for Windows File Server를 Amazon S3와 통합  
C. Amazon S3 Glacier를 Amazon Elastic Block Store(Amazon EBS)와 통합  
D. Amazon S3 버킷을 VPC 엔드포인트와 통합하고 Amazon EBS General Purpose SSD(gp2) 볼륨과 통합

```
A company wants to use high performance computing (HPC) infrastructure on AWS for financial risk modeling. The company’s HPC workloads run on Linux. Each HPC workflow runs on hundreds of Amazon EC2 Spot Instances, is short-lived, and generates thousands of output files that are ultimately stored in persistent storage for analytics and long-term future use.  
  
The company seeks a cloud storage solution that permits the copying of on-premises data to long-term persistent storage to make data available for processing by all EC2 instances. The solution should also be a high performance file system that is integrated with persistent storage to read and write datasets and output files.  
  
Which combination of AWS services meets these requirements?

- A. Amazon FSx for Lustre integrated with Amazon S3
- B. Amazon FSx for Windows File Server integrated with Amazon S3
- C. Amazon S3 Glacier integrated with Amazon Elastic Block Store (Amazon EBS)
- D. Amazon S3 bucket with a VPC endpoint integrated with an Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) volume
```

정답 : `A`

- Amazon FSx for Lustre는 HPC 워크로드에 적합한 고성능 POSIX 호환 파일 시스템 제공
- S3와 통합하면 온프레미스 데이터를 S3로 업로드하고, FSx for Lustre를 통해 EC2 인스턴스가 빠른 읽기/쓰기 성능으로 데이터 처리 가능
- Lustre 파일 시스템은 단기 HPC 작업에서 수천 개의 출력 파일 처리와 연계하여 데이터를 S3에 다시 저장하는 영구 스토리지 통합 기능 지원
- Spot 인스턴스를 사용하는 단기 워크로드에도 적합하며, EC2와 밀접하게 통합되어 HPC 요구사항 충족

오답 이유

- **B. FSx for Windows File Server + S3**
    - Windows 기반 전용 파일 시스템, HPC Linux 워크로드에는 적합하지 않음.
    
- **C. S3 Glacier + EBS**
    - Glacier는 **저비용 장기 아카이브용**, HPC 처리에 필요한 **실시간 고성능 읽기/쓰기** 불가.
    
- **D. S3 + EBS(gp2) 볼륨**
    - EBS는 단일 인스턴스에 연결된 블록 스토리지, 수백 EC2 인스턴스에서 공유 불가. HPC 워크로드에서 요구되는 **공유 고성능 파일 시스템** 조건 미충족.


## #163
한 회사가 온프레미스에서 컨테이너화된 애플리케이션을 구축하고 있으며, 애플리케이션을 AWS로 이전하려고 합니다. 애플리케이션은 배포 직후 수천 명의 사용자가 사용할 예정입니다. 회사는 컨테이너를 대규모로 배포하는 방법을 잘 모릅니다. 회사는 **운영 부담을 최소화하면서 고가용성 아키텍처**에서 컨테이너화된 애플리케이션을 배포할 필요가 있습니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

A. 컨테이너 이미지를 Amazon Elastic Container Registry(Amazon ECR) 리포지토리에 저장합니다. Amazon Elastic Container Service(Amazon ECS) 클러스터를 **AWS Fargate 런치 타입**으로 사용하여 컨테이너를 실행합니다. 수요에 따라 자동으로 스케일링하도록 **타겟 트래킹**을 사용합니다.  

B. 컨테이너 이미지를 Amazon ECR 리포지토리에 저장합니다. Amazon ECS 클러스터를 **Amazon EC2 런치 타입**으로 사용하여 컨테이너를 실행합니다. 수요에 따라 자동으로 스케일링하도록 타겟 트래킹을 사용합니다.  

C. EC2 인스턴스에서 실행되는 리포지토리에 컨테이너 이미지를 저장합니다. 컨테이너를 여러 가용 영역에 걸쳐 배포된 EC2 인스턴스에서 실행합니다. Amazon CloudWatch에서 평균 CPU 사용률을 모니터링하고 필요에 따라 새로운 EC2 인스턴스를 실행합니다.  

D. 컨테이너 이미지를 포함하는 Amazon EC2 AMI를 생성합니다. EC2 인스턴스를 여러 가용 영역에 걸친 Auto Scaling 그룹에서 시작합니다. 평균 CPU 사용률 임계값을 초과하면 CloudWatch 경보를 사용하여 EC2 인스턴스를 스케일 아웃합니다.

```
A company is building a containerized application on premises and decides to move the application to AWS. The application will have thousands of users soon after it is deployed. The company is unsure how to manage the deployment of containers at scale. The company needs to deploy the containerized application in a highly available architecture that minimizes operational overhead.  
  
Which solution will meet these requirements?

- A. Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service (Amazon ECS) cluster with the AWS Fargate launch type to run the containers. Use target tracking to scale automatically based on demand.
- B. Store container images in an Amazon Elastic Container Registry (Amazon ECR) repository. Use an Amazon Elastic Container Service (Amazon ECS) cluster with the Amazon EC2 launch type to run the containers. Use target tracking to scale automatically based on demand.
- C. Store container images in a repository that runs on an Amazon EC2 instance. Run the containers on EC2 instances that are spread across multiple Availability Zones. Monitor the average CPU utilization in Amazon CloudWatch. Launch new EC2 instances as needed.
- D. Create an Amazon EC2 Amazon Machine Image (AMI) that contains the container image. Launch EC2 instances in an Auto Scaling group across multiple Availability Zones. Use an Amazon CloudWatch alarm to scale out EC2 instances when the average CPU utilization threshold is breached.
```

정답 : `A`

- AWS Fargate 런치 타입은 컨테이너 실행을 위한 서버 관리 및 패치 작업을 필요로 하지 않으므로 운영 부담 최소화
- ECS 클러스터 + Fargate 조합은 컨테이너를 고가용성으로 여러 AZ에 배포 가능
- 타겟 트래킹을 통해 CPU나 메모리 관리 사용률에 따라 자동으로 스케일링 가능, 수천 명 사용자가 갑자기 증가해도 대응 가능
- 서버 프로비저닝, OS 관리, 패치 등 관리가 필요 없으므로 대규모 컨테이너 배포에 적합

오답 이유

- **B. ECS + EC2 런치 타입**
    - EC2 인스턴스를 직접 관리해야 하므로 운영 부담 증가.
    - 고가용성 확보와 스케일링 가능하지만, 서버 관리 필요성이 Fargate보다 높음.
    
- **C. EC2에서 리포지토리와 컨테이너 실행**
    - EC2 인스턴스와 리포지토리를 직접 관리해야 하므로 운영 부담이 매우 큼.
    - 스케일링 자동화 및 고가용성 구성도 복잡.
    
- **D. EC2 AMI + Auto Scaling**
    - 컨테이너를 AMI로 포함시켜 EC2에서 직접 실행하는 방식은 Fargate 대비 운영 부담이 큼.
    - 이미지 업데이트, 패치 관리, 인스턴스 관리 필요.


## #164
한 회사에는 두 개의 애플리케이션이 있습니다:  
- **송신자 애플리케이션**: 처리할 페이로드를 포함한 메시지를 전송  
- **처리 애플리케이션**: 페이로드 메시지를 수신하여 처리  

회사는 두 애플리케이션 간 메시지를 처리할 AWS 서비스를 구현하고자 합니다. 송신자 애플리케이션은 시간당 약 1,000개의 메시지를 보낼 수 있습니다. 메시지는 최대 2일 동안 처리될 수 있습니다. 메시지가 처리에 실패하면 나머지 메시지 처리에 영향을 주지 않도록 메시지를 유지해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족하면서 가장 운영 효율적인 방법입니까?

A. Redis 데이터베이스를 실행하는 Amazon EC2 인스턴스를 설정합니다. 두 애플리케이션을 인스턴스에 통합합니다. 메시지를 저장, 처리 및 삭제합니다.  

B. Amazon Kinesis 데이터 스트림을 생성하여 송신자 애플리케이션에서 메시지를 수신합니다. Kinesis Client Library(KCL)를 사용하여 처리 애플리케이션과 통합합니다.  

C. Amazon Simple Queue Service(Amazon SQS) 큐를 송신자 및 처리 애플리케이션과 통합합니다. 처리에 실패한 메시지를 수집하도록 데드 레터 큐(Dead-Letter Queue)를 구성합니다.  

D. 처리 애플리케이션이 메시지를 처리하도록 Amazon Simple Notification Service(Amazon SNS) 주제를 구독하도록 합니다. 송신자 애플리케이션을 SNS 주제에 연결합니다.

```
A company has two applications: a sender application that sends messages with payloads to be processed and a processing application intended to receive the messages with payloads. The company wants to implement an AWS service to handle messages between the two applications. The sender application can send about 1,000 messages each hour. The messages may take up to 2 days to be processed: If the messages fail to process, they must be retained so that they do not impact the processing of any remaining messages.  
  
Which solution meets these requirements and is the MOST operationally efficient?

- A. Set up an Amazon EC2 instance running a Redis database. Configure both applications to use the instance. Store, process, and delete the messages, respectively.
- B. Use an Amazon Kinesis data stream to receive the messages from the sender application. Integrate the processing application with the Kinesis Client Library (KCL).
- C. Integrate the sender and processor applications with an Amazon Simple Queue Service (Amazon SQS) queue. Configure a dead-letter queue to collect the messages that failed to process.
- D. Subscribe the processing application to an Amazon Simple Notification Service (Amazon SNS) topic to receive notifications to process. Integrate the sender application to write to the SNS topic.
```

정답 : `C`

- SQS 큐와 DLQ를 사용하면 세미지를 유지하고 재처리할 수 있어, 실패 메시지가 다른 메시지 처리에 영향을 주지 않음
- 메시지는 최대 14일간 보관 가능, 따라서 메시지가 최대 2일 동안 처리되어야 한다는 요구 사항 충족
- 서버 관리를 필요로 하지 않아 운영 효율성이 높음
- 시간당 약 1,000개의 메시지를 처리할 수 있으며, FIFO 큐를 사용하면 메시지 순서를 보장 가능

오답 이유

- **A. EC2 + Redis**
    - 서버 관리 필요, 운영 부담이 큼.
    - 메시지 유지, 실패 처리, 재처리 로직을 직접 구현해야 함.
    
- **B. Kinesis Data Streams**
    - 실시간 스트리밍 처리에 적합하지만, 최대 2일 지연 처리 요구에는 과도함.
    - 운영 오버헤드가 SQS보다 높음.
    
- **D. SNS**
    - SNS는 **푸시 기반**으로 메시지를 즉시 전달함.
    - 실패 시 메시지 유지 및 재처리 기능이 제한적임.

## #165
솔루션 아키텍트는 Amazon S3를 오리진으로 사용하여 정적 웹사이트를 호스팅하는 Amazon CloudFront 솔루션을 설계해야 합니다. 회사의 보안 정책에 따르면 모든 웹사이트 트래픽은 AWS WAF를 통해 검사되어야 합니다.

이 요구 사항을 준수하려면 솔루션 아키텍트는 어떻게 해야 합니까?

A. S3 버킷 정책을 구성하여 AWS WAF의 Amazon Resource Name(ARN)에서 오는 요청만 허용합니다.  

B. Amazon CloudFront를 구성하여 S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF로 전달합니다.  

C. Amazon CloudFront IP 주소만 Amazon S3에 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에 연결합니다.  

D. Amazon CloudFront와 Amazon S3를 구성하여 오리진 액세스 아이덴티티(OAI)를 사용하여 S3 버킷 접근을 제한합니다. 배포에서 AWS WAF를 활성화합니다.

```
A solutions architect must design a solution that uses Amazon CloudFront with an Amazon S3 origin to store a static website. The company’s security policy requires that all website traffic be inspected by AWS WAF.  
  
How should the solutions architect comply with these requirements?

- A. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only.
- B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin.
- C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only. Associate AWS WAF to CloudFront.
- D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution.
```

정답 : `D`

- OAI(Origin Access Identity)를 사용하면 CloudFront를 통해서만 S3 콘텐츠에 접근 가능하도록 제한할 수 있어 보안을 강화
- AWS WAF는 CloudFront 배포에 직접 연결하여 모든 웹 요청을 검사할 수 있음
- 이 방식은 트래픽이 WAF를 통과해야만 하는 회사의 보안 정책을 준수하면서 CloudFront + S3 정적 웹사이트를 안전하게 호스팅 가능

오답 이유

- **A. S3 버킷 정책에서 WAF ARN 허용**
    - WAF는 리소스에 접근하는 주체가 아니므로, ARN을 사용해 직접 허용하는 것은 불가능합니다.
    
- **B. CloudFront를 WAF로 요청 전달**
    - CloudFront는 이미 WAF와 통합 가능하며, 별도의 전달 단계는 필요하지 않습니다.
    
- **C. CloudFront IP를 허용하는 보안 그룹**
    - S3는 보안 그룹을 지원하지 않습니다. (EC2, RDS 등과 달리)
    - 따라서 이 방법은 불가능합니다.

## #166
글로벌 이벤트 주최측은 매일 보고서를 정적 HTML 페이지로 온라인에 게시하려고 합니다. 이 페이지는 전 세계 사용자로부터 수백만 건의 조회가 예상됩니다. 파일은 Amazon S3 버킷에 저장되어 있습니다. 솔루션 아키텍트는 효율적이고 효과적인 솔루션을 설계하도록 요청받았습니다.

이 요구 사항을 달성하기 위해 솔루션 아키텍트는 어떤 조치를 취해야 합니까?

A. 파일에 대해 사전 서명된 URL을 생성합니다.  
B. 모든 리전으로 교차 리전 복제를 사용합니다.  
C. Amazon Route 53의 지리 근접 기능을 사용합니다.  
D. Amazon CloudFront를 사용하고 S3 버킷을 오리진으로 설정합니다.

```
Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution.  
  
Which action should the solutions architect take to accomplish this?

- A. Generate presigned URLs for the files.
- B. Use cross-Region replication to all Regions.
- C. Use the geoproximity feature of Amazon Route 53.
- D. Use Amazon CloudFront with the S3 bucket as its origin.
```

정답 : `D`

- Amazon CloudFront는 전 세계에 분산된 엣지 로케이션을 사용하여 S3 콘텐츠를 캐싱하고 제공하므로, 수백만 건의 글로벌 조회에도 **낮은 지연 시간과 높은 처리량**을 제공합니다.
- S3를 오리진으로 사용하면 정적 HTML 페이지를 빠르게 배포하면서 운영 비용도 최소화할 수 있습니다.
- CloudFront는 자동으로 콘텐츠를 캐싱하고 전 세계 사용자에게 최적화된 경로로 제공하므로 가장 효율적입니다.

오답 이유

- **A. 사전 서명된 URL 생성**
    - 인증된 접근 제어용이며, 전 세계 수백만 사용자에게 빠른 전송을 보장하지 않습니다.
    
- **B. 교차 리전 복제**
    - 여러 리전에 복제하면 비용이 증가하고 관리 오버헤드가 커지며, 캐싱과 전송 최적화를 제공하지 않습니다.
    
- **C. Route 53 지리 근접 기능**
    - DNS 수준에서 사용자를 특정 리전으로 라우팅하지만, 콘텐츠 캐싱이나 전송 가속을 제공하지 않습니다.

## #167
한 회사는 Amazon EC2 인스턴스 그룹에서 프로덕션 애플리케이션을 실행합니다. 이 애플리케이션은 Amazon SQS 큐에서 데이터를 읽고 메시지를 병렬로 처리합니다. 메시지 볼륨은 예측할 수 없으며 간헐적으로 트래픽이 발생합니다. 이 애플리케이션은 다운타임 없이 지속적으로 메시지를 처리해야 합니다.

이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. Spot 인스턴스만 사용하여 최대 용량을 처리합니다.  
B. Reserved 인스턴스만 사용하여 최대 용량을 처리합니다.  
C. 기본 용량은 Reserved 인스턴스를 사용하고, 추가 용량은 Spot 인스턴스를 사용합니다.  
D. 기본 용량은 Reserved 인스턴스를 사용하고, 추가 용량은 On-Demand 인스턴스를 사용합니다.

```
A company runs a production application on a fleet of Amazon EC2 instances. The application reads the data from an Amazon SQS queue and processes the messages in parallel. The message volume is unpredictable and often has intermittent traffic. This application should continually process messages without any downtime.  
  
Which solution meets these requirements MOST cost-effectively?

- A. Use Spot Instances exclusively to handle the maximum capacity required.
- B. Use Reserved Instances exclusively to handle the maximum capacity required.
- C. Use Reserved Instances for the baseline capacity and use Spot Instances to handle additional capacity.
- D. Use Reserved Instances for the baseline capacity and use On-Demand Instances to handle additional capacity.
```

정답 : `C`

- SQS 메시지 처리량이 불규칙하고 간헐적이므로 최대 용량을 항상 온전히 Reserved Instances로 준비하면 비용 낭비가 발생
- Reserved Instances를 사용하여 안정적인 기본 용량을 확보하고, Spot Instances를 사용해 추가 트래픽이 발생할 때 유연하게 확장하면 비용을 최소화
- Spot Instances는 최대 용량을 처리할 수 있지만, 중단될 수 있으므로 기본 용량을 Reserved Instances로 유지함으로써 다운타임 없이 메시지 처리

오답 이유

- **A. Spot 인스턴스만 사용**
    - 중단 가능성이 있으므로 다운타임이 발생할 수 있습니다.
    
- **B. Reserved 인스턴스만 사용**
    - 간헐적 트래픽을 위해 최대 용량을 항상 유지해야 하므로 비용이 비효율적입니다.
    
- **D. Reserved + On-Demand**
    - On-Demand는 Spot보다 비싸므로, 비용 효율성이 떨어집니다.


## #168
보안 팀은 팀의 모든 AWS 계정에서 특정 서비스 또는 작업에 대한 액세스를 제한하려고 합니다. 모든 계정은 AWS Organizations의 대규모 조직에 속해 있습니다. 솔루션은 확장 가능해야 하며, 권한을 관리할 수 있는 단일 지점이 필요합니다.

이 요구 사항을 달성하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

A. 서비스 또는 작업에 대한 액세스를 제공하도록 ACL을 생성합니다.  
B. 계정을 허용하도록 보안 그룹을 생성하고 이를 사용자 그룹에 연결합니다.  
C. 각 계정에 교차 계정 역할(cross-account role)을 생성하여 서비스 또는 작업에 대한 액세스를 거부합니다.  
D. 루트 조직 단위(OU)에서 서비스 제어 정책(SCP)을 생성하여 서비스 또는 작업에 대한 액세스를 거부합니다.

```
A security team wants to limit access to specific services or actions in all of the team’s AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained.  
  
What should a solutions architect do to accomplish this?

- A. Create an ACL to provide access to the services or actions.
- B. Create a security group to allow accounts and attach it to user groups.
- C. Create cross-account roles in each account to deny access to the services or actions.
- D. Create a service control policy in the root organizational unit to deny access to the services or actions.
```

정답 : `D`

- AWS Organizations의 서비스 제어 정책(SCP)은 조직 내 모든 계정에 적용되며, 중앙에서 관리할 수 있음
- SCP를 사용하면 계정 단위로 특정 서비스나 작업에 대한 허용/거부를 일괄 관리할 수 있음
- 루트 조직 단위에 적용하면 모든 계정에 자동으로 적용되어 확장성과 단일 관리 지점 요구사항 충족

오답 이유

- **A. ACL 생성**
    - ACL은 주로 S3 같은 리소스 수준 접근 제어에 사용되며, 계정 전체 권한 관리에는 적합하지 않습니다.
    
- **B. 보안 그룹 생성**
    - 보안 그룹은 네트워크 트래픽 제어용이며, 서비스/작업 권한을 제어하지 못합니다.
    
- **C. 각 계정에 교차 계정 역할 생성**
    - 계정마다 별도로 설정해야 하므로 중앙 관리가 어렵고 확장성이 떨어집니다.

## #169
회사는 최근 웹 공격으로 인해 공용 웹 애플리케이션의 보안에 대해 우려하고 있습니다. 해당 애플리케이션은 애플리케이션 로드 밸런서(ALB)를 사용합니다. 솔루션 아키텍트는 애플리케이션에 대한 DDoS 공격 위험을 줄여야 합니다.

이 요구 사항을 충족하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

A. ALB에 Amazon Inspector 에이전트를 추가합니다.  
B. 공격을 방지하도록 Amazon Macie를 구성합니다.  
C. AWS Shield Advanced를 활성화하여 공격을 방지합니다.  
D. ALB를 모니터링하도록 Amazon GuardDuty를 구성합니다.

```
A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load Balancer (ALB). A solutions architect must reduce the risk of DDoS attacks against the application.  
  
What should the solutions architect do to meet this requirement?

- A. Add an Amazon Inspector agent to the ALB.
- B. Configure Amazon Macie to prevent attacks.
- C. Enable AWS Shield Advanced to prevent attacks.
- D. Configure Amazon GuardDuty to monitor the ALB.
```

정답 : `C`

- AWS Shield Advanced는 DDoS 공격으로부터 애플리케이션을 보호하도록 설계된 서비스
- ALB를 포함한 AWS 리소스를 자동으로 보호하며, 웹 애플리케이션을 대상으로 한 공격을 환화
- 표준 Shield(Standard)는 모든 AWS 고객에게 기본 제공되지만, 고급 기능과 알림/대응을 위해 Shield Advanced를 사용해야함

오답 이유

- **A. Amazon Inspector**
    - Inspector는 EC2와 컨테이너 이미지의 취약점 평가 도구이며, DDoS 방어 기능이 없습니다.
    
- **B. Amazon Macie**
    - Macie는 S3 데이터의 민감정보 탐지와 보호를 위한 서비스이며, 웹 공격 방어와는 관련이 없습니다.
    
- **D. Amazon GuardDuty**
    - GuardDuty는 위협 탐지 서비스로 로그 기반 이상 활동을 감지하지만, **DDoS 공격을 방지하지는 않습니다**.


## #170
회사의 웹 애플리케이션은 애플리케이션 로드 밸런서(ALB) 뒤에서 Amazon EC2 인스턴스에서 실행되고 있습니다. 회사는 최근 정책을 변경하여 애플리케이션에 접근할 수 있는 국가를 하나로 제한해야 합니다.

이 요구 사항을 충족하는 구성은 무엇입니까?

A. EC2 인스턴스의 보안 그룹을 구성합니다.  
B. 애플리케이션 로드 밸런서의 보안 그룹을 구성합니다.  
C. VPC 내 애플리케이션 로드 밸런서에 AWS WAF를 구성합니다.  
D. EC2 인스턴스가 있는 서브넷의 네트워크 ACL을 구성합니다.

```
A company’s web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only.  
  
Which configuration will meet this requirement?

- A. Configure the security group for the EC2 instances.
- B. Configure the security group on the Application Load Balancer.
- C. Configure AWS WAF on the Application Load Balancer in a VPC.
- D. Configure the network ACL for the subnet that contains the EC2 instances.
```

정답 : `C`

- AWS WAF는 웹 애플리케이션 방화벽으로, 요청을 국가 단위로 필터링 가능
- ALB에 WAF를 적용하면 특정 국가에서 들어오는 요청만 허용하거나 차단할 수 있어, 정책 요구사항 충족
- 보안 그릅이나 네트워크 ACL은 IP 주소 범위를 기준으로만 트래픽을 제어하며, 국가 기반 필터링은 지원 X

오답 이유

- **A. EC2 인스턴스 보안 그룹**
    - 보안 그룹은 포트와 IP 주소 단위 트래픽 제어 가능, 국가 기반 필터링은 불가
    
- **B. ALB 보안 그룹**
    - 보안 그룹도 IP 주소 기반 제어만 가능, GeoIP 기반 차단 불가
    
- **D. 네트워크 ACL**
    - 서브넷 레벨에서 IP 주소 기반 트래픽 제어 가능, 국가 단위 필터링은 불가


## #171
회사는 항목 가격을 기반으로 세금 계산을 자동화하는 API를 사용자에게 제공합니다. 회사는 연휴 시즌에만 조회 수가 많아져 응답 시간이 느려지는 문제가 발생합니다. 솔루션 아키텍트는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다.

솔루션 아키텍트가 이를 달성하기 위해 수행해야 하는 작업은 무엇입니까?

A. Amazon EC2 인스턴스에서 호스팅되는 API를 제공합니다. EC2 인스턴스가 API 요청이 들어올 때 필요한 계산을 수행합니다.  

B. 항목 이름을 수락하는 Amazon API Gateway를 사용하여 REST API를 설계합니다. API Gateway가 항목 이름을 AWS Lambda로 전달하여 세금을 계산합니다.  

C. 두 개의 Amazon EC2 인스턴스 뒤에 Application Load Balancer를 생성합니다. EC2 인스턴스가 받은 항목 이름에 대해 세금을 계산합니다.  

D. Amazon EC2 인스턴스에서 호스팅되는 API와 연결되는 Amazon API Gateway를 사용하여 REST API를 설계합니다. API Gateway가 항목 이름을 수락하고 EC2 인스턴스로 전달하여 세금을 계산합니다.

```
A company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a larger number of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is scalable and elastic.  
  
What should the solutions architect do to accomplish this?

- A. Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made.
- B. Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations.
- C. Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names.
- D. Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and passes the item names to the EC2 instance for tax computations.
```

정답 : `B`

- API Gateway + Lambda 조합은 서버리스 아키텍처로, 트래픽이 많아지는 시점에도 자동으로 확장
- 람다는 이벤트 기반으로 실행되며, 필요할 때만 컴퓨팅 리소스를 사용하므로 비용 효율적
- 연휴 시즌과 같은 트래픽 급증에도 탄력적으로 처리할 수 있어 요청 지연을 최소화

오답 이유

- **A. EC2에서 API 호스팅**
    - 단일 인스턴스이므로 트래픽 급증 시 확장이 어렵고, 탄력성이 부족합니다.
    
- **C. ALB + EC2 인스턴스 2개**
    - 두 인스턴스로만 처리 가능하며, 트래픽 급증 시 확장이 제한적이고 운영 오버헤드가 발생합니다.
    
- **D. API Gateway + EC2**
    - EC2를 사용하므로 트래픽 급증 시 확장 관리가 필요하며, 서버리스의 탄력성을 활용하지 못합니다.


## #172
솔루션 아키텍트는 애플리케이션용 새로운 Amazon CloudFront 배포를 생성하고 있습니다. 사용자가 제출하는 일부 정보는 민감합니다. 애플리케이션은 HTTPS를 사용하지만, 추가적인 보안 계층이 필요합니다. 민감한 정보는 애플리케이션 스택 전체에서 보호되어야 하며, 정보에 대한 접근은 특정 애플리케이션으로 제한되어야 합니다.

솔루션 아키텍트가 수행해야 하는 작업은 무엇입니까?

A. CloudFront 서명된 URL을 구성합니다.  
B. CloudFront 서명된 쿠키를 구성합니다.  
C. CloudFront 필드 수준 암호화(profile-level encryption) 구성을 설정합니다.  
D. CloudFront를 구성하고 Viewer Protocol Policy에 대해 Origin Protocol Policy를 HTTPS 전용으로 설정합니다.

```
A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should.be protected throughout the entire application stack, and access to the information should be restricted to certain applications.  
  
Which action should the solutions architect take?

- A. Configure a CloudFront signed URL.
- B. Configure a CloudFront signed cookie.
- C. Configure a CloudFront field-level encryption profile.
- D. Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy.
```


정답 : `C`

- CloudFront 필드 수준 암호화는 사용자가 제출한 민감 정보를 CloudFront를 통해 전송할 때, 지정된 필드만 선택적으로 암호화할 수 있음
- 데이터가 애플리케이션 스택 전체를 통과하는 동안 암호화되어 보호
- 접근 권한을 특정 애플리케이션(즉, 해당 필드의 암호화 키를 가진 애플리케이션)으로 제한할 수 있음

오답 이유

- **A. 서명된 URL**
    - 콘텐츠 접근 제어는 가능하지만, 필드 수준의 민감 정보 보호에는 적합하지 않습니다.
    
- **B. 서명된 쿠키**
    - 특정 사용자 또는 그룹에 대한 접근 제한에는 유용하지만, 개별 데이터 필드 암호화는 제공하지 않습니다.
    
- **D. HTTPS 전용 설정**
    - HTTPS만 사용하면 전송 중 데이터는 암호화되지만, 애플리케이션 스택 전체에서의 민감 정보 보호는 보장되지 않습니다.


## #173
게임 회사는 브라우저 기반 애플리케이션을 AWS에서 호스팅합니다. 애플리케이션 사용자는 Amazon S3에 저장된 많은 비디오와 이미지를 소비합니다. 이 콘텐츠는 모든 사용자에게 동일합니다.

애플리케이션의 인기가 증가하면서 전 세계 수백만 명의 사용자가 이러한 미디어 파일에 접근하고 있습니다. 회사는 오리진에 대한 부하를 줄이면서 사용자에게 파일을 제공하고자 합니다.

요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

A. 웹 서버 앞에 AWS Global Accelerator를 배포합니다.  
B. S3 버킷 앞에 Amazon CloudFront 웹 배포를 배포합니다.  
C. 웹 서버 앞에 Amazon ElastiCache for Redis 인스턴스를 배포합니다.  
D. 웹 서버 앞에 Amazon ElastiCache for Memcached 인스턴스를 배포합니다.

```
A gaming company hosts a browser-based application on AWS. The users of the application consume a large number of videos and images that are stored in Amazon S3. This content is the same for all users.  
  
The application has increased in popularity, and millions of users worldwide accessing these media files. The company wants to provide the files to the users while reducing the load on the origin.  
  
Which solution meets these requirements MOST cost-effectively?

- A. Deploy an AWS Global Accelerator accelerator in front of the web servers.
- B. Deploy an Amazon CloudFront web distribution in front of the S3 bucket.
- C. Deploy an Amazon ElastiCache for Redis instance in front of the web servers.
- D. Deploy an Amazon ElastiCache for Memcached instance in front of the web servers.
```

정답 : `B`

- **Amazon CloudFront**는 전 세계에 분산된 엣지 로케이션을 통해 정적 콘텐츠(S3에 저장된 이미지, 비디오)를 캐싱하고 제공할 수 있습니다.
- 모든 사용자가 동일한 콘텐츠를 소비하므로 캐싱 효율이 높으며, 오리진 S3에 대한 부하를 크게 줄입니다.
- 비용 효율적이며, 글로벌 사용자에게 낮은 지연 시간으로 콘텐츠를 제공할 수 있습니다.


오답 이유

- **A. AWS Global Accelerator**
    - 글로벌 사용자에 대한 네트워크 레이어 지연 시간을 줄여주지만, S3 콘텐츠 캐싱 기능은 제공하지 않습니다.
- **C. ElastiCache for Redis**
    - 웹 서버 기반 데이터 캐싱에는 유용하지만, 전 세계 수백만 사용자에게 S3 정적 콘텐츠를 제공하는 데에는 효율적이지 않습니다.
- **D. ElastiCache for Memcached**
    - Redis와 동일하게 동작하며, 웹 서버 캐싱에는 적합하지만 S3 정적 파일 글로벌 배포에는 적합하지 않습니다.


## #174
한 회사는 단일 가용 영역(AZ)에서 실행되는 6개의 프런트엔드 웹 서버를 가진 다중 계층 애플리케이션을 운영하고 있으며, 이들은 Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 솔루션스 아키텍트는 애플리케이션을 수정하지 않고도 인프라를 고가용성으로 변경해야 합니다.

애플리케이션을 수정하지 않고 고가용성을 제공하는 아키텍처는 무엇입니까?

A. 두 개의 리전에서 각각 세 개의 인스턴스를 사용하는 Auto Scaling 그룹을 생성합니다.  
B. 두 개의 가용 영역에서 각각 세 개의 인스턴스를 사용하는 Auto Scaling 그룹으로 수정합니다.  
C. 다른 리전에서 인스턴스를 신속하게 생성할 수 있는 Auto Scaling 템플릿을 생성합니다.  
D. Amazon EC2 인스턴스 앞의 ALB를 라운드 로빈 구성으로 변경하여 웹 계층으로 트래픽을 분산합니다.

```
A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application.  
  
Which architecture should the solutions architect choose that provides high availability?

- A. Create an Auto Scaling group that uses three instances across each of two Regions.
- B. Modify the Auto Scaling group to use three instances across each of two Availability Zones.
- C. Create an Auto Scaling template that can be used to quickly create more instances in another Region.
- D. Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier.
```

정답 : `B`

- 현재 환경은 단일 AZ에서 실행되므로 AZ 장애 시 전체 웹 계층이 다운될 수 있음
- 두 개 이상의 AZ에 오토 스케일링 그룹을 배포하면 AZ 중 하나가 실패해도 다른 AZ에서 인스턴스가 트래픽을 처리
- ALB는 이미 트래픽을 오토 스케일립 그룹의 인스턴스로 분산할 수 있으므로 애플리케이션 수정 없이 고가용성 달성 가능

오답 이유

- **A. 두 개 리전에서 인스턴스를 배포**
    - 리전 간 배포는 고가용성을 제공할 수 있으나, 다중 리전 환경에서 ALB는 기본적으로 리전 내에서만 작동합니다. 애플리케이션을 수정하지 않고 두 리전에서 동작하게 하려면 Route 53 기반 글로벌 로드 밸런싱이 필요합니다.
- **C. Auto Scaling 템플릿 생성**
    - 템플릿은 인스턴스 생성을 단순화하지만, 고가용성을 자동으로 제공하지 않습니다.
- **D. ALB를 라운드 로빈으로 변경**
    - ALB는 기본적으로 라운드 로빈 또는 최적화된 분산을 사용하며, 단일 AZ 환경에서는 AZ 장애 시 고가용성을 제공하지 못합니다.


## #175
한 전자상거래 회사는 Amazon API Gateway와 AWS Lambda 함수를 사용하는 주문 처리 애플리케이션을 운영하고 있습니다. 애플리케이션은 Amazon Aurora PostgreSQL 데이터베이스에 데이터를 저장합니다. 최근 판매 이벤트 동안 고객 주문이 갑자기 급증했습니다. 일부 고객은 시간 초과(timeout)를 경험했고, 애플리케이션은 해당 고객들의 주문을 처리하지 못했습니다.

솔루션스 아키텍트는 데이터베이스의 CPU 사용률과 메모리 사용률이 높은 이유가 많은 수의 열린 연결 때문임을 확인했습니다. 솔루션스 아키텍트는 애플리케이션에 대한 변경을 최소화하면서 시간 초과 오류를 방지해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. Lambda 함수에 프로비저닝된 동시성을 구성합니다. 데이터베이스를 다중 AWS 리전에서 글로벌 데이터베이스로 수정합니다.  

B. Amazon RDS Proxy를 사용하여 데이터베이스에 대한 프록시를 생성합니다. Lambda 함수가 데이터베이스 엔드포인트 대신 RDS Proxy 엔드포인트를 사용하도록 수정합니다.  

C. 데이터베이스의 리드 리플리카를 다른 AWS 리전에 생성합니다. API Gateway에서 쿼리 문자열 매개변수를 사용하여 리드 리플리카로 트래픽을 라우팅합니다.  

D. AWS Database Migration Service(AWS DMS)를 사용하여 Aurora PostgreSQL의 데이터를 Amazon DynamoDB로 마이그레이션합니다. Lambda 함수가 DynamoDB 테이블을 사용하도록 수정합니다.

```
An ecommerce company has an order-processing application that uses Amazon API Gateway and an AWS Lambda function. The application stores data in an Amazon Aurora PostgreSQL database. During a recent sales event, a sudden surge in customer orders occurred. Some customers experienced timeouts, and the application did not process the orders of those customers.  
  
A solutions architect determined that the CPU utilization and memory utilization were high on the database because of a large number of open connections. The solutions architect needs to prevent the timeout errors while making the least possible changes to the application.  
  
Which solution will meet these requirements?

- A. Configure provisioned concurrency for the Lambda function. Modify the database to be a global database in multiple AWS Regions.
- B. Use Amazon RDS Proxy to create a proxy for the database. Modify the Lambda function to use the RDS Proxy endpoint instead of the database endpoint.
- C. Create a read replica for the database in a different AWS Region. Use query string parameters in API Gateway to route traffic to the read replica.
- D. Migrate the data from Aurora PostgreSQL to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS). Modify the Lambda function to use the DynamoDB table.
```

정답 : `B`

- 문제의 핵심 원인 = 람다 함수의 병렬 호출로 인해 Aurora PostreSQL 데이터베이스에 열리는 연결 수가 급증
- RDS Proxy를 사용하면 데이터베이스 연결 풀링(Connection Pooling)과 재사용을 통해 데이터베이스에 대한 연결 수를 제한할 수 있음
- 람다 함수 코드는 최소한만 수정하여 RDS Proxy 엔드포인트를 사용하도록 변경하면 되므로 운영 변경이 적음
- 이는 갑작스러운 트래픽 급증에도 데이터베이스 연결 문제를 완화하고, 시간 초과를 방지하는 가장 비용 효율적이고 최소 변경 솔루션

오답 이유

- **A. 프로비저닝된 동시성 + 글로벌 데이터베이스**
    - 글로벌 데이터베이스는 다중 리전에서 읽기 성능 향상에 적합하지만, **연결 수 폭증 문제를 직접 해결하지 않음**.
    - Lambda 프로비저닝 동시성은 Lambda 실행 지연을 줄이지만, 데이터베이스 연결 수 문제를 해결하지 못함.
- **C. 리드 리플리카 + 쿼리 매개변수 라우팅**
    - 읽기 요청 분산에는 도움이 되지만, Aurora PostgreSQL은 **쓰기 작업은 기본 인스턴스에서만 처리**되므로 주문 처리(write-heavy)에 대한 연결 폭증 문제를 해결하지 못함.
- **D. Aurora → DynamoDB 마이그레이션**
    - 애플리케이션 변경이 크고, 문제 해결에 과도하며 **즉각적 해결책이 아님**.


## #176
애플리케이션이 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon DynamoDB 테이블에 접근해야 합니다.

트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 테이블에 접근하는 가장 안전한 방법은 무엇입니까?

A. DynamoDB에 대한 VPC 엔드포인트를 사용합니다.  
B. 퍼블릭 서브넷에 NAT 게이트웨이를 사용합니다.  
C. 프라이빗 서브넷에 NAT 인스턴스를 사용합니다.  
D. VPC에 연결된 인터넷 게이트웨이를 사용합니다.

```
An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table.  
  
What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?

- A. Use a VPC endpoint for DynamoDB.
- B. Use a NAT gateway in a public subnet.
- C. Use a NAT instance in a private subnet.
- D. Use the internet gateway attached to the VPC.
```

정답 : `A`

- VPC 엔드포인트는 AWS PrivateLink를 사용하여 프라이빗 서브넷에서 인터넷을 거치지 않고 DynamoDB에 직접 연결할 수 있는 방법
- 이를 사용하면 트래픽이 AWS 네트워크 내부에서만 흐르므로, 보안성이 가장 높음
- NAT 게이트웨이/인스턴스 또는 인터넷 게이트웨이를 사용하는 경우 트래픽이 퍼블릭 인터넷을 통해 나가게 되므로 보안상 취약

오답 이유

- **B. NAT 게이트웨이**
    - 트래픽이 퍼블릭 서브넷을 통해 인터넷으로 나가므로 AWS 네트워크 내부에만 머무르는 것이 아님.
- **C. NAT 인스턴스**
    - NAT 게이트웨이와 동일하게 인터넷을 통해 트래픽이 나가므로 보안 요구사항 불충족.
- **D. 인터넷 게이트웨이**
    - 직접 인터넷으로 나가야 하므로 가장 보안에 취약하고 요구사항에 부합하지 않음.


## #177
엔터테인먼트 회사가 Amazon DynamoDB를 사용하여 미디어 메타데이터를 저장하고 있습니다. 애플리케이션은 읽기 중심이며 지연이 발생하고 있습니다. 회사에는 추가적인 운영 부담을 처리할 인력이 없으며, 애플리케이션을 재구성하지 않고 DynamoDB의 성능 효율성을 개선해야 합니다.

이 요구사항을 충족하기 위해 솔루션 아키텍트가 권장해야 하는 방법은 무엇입니까?

A. Amazon ElastiCache for Redis를 사용합니다.  

B. Amazon DynamoDB Accelerator(DAX)를 사용합니다.  

C. DynamoDB 글로벌 테이블을 사용하여 데이터를 복제합니다.  

D. 자동 검색(Auto Discovery) 기능이 활성화된 Amazon ElastiCache for Memcached를 사용합니다.

```
An entertainment company is using Amazon DynamoDB to store media metadata. The application is read intensive and experiencing delays. The company does not have staff to handle additional operational overhead and needs to improve the performance efficiency of DynamoDB without reconfiguring the application.  
  
What should a solutions architect recommend to meet this requirement?

- A. Use Amazon ElastiCache for Redis.
- B. Use Amazon DynamoDB Accelerator (DAX).
- C. Replicate data by using DynamoDB global tables.
- D. Use Amazon ElastiCache for Memcached with Auto Discovery enabled.
```


정답 : `B`

- DynamoDB Accelerator(DAX)는 DynamoDB에 대한 완전 관리형 인-메모리 캐시
- 애플리케이션 코드를 거의 변경하지 않고, 읽기 중심 워크로드의 성능을 수 밀리초에서 수 마이크로초 수준으로 개선 가능
- 추가적인 운영 부담이 없으며 애플리케이션 재구성이 최소화

오답 이유

- **A. ElastiCache for Redis**
    - 별도의 캐시 계층을 도입해야 하며, 애플리케이션 코드 수정이 필요합니다.
    - 운영 부담이 증가합니다.
- **C. DynamoDB 글로벌 테이블**
    - 다중 리전 데이터 복제용이며 성능 최적화보다는 **글로벌 가용성 및 읽기 분산** 목적.
    - 단순 읽기 성능 향상에는 적합하지 않습니다.
- **D. ElastiCache for Memcached**
    - Redis와 동일하게 별도의 캐시 계층 도입 및 애플리케이션 코드 수정 필요.
    - Auto Discovery가 있어도 운영 부담은 존재합니다.


## #178
회사의 인프라는 단일 AWS 리전에서 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성되어 있습니다. 회사는 데이터를 별도의 리전에서 백업하고자 합니다.

운영 오버헤드가 가장 적은 방식으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?

A. AWS Backup을 사용하여 EC2 백업과 RDS 백업을 별도의 리전으로 복사합니다.  

B. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EC2 백업과 RDS 백업을 별도의 리전으로 복사합니다.  

C. EC2 인스턴스의 Amazon Machine Image(AMI)를 생성합니다. AMI를 별도의 리전으로 복사합니다. RDS DB 인스턴스에 대한 읽기 전용 리플리카를 별도의 리전에 생성합니다.  

D. Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성합니다. EBS 스냅샷을 별도의 리전으로 복사합니다. RDS 스냅샷을 생성하고, RDS 스냅샷을 Amazon S3로 내보냅니다. S3 교차 리전 복제(CRR)를 별도의 리전으로 구성합니다.

```
A company’s infrastructure consists of Amazon EC2 instances and an Amazon RDS DB instance in a single AWS Region. The company wants to back up its data in a separate Region.  
  
Which solution will meet these requirements with the LEAST operational overhead?

- A. Use AWS Backup to copy EC2 backups and RDS backups to the separate Region.
- B. Use Amazon Data Lifecycle Manager (Amazon DLM) to copy EC2 backups and RDS backups to the separate Region.
- C. Create Amazon Machine Images (AMIs) of the EC2 instances. Copy the AMIs to the separate Region. Create a read replica for the RDS DB instance in the separate Region.
- D. Create Amazon Elastic Block Store (Amazon EBS) snapshots. Copy the EBS snapshots to the separate Region. Create RDS snapshots. Export the RDS snapshots to Amazon S3. Configure S3 Cross-Region Replication (CRR) to the separate Region.
```

정답 : `A`

- AWS Backup은 EC2, RDS, EBS, EFS 등 다양한 AWS 리소스의 백업과 복원을 중앙에서 관리할 수 있는 서비스
- 별도의 리전으로 자동 복사(Cross-Region Backup)를 구성할 수 있어 운영 부담이 최소화
- 별도 스크립트나 수동 복사 없이도, EC2와 RDS 모두 통합 관리 가능

오답 이유

- **B. Amazon Data Lifecycle Manager (DLM)**
    - DLM은 **EBS 볼륨과 AMI의 라이프사이클 관리**에만 사용 가능.
    - RDS 백업은 지원하지 않으므로 요구사항에 부합하지 않습니다.
- **C. AMI 복사 + RDS 읽기 리플리카**
    - 작동은 가능하지만, 수동 관리가 필요하고 운영 오버헤드가 높습니다.
    - AWS Backup 대비 자동화 및 통합 관리가 어렵습니다.
- **D. EBS 스냅샷 + RDS 스냅샷 + S3 CRR**
    - 지나치게 복잡하며 불필요한 단계가 많아 운영 오버헤드가 증가합니다.


## #179
1. 문제 전체 한글 번역:

솔루션 아키텍트는 애플리케이션이 Amazon RDS DB 인스턴스에 액세스할 때 사용하는 데이터베이스 사용자 이름과 암호를 안전하게 저장해야 합니다. 데이터베이스에 접근하는 애플리케이션은 Amazon EC2 인스턴스에서 실행됩니다. 솔루션 아키텍트는 AWS Systems Manager Parameter Store에 안전한 파라미터를 생성하려고 합니다.

이 요구사항을 충족하려면 솔루션 아키텍트는 무엇을 해야 합니까?

A. Parameter Store 파라미터에 대한 읽기 권한이 있는 IAM 역할을 생성합니다. 파라미터를 암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대해 Decrypt 권한을 허용합니다. 이 IAM 역할을 EC2 인스턴스에 할당합니다.  

B. Parameter Store 파라미터에 대한 읽기 권한이 있는 IAM 정책을 생성합니다. 파라미터를 암호화하는 데 사용되는 AWS Key Management Service(AWS KMS) 키에 대해 Decrypt 권한을 허용합니다. 이 IAM 정책을 EC2 인스턴스에 할당합니다.  

C. Parameter Store 파라미터와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 정책에서 Amazon RDS를 주체(principal)로 지정합니다.  

D. DB 인스턴스와 EC2 인스턴스 간에 IAM 신뢰 관계를 생성합니다. 신뢰 정책에서 Systems Manager를 주체(principal)로 지정합니다.

```
A solutions architect needs to securely store a database user name and password that an application uses to access an Amazon RDS DB instance. The application that accesses the database runs on an Amazon EC2 instance. The solutions architect wants to create a secure parameter in AWS Systems Manager Parameter Store.  
  
What should the solutions architect do to meet this requirement?

- A. Create an IAM role that has read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM role to the EC2 instance.
- B. Create an IAM policy that allows read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM policy to the EC2 instance.
- C. Create an IAM trust relationship between the Parameter Store parameter and the EC2 instance. Specify Amazon RDS as a principal in the trust policy.
- D. Create an IAM trust relationship between the DB instance and the EC2 instance. Specify Systems Manager as a principal in the trust policy.
```

정답 : `A`

- AWS Systems Manager Parameter Store에서 SecureString 타입을 사용하면 KMS 키로 암호화된 파라미터를 안전하게 저장 가능
- EC2 인스턴스가 해당 파라미터를 읽을 수 있도록 IAM 역할을 생성하고, Parameter Store 읽기 권한과 KMS Decrypt 권한을 역할에 부여해야 함
- EC2에 IAM 역할을 연결하면, 애플리케이션이 안전하게 파라미터 조회 가능
- 정책을 직접 EC2 인스턴스에 붙이는 것보다 역할을 사용하는 방식이 AWS 모범 사례이며, 보안과 운영 효율성을 모두 제공

오답 이유

- **B. IAM 정책을 EC2 인스턴스에 직접 할당**
    - EC2 인스턴스에는 정책을 직접 붙일 수 없습니다. 대신 **IAM 역할**을 사용해야 합니다.
- **C. Parameter Store와 EC2 간 IAM 신뢰 관계**
    - Parameter Store는 IAM 역할 기반 접근을 사용하며, 신뢰 관계를 설정하지 않습니다.
- **D. DB 인스턴스와 EC2 간 IAM 신뢰 관계**
    - DB 인스턴스는 IAM 리소스가 아니므로 신뢰 관계를 생성할 수 없고, Systems Manager 접근과도 관련이 없습니다.


## #180
한 회사가 API 기반으로 동작하는 클라우드 커뮤니케이션 플랫폼을 설계하고 있습니다. 
애플리케이션은 Network Load Balancer(NLB) 뒤에 있는 Amazon EC2 인스턴스에서 호스팅됩니다. 
회사는 Amazon API Gateway를 사용하여 외부 사용자가 API를 통해 애플리케이션에 액세스하도록 제공합니다. 
회사는 SQL 인젝션 같은 웹 공격으로부터 플랫폼을 보호하고, 
대규모 정교한 DDoS 공격을 감지하고 완화하기를 원합니다.

가장 강력한 보호를 제공하는 솔루션 조합은 무엇입니까? (두 가지 선택)

A. AWS WAF를 사용하여 NLB 보호
B. AWS Shield Advanced를 NLB와 함께 사용
C. AWS WAF를 사용하여 Amazon API Gateway 보호
D. Amazon GuardDuty를 AWS Shield Standard와 함께 사용
E. AWS Shield Standard를 Amazon API Gateway와 함께 사용

```
A company is designing a cloud communications platform that is driven by APIs. The application is hosted on Amazon EC2 instances behind a Network Load Balancer (NLB). The company uses Amazon API Gateway to provide external users with access to the application through APIs. The company wants to protect the platform against web exploits like SQL injection and also wants to detect and mitigate large, sophisticated DDoS attacks.  
  
Which combination of solutions provides the MOST protection? (Choose two.)

- A. Use AWS WAF to protect the NLB.
- B. Use AWS Shield Advanced with the NLB.
- C. Use AWS WAF to protect Amazon API Gateway.
- D. Use Amazon GuardDuty with AWS Shield Standard
- E. Use AWS Shield Standard with Amazon API Gateway.
```

정답 : `B, C`

- AWS WAF(Web Application Firewall)
	- 웹 애플리케이션 공격(SQL 인젝션, XSS 등) 차단
	- API Gateway에 적용 가능 -> 외부 API 요청 보호
- AWS Shield Advanced
	- 대규모, 정교한 DDoS 공격 감지 및 완화
	- NLB와 통합하여 TCP/UDP 계층 공격 보호

오답 이유

- **A. WAF를 NLB에 적용**
    - AWS WAF는 **ALB, API Gateway, CloudFront**만 지원
    - NLB 직접 보호 불가
- **D. GuardDuty + Shield Standard**
    - GuardDuty는 위협 탐지 서비스, Shield Standard는 기본 DDoS 보호
    - 정교한 공격 완화 및 웹 공격 보호는 불충분
- **E. Shield Standard + API Gateway**
    - 기본 DDoS 보호만 제공
    - 정교한 대규모 공격 대응에는 Shield Advanced 필요